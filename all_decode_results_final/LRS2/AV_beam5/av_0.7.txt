2023-02-28 22:15:25,121 - __main__ - INFO - Namespace(batch_size=64, beam=500, beamWidth=5, beamsizetoken=None, beamthreshold=100.0, beta=0.7, decode_type='HYBRID_RESCORE', eval_lrs3_model_file='/home/xcpan/server_1/AAAIckp/av.ckpt', lexicon='/home/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/lst/LRS23.lst', lmpath='/home/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/LRS23_4gram.bin', lmweight=1, logname='/home/gryang/L2_train/av_0.7.txt', modal='AV', nbest=30, silweight=0, type='kenlm', unitlm=False, unkweight=-inf, wordscore=2)
2023-02-28 22:15:25,121 - __main__ - INFO - 
Trained Model File: /home/xcpan/server_1/AAAIckp/av.ckpt
2023-02-28 22:15:25,121 - __main__ - INFO - no noise
2023-02-28 22:15:39,861 - __main__ - INFO - _IncompatibleKeys(missing_keys=['transformer_lm._float_tensor', 'transformer_lm.models.0.decoder.version', 'transformer_lm.models.0.decoder.embed_tokens.weight', 'transformer_lm.models.0.decoder.project_in_dim.weight', 'transformer_lm.models.0.decoder.embed_positions._float_tensor', 'transformer_lm.models.0.decoder.layers.0.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.0.fc1.weight', 'transformer_lm.models.0.decoder.layers.0.fc1.bias', 'transformer_lm.models.0.decoder.layers.0.fc2.weight', 'transformer_lm.models.0.decoder.layers.0.fc2.bias', 'transformer_lm.models.0.decoder.layers.0.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.0.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.1.fc1.weight', 'transformer_lm.models.0.decoder.layers.1.fc1.bias', 'transformer_lm.models.0.decoder.layers.1.fc2.weight', 'transformer_lm.models.0.decoder.layers.1.fc2.bias', 'transformer_lm.models.0.decoder.layers.1.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.1.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.2.fc1.weight', 'transformer_lm.models.0.decoder.layers.2.fc1.bias', 'transformer_lm.models.0.decoder.layers.2.fc2.weight', 'transformer_lm.models.0.decoder.layers.2.fc2.bias', 'transformer_lm.models.0.decoder.layers.2.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.2.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.3.fc1.weight', 'transformer_lm.models.0.decoder.layers.3.fc1.bias', 'transformer_lm.models.0.decoder.layers.3.fc2.weight', 'transformer_lm.models.0.decoder.layers.3.fc2.bias', 'transformer_lm.models.0.decoder.layers.3.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.3.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.4.fc1.weight', 'transformer_lm.models.0.decoder.layers.4.fc1.bias', 'transformer_lm.models.0.decoder.layers.4.fc2.weight', 'transformer_lm.models.0.decoder.layers.4.fc2.bias', 'transformer_lm.models.0.decoder.layers.4.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.4.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.5.fc1.weight', 'transformer_lm.models.0.decoder.layers.5.fc1.bias', 'transformer_lm.models.0.decoder.layers.5.fc2.weight', 'transformer_lm.models.0.decoder.layers.5.fc2.bias', 'transformer_lm.models.0.decoder.layers.5.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.5.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.6.fc1.weight', 'transformer_lm.models.0.decoder.layers.6.fc1.bias', 'transformer_lm.models.0.decoder.layers.6.fc2.weight', 'transformer_lm.models.0.decoder.layers.6.fc2.bias', 'transformer_lm.models.0.decoder.layers.6.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.6.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.7.fc1.weight', 'transformer_lm.models.0.decoder.layers.7.fc1.bias', 'transformer_lm.models.0.decoder.layers.7.fc2.weight', 'transformer_lm.models.0.decoder.layers.7.fc2.bias', 'transformer_lm.models.0.decoder.layers.7.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.7.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.8.fc1.weight', 'transformer_lm.models.0.decoder.layers.8.fc1.bias', 'transformer_lm.models.0.decoder.layers.8.fc2.weight', 'transformer_lm.models.0.decoder.layers.8.fc2.bias', 'transformer_lm.models.0.decoder.layers.8.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.8.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.9.fc1.weight', 'transformer_lm.models.0.decoder.layers.9.fc1.bias', 'transformer_lm.models.0.decoder.layers.9.fc2.weight', 'transformer_lm.models.0.decoder.layers.9.fc2.bias', 'transformer_lm.models.0.decoder.layers.9.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.9.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.10.fc1.weight', 'transformer_lm.models.0.decoder.layers.10.fc1.bias', 'transformer_lm.models.0.decoder.layers.10.fc2.weight', 'transformer_lm.models.0.decoder.layers.10.fc2.bias', 'transformer_lm.models.0.decoder.layers.10.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.10.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.11.fc1.weight', 'transformer_lm.models.0.decoder.layers.11.fc1.bias', 'transformer_lm.models.0.decoder.layers.11.fc2.weight', 'transformer_lm.models.0.decoder.layers.11.fc2.bias', 'transformer_lm.models.0.decoder.layers.11.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.11.final_layer_norm.bias', 'transformer_lm.models.0.decoder.project_out_dim.weight', 'transformer_lm.models.0.decoder.output_projection.weight'], unexpected_keys=[])
2023-02-28 22:15:40,238 - __main__ - INFO - 
Testing the trained model .... 

2023-02-28 22:17:25,982 - __main__ - INFO - rescore index:25
2023-02-28 22:17:39,313 - __main__ - INFO - rescore index:2
2023-02-28 22:17:51,880 - __main__ - INFO - rescore index:23
2023-02-28 22:17:53,178 - __main__ - INFO - rescore index:1
2023-02-28 22:17:54,037 - __main__ - INFO - 

2023-02-28 22:17:54,037 - __main__ - INFO - evalWER:8,evalWCount:411
2023-02-28 22:17:54,037 - __main__ - INFO - batch1 || Test CER: 0.01528 || Test WER: 0.01946
2023-02-28 22:18:41,771 - __main__ - INFO - rescore index:26
2023-02-28 22:18:43,161 - __main__ - INFO - rescore index:1
2023-02-28 22:18:48,322 - __main__ - INFO - rescore index:21
2023-02-28 22:18:55,515 - __main__ - INFO - rescore index:1
2023-02-28 22:19:04,601 - __main__ - INFO - rescore index:23
2023-02-28 22:19:08,558 - __main__ - INFO - 

2023-02-28 22:19:08,558 - __main__ - INFO - evalWER:18,evalWCount:728
2023-02-28 22:19:08,558 - __main__ - INFO - batch2 || Test CER: 0.01794 || Test WER: 0.02473
2023-02-28 22:20:28,011 - __main__ - INFO - rescore index:16
2023-02-28 22:20:35,222 - __main__ - INFO - rescore index:1
2023-02-28 22:20:49,558 - __main__ - INFO - 

2023-02-28 22:20:49,558 - __main__ - INFO - evalWER:27,evalWCount:1102
2023-02-28 22:20:49,558 - __main__ - INFO - batch3 || Test CER: 0.01757 || Test WER: 0.02450
2023-02-28 22:21:38,957 - __main__ - INFO - rescore index:1
2023-02-28 22:21:39,586 - __main__ - INFO - rescore index:1
2023-02-28 22:21:44,747 - __main__ - INFO - rescore index:26
2023-02-28 22:21:52,576 - __main__ - INFO - rescore index:26
2023-02-28 22:21:58,360 - __main__ - INFO - rescore index:16
2023-02-28 22:22:06,820 - __main__ - INFO - rescore index:1
2023-02-28 22:22:17,847 - __main__ - INFO - 

2023-02-28 22:22:17,847 - __main__ - INFO - evalWER:37,evalWCount:1430
2023-02-28 22:22:17,847 - __main__ - INFO - batch4 || Test CER: 0.01814 || Test WER: 0.02587
2023-02-28 22:23:44,767 - __main__ - INFO - rescore index:1
2023-02-28 22:23:46,809 - __main__ - INFO - rescore index:1
2023-02-28 22:23:47,447 - __main__ - INFO - rescore index:1
2023-02-28 22:23:51,227 - __main__ - INFO - rescore index:1
2023-02-28 22:24:23,812 - __main__ - INFO - rescore index:9
2023-02-28 22:24:24,527 - __main__ - INFO - 

2023-02-28 22:24:24,527 - __main__ - INFO - evalWER:46,evalWCount:1774
2023-02-28 22:24:24,527 - __main__ - INFO - batch5 || Test CER: 0.01681 || Test WER: 0.02593
2023-02-28 22:25:42,912 - __main__ - INFO - rescore index:29
2023-02-28 22:25:50,781 - __main__ - INFO - rescore index:26
2023-02-28 22:25:52,665 - __main__ - INFO - rescore index:2
2023-02-28 22:26:02,387 - __main__ - INFO - rescore index:24
2023-02-28 22:26:18,710 - __main__ - INFO - rescore index:1
2023-02-28 22:26:19,409 - __main__ - INFO - 

2023-02-28 22:26:19,409 - __main__ - INFO - evalWER:63,evalWCount:2122
2023-02-28 22:26:19,409 - __main__ - INFO - batch6 || Test CER: 0.01889 || Test WER: 0.02969
2023-02-28 22:27:26,518 - __main__ - INFO - rescore index:5
2023-02-28 22:27:35,584 - __main__ - INFO - rescore index:29
2023-02-28 22:27:42,147 - __main__ - INFO - rescore index:15
2023-02-28 22:27:47,922 - __main__ - INFO - rescore index:1
2023-02-28 22:27:53,163 - __main__ - INFO - 

2023-02-28 22:27:53,163 - __main__ - INFO - evalWER:72,evalWCount:2455
2023-02-28 22:27:53,164 - __main__ - INFO - batch7 || Test CER: 0.01860 || Test WER: 0.02933
2023-02-28 22:28:40,353 - __main__ - INFO - rescore index:1
2023-02-28 22:29:05,506 - __main__ - INFO - rescore index:2
2023-02-28 22:29:15,335 - __main__ - INFO - rescore index:18
2023-02-28 22:29:18,540 - __main__ - INFO - 

2023-02-28 22:29:18,541 - __main__ - INFO - evalWER:80,evalWCount:2818
2023-02-28 22:29:18,541 - __main__ - INFO - batch8 || Test CER: 0.01858 || Test WER: 0.02839
2023-02-28 22:30:28,315 - __main__ - INFO - rescore index:1
2023-02-28 22:30:28,940 - __main__ - INFO - rescore index:1
2023-02-28 22:30:35,371 - __main__ - INFO - rescore index:27
2023-02-28 22:30:42,600 - __main__ - INFO - rescore index:1
2023-02-28 22:30:48,415 - __main__ - INFO - rescore index:27
2023-02-28 22:30:51,084 - __main__ - INFO - rescore index:2
2023-02-28 22:30:52,966 - __main__ - INFO - rescore index:1
2023-02-28 22:31:03,383 - __main__ - INFO - 

2023-02-28 22:31:03,384 - __main__ - INFO - evalWER:95,evalWCount:3175
2023-02-28 22:31:03,384 - __main__ - INFO - batch9 || Test CER: 0.01933 || Test WER: 0.02992
2023-02-28 22:32:12,296 - __main__ - INFO - rescore index:22
2023-02-28 22:32:12,922 - __main__ - INFO - rescore index:9
2023-02-28 22:32:23,413 - __main__ - INFO - rescore index:1
2023-02-28 22:32:24,671 - __main__ - INFO - rescore index:29
2023-02-28 22:32:33,132 - __main__ - INFO - rescore index:28
2023-02-28 22:32:35,644 - __main__ - INFO - rescore index:1
2023-02-28 22:32:37,664 - __main__ - INFO - rescore index:1
2023-02-28 22:32:38,292 - __main__ - INFO - rescore index:15
2023-02-28 22:32:39,605 - __main__ - INFO - 

2023-02-28 22:32:39,605 - __main__ - INFO - evalWER:115,evalWCount:3502
2023-02-28 22:32:39,605 - __main__ - INFO - batch10 || Test CER: 0.02190 || Test WER: 0.03284
2023-02-28 22:33:43,827 - __main__ - INFO - rescore index:2
2023-02-28 22:33:44,600 - __main__ - INFO - rescore index:1
2023-02-28 22:34:01,335 - __main__ - INFO - rescore index:27
2023-02-28 22:34:09,172 - __main__ - INFO - rescore index:2
2023-02-28 22:34:18,959 - __main__ - INFO - 

2023-02-28 22:34:18,960 - __main__ - INFO - evalWER:124,evalWCount:3851
2023-02-28 22:34:18,960 - __main__ - INFO - batch11 || Test CER: 0.02156 || Test WER: 0.03220
2023-02-28 22:35:16,353 - __main__ - INFO - rescore index:9
2023-02-28 22:35:16,977 - __main__ - INFO - rescore index:26
2023-02-28 22:35:18,240 - __main__ - INFO - rescore index:27
2023-02-28 22:35:35,724 - __main__ - INFO - rescore index:3
2023-02-28 22:35:50,020 - __main__ - INFO - 

2023-02-28 22:35:50,020 - __main__ - INFO - evalWER:129,evalWCount:4173
2023-02-28 22:35:50,020 - __main__ - INFO - batch12 || Test CER: 0.02113 || Test WER: 0.03091
2023-02-28 22:36:36,148 - __main__ - INFO - rescore index:24
2023-02-28 22:36:36,773 - __main__ - INFO - rescore index:1
2023-02-28 22:37:13,204 - __main__ - INFO - 

2023-02-28 22:37:13,204 - __main__ - INFO - evalWER:135,evalWCount:4507
2023-02-28 22:37:13,204 - __main__ - INFO - batch13 || Test CER: 0.02033 || Test WER: 0.02995
2023-02-28 22:38:24,692 - __main__ - INFO - rescore index:4
2023-02-28 22:38:35,043 - __main__ - INFO - rescore index:25
2023-02-28 22:38:37,081 - __main__ - INFO - rescore index:26
2023-02-28 22:38:37,712 - __main__ - INFO - rescore index:5
2023-02-28 22:38:48,699 - __main__ - INFO - rescore index:3
2023-02-28 22:38:51,358 - __main__ - INFO - rescore index:24
2023-02-28 22:38:52,052 - __main__ - INFO - 

2023-02-28 22:38:52,053 - __main__ - INFO - evalWER:153,evalWCount:4880
2023-02-28 22:38:52,053 - __main__ - INFO - batch14 || Test CER: 0.02153 || Test WER: 0.03135
2023-02-28 22:39:57,761 - __main__ - INFO - rescore index:1
2023-02-28 22:40:13,993 - __main__ - INFO - rescore index:24
2023-02-28 22:40:21,885 - __main__ - INFO - 

2023-02-28 22:40:21,886 - __main__ - INFO - evalWER:160,evalWCount:5178
2023-02-28 22:40:21,886 - __main__ - INFO - batch15 || Test CER: 0.02094 || Test WER: 0.03090
2023-02-28 22:40:55,081 - __main__ - INFO - rescore index:1
2023-02-28 22:41:05,356 - __main__ - INFO - rescore index:1
2023-02-28 22:41:13,135 - __main__ - INFO - rescore index:10
2023-02-28 22:41:27,449 - __main__ - INFO - rescore index:1
2023-02-28 22:41:35,912 - __main__ - INFO - 

2023-02-28 22:41:35,912 - __main__ - INFO - evalWER:164,evalWCount:5499
2023-02-28 22:41:35,912 - __main__ - INFO - batch16 || Test CER: 0.02044 || Test WER: 0.02982
2023-02-28 22:43:10,540 - __main__ - INFO - rescore index:1
2023-02-28 22:43:12,423 - __main__ - INFO - rescore index:1
2023-02-28 22:43:23,567 - __main__ - INFO - rescore index:24
2023-02-28 22:43:40,375 - __main__ - INFO - rescore index:18
2023-02-28 22:43:42,885 - __main__ - INFO - rescore index:3
2023-02-28 22:43:42,972 - __main__ - INFO - 

2023-02-28 22:43:42,972 - __main__ - INFO - evalWER:173,evalWCount:5852
2023-02-28 22:43:42,972 - __main__ - INFO - batch17 || Test CER: 0.02014 || Test WER: 0.02956
2023-02-28 22:44:44,520 - __main__ - INFO - rescore index:1
2023-02-28 22:44:45,776 - __main__ - INFO - rescore index:1
2023-02-28 22:45:00,650 - __main__ - INFO - rescore index:1
2023-02-28 22:45:06,457 - __main__ - INFO - rescore index:2
2023-02-28 22:45:10,993 - __main__ - INFO - rescore index:28
2023-02-28 22:45:13,657 - __main__ - INFO - rescore index:5
2023-02-28 22:45:16,313 - __main__ - INFO - rescore index:1
2023-02-28 22:45:18,192 - __main__ - INFO - rescore index:2
2023-02-28 22:45:22,798 - __main__ - INFO - 

2023-02-28 22:45:22,799 - __main__ - INFO - evalWER:187,evalWCount:6185
2023-02-28 22:45:22,799 - __main__ - INFO - batch18 || Test CER: 0.02009 || Test WER: 0.03023
2023-02-28 22:46:25,608 - __main__ - INFO - rescore index:1
2023-02-28 22:46:28,243 - __main__ - INFO - rescore index:1
2023-02-28 22:46:30,765 - __main__ - INFO - rescore index:27
2023-02-28 22:46:40,573 - __main__ - INFO - rescore index:1
2023-02-28 22:46:42,511 - __main__ - INFO - 

2023-02-28 22:46:42,512 - __main__ - INFO - evalWER:195,evalWCount:6511
2023-02-28 22:46:42,512 - __main__ - INFO - batch19 || Test CER: 0.01977 || Test WER: 0.02995
2023-02-28 22:47:04,769 - __main__ - INFO - rescore index:27
2023-02-28 22:47:05,500 - __main__ - INFO - rescore index:2
2023-02-28 22:47:10,612 - __main__ - INFO - rescore index:1
2023-02-28 22:47:19,094 - __main__ - INFO - 

2023-02-28 22:47:19,094 - __main__ - INFO - evalWER:196,evalWCount:6660
2023-02-28 22:47:19,094 - __main__ - INFO - batch20 || Test CER: 0.01954 || Test WER: 0.02943
2023-02-28 22:47:19,264 - __main__ - INFO - evalWER:196,evalCCount:6660
2023-02-28 22:47:19,264 - __main__ - INFO - AVMODAL || Test CER: 0.01954 || Test WER: 0.02943
2023-02-28 22:47:19,265 - __main__ - INFO - 
Testing Done.

