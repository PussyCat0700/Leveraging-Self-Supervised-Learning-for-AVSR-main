2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11614
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11614
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11614
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11614
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | initialized host yase as rank 1
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | initialized host yase as rank 0
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | initialized host yase as rank 2
2023-02-10 19:34:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-02-10 19:34:21 | INFO | fairseq.distributed.utils | initialized host yase as rank 3
2023-02-10 19:34:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'language_model', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11614', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 83968, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 83968, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 12, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': '/home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/data-bin/LibriLRS23_wordpiece_vocab4000', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
2023-02-10 19:34:24 | INFO | fairseq.tasks.language_modeling | dictionary: 3984 types
2023-02-10 19:34:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(3984, 512, padding_idx=1)
    (project_in_dim): Linear(in_features=512, out_features=1024, bias=False)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (project_out_dim): Linear(in_features=1024, out_features=512, bias=False)
    (output_projection): Linear(in_features=512, out_features=3984, bias=False)
  )
)
2023-02-10 19:34:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2023-02-10 19:34:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2023-02-10 19:34:25 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2023-02-10 19:34:25 | INFO | fairseq_cli.train | num. shared model params: 103,886,848 (num. trained: 103,886,848)
2023-02-10 19:34:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-02-10 19:34:25 | INFO | fairseq.data.data_utils | loaded 1,082 examples from: /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/data-bin/LibriLRS23_wordpiece_vocab4000/valid
2023-02-10 19:34:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-02-10 19:34:25 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2023-02-10 19:34:25 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-02-10 19:34:25 | INFO | fairseq.trainer | detected shared parameter: decoder.project_in_dim.bias <- decoder.project_out_dim.bias
2023-02-10 19:34:25 | INFO | fairseq.trainer | detected shared parameter: decoder.project_in_dim.bias <- decoder.output_projection.bias
2023-02-10 19:34:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-02-10 19:34:26 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.424 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-02-10 19:34:26 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 39.424 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-02-10 19:34:26 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 39.424 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-02-10 19:34:26 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 39.424 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-02-10 19:34:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-02-10 19:34:26 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-02-10 19:34:26 | INFO | fairseq_cli.train | max tokens per device = 83968 and max sentences per device = None
2023-02-10 19:34:26 | INFO | fairseq.trainer | Preparing to load checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint_last.pt
2023-02-10 19:34:26 | INFO | fairseq.trainer | No existing checkpoint found /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint_last.pt
2023-02-10 19:34:26 | INFO | fairseq.trainer | loading train data for epoch 1
2023-02-10 19:34:26 | INFO | fairseq.data.data_utils | loaded 566,817 examples from: /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/data-bin/LibriLRS23_wordpiece_vocab4000/train
wandb: Currently logged in as: yanghaha. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /home/gryang/fairseq/wandb/run-20230210_193430-31fi691w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run LRS23vocab_LibriLRS23_transformer_drop0.5wd0.01
wandb: ⭐️ View project at https://wandb.ai/yanghaha/language_model
wandb: 🚀 View run at https://wandb.ai/yanghaha/language_model/runs/31fi691w
2023-02-10 19:35:03 | INFO | fairseq.trainer | begin training epoch 1
2023-02-10 19:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:35:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-02-10 19:35:29 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
2023-02-10 19:35:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-02-10 19:36:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-02-10 19:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-02-10 19:36:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-02-10 19:36:42 | INFO | train | epoch 001 | loss 13.01 | ppl 8250.58 | wps 0 | ups 0 | wpb 163840 | bsz 320 | num_updates 1 | lr 2.24975e-07 | gnorm 7.055 | loss_scale 8 | train_wall 97 | gb_free 6.2 | wall 137
2023-02-10 19:36:43 | INFO | fairseq.trainer | begin training epoch 2
2023-02-10 19:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:37:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-02-10 19:37:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-02-10 19:37:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-10 19:37:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-10 19:37:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-02-10 19:37:49 | INFO | train | epoch 002 | loss 13.014 | ppl 8269.52 | wps 2456.9 | ups 0.01 | wpb 163840 | bsz 320 | num_updates 2 | lr 3.4995e-07 | gnorm 7.018 | loss_scale 0.5 | train_wall 34 | gb_free 5.4 | wall 203
2023-02-10 19:37:49 | INFO | fairseq.trainer | begin training epoch 3
2023-02-10 19:37:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:38:25 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-02-10 19:38:25 | INFO | train | epoch 003 | loss 13.008 | ppl 8237.68 | wps 583119 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7 | lr 9.74825e-07 | gnorm 7.015 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 239
2023-02-10 19:38:25 | INFO | fairseq.trainer | begin training epoch 4
2023-02-10 19:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:39:02 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-02-10 19:39:02 | INFO | train | epoch 004 | loss 12.872 | ppl 7493.95 | wps 568934 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 12 | lr 1.5997e-06 | gnorm 6.633 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 276
2023-02-10 19:39:02 | INFO | fairseq.trainer | begin training epoch 5
2023-02-10 19:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:39:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-02-10 19:39:38 | INFO | train | epoch 005 | loss 12.475 | ppl 5691.22 | wps 583428 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 17 | lr 2.22458e-06 | gnorm 5.495 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 312
2023-02-10 19:39:38 | INFO | fairseq.trainer | begin training epoch 6
2023-02-10 19:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:40:15 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-02-10 19:40:15 | INFO | train | epoch 006 | loss 12.096 | ppl 4378.63 | wps 575815 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 22 | lr 2.84945e-06 | gnorm 4.066 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 349
2023-02-10 19:40:15 | INFO | fairseq.trainer | begin training epoch 7
2023-02-10 19:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:40:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-02-10 19:40:51 | INFO | train | epoch 007 | loss 11.843 | ppl 3673.3 | wps 584031 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 27 | lr 3.47433e-06 | gnorm 3.188 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 385
2023-02-10 19:40:51 | INFO | fairseq.trainer | begin training epoch 8
2023-02-10 19:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:41:28 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-02-10 19:41:28 | INFO | train | epoch 008 | loss 11.593 | ppl 3088.73 | wps 569534 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 32 | lr 4.0992e-06 | gnorm 2.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 422
2023-02-10 19:41:28 | INFO | fairseq.trainer | begin training epoch 9
2023-02-10 19:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:42:04 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-02-10 19:42:04 | INFO | train | epoch 009 | loss 11.422 | ppl 2744.28 | wps 585203 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 37 | lr 4.72408e-06 | gnorm 2.038 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 458
2023-02-10 19:42:04 | INFO | fairseq.trainer | begin training epoch 10
2023-02-10 19:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 19:42:43 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.401 | ppl 1352.23 | wps 0 | wpb 11230 | bsz 22 | num_updates 42
2023-02-10 19:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 42 updates
2023-02-10 19:42:43 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint10.pt
2023-02-10 19:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint10.pt
2023-02-10 19:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint10.pt (epoch 10 @ 42 updates, score 10.401) (writing took 65.38497159499093 seconds)
2023-02-10 19:43:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-02-10 19:43:48 | INFO | train | epoch 010 | loss 11.279 | ppl 2484.84 | wps 201864 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 42 | lr 5.34895e-06 | gnorm 1.68 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 562
2023-02-10 19:43:48 | INFO | fairseq.trainer | begin training epoch 11
2023-02-10 19:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:44:40 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-02-10 19:44:40 | INFO | train | epoch 011 | loss 11.167 | ppl 2298.57 | wps 402251 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 47 | lr 5.97383e-06 | gnorm 1.469 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 614
2023-02-10 19:44:40 | INFO | fairseq.trainer | begin training epoch 12
2023-02-10 19:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:45:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-02-10 19:45:16 | INFO | train | epoch 012 | loss 11.073 | ppl 2154.28 | wps 583456 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 52 | lr 6.5987e-06 | gnorm 1.323 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 650
2023-02-10 19:45:16 | INFO | fairseq.trainer | begin training epoch 13
2023-02-10 19:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:45:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-02-10 19:45:53 | INFO | train | epoch 013 | loss 10.991 | ppl 2035.26 | wps 577618 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 57 | lr 7.22358e-06 | gnorm 1.195 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 687
2023-02-10 19:45:53 | INFO | fairseq.trainer | begin training epoch 14
2023-02-10 19:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:46:29 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-02-10 19:46:29 | INFO | train | epoch 014 | loss 10.918 | ppl 1935.13 | wps 578652 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 62 | lr 7.84845e-06 | gnorm 1.116 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 723
2023-02-10 19:46:29 | INFO | fairseq.trainer | begin training epoch 15
2023-02-10 19:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:47:06 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-02-10 19:47:06 | INFO | train | epoch 015 | loss 10.851 | ppl 1847.45 | wps 573693 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 67 | lr 8.47333e-06 | gnorm 1.05 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 760
2023-02-10 19:47:06 | INFO | fairseq.trainer | begin training epoch 16
2023-02-10 19:47:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:47:42 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-02-10 19:47:42 | INFO | train | epoch 016 | loss 10.788 | ppl 1768.02 | wps 575886 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 72 | lr 9.0982e-06 | gnorm 0.99 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 796
2023-02-10 19:47:42 | INFO | fairseq.trainer | begin training epoch 17
2023-02-10 19:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:48:18 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-02-10 19:48:18 | INFO | train | epoch 017 | loss 10.729 | ppl 1696.76 | wps 582282 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 77 | lr 9.72308e-06 | gnorm 0.954 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 832
2023-02-10 19:48:18 | INFO | fairseq.trainer | begin training epoch 18
2023-02-10 19:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:48:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-02-10 19:48:54 | INFO | train | epoch 018 | loss 10.67 | ppl 1629.65 | wps 584892 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 82 | lr 1.0348e-05 | gnorm 0.91 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 868
2023-02-10 19:48:54 | INFO | fairseq.trainer | begin training epoch 19
2023-02-10 19:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:49:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-02-10 19:49:31 | INFO | train | epoch 019 | loss 10.615 | ppl 1568.08 | wps 572508 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 87 | lr 1.09728e-05 | gnorm 0.88 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 905
2023-02-10 19:49:31 | INFO | fairseq.trainer | begin training epoch 20
2023-02-10 19:49:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 19:50:09 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.777 | ppl 877.42 | wps 0 | wpb 11230 | bsz 22 | num_updates 92 | best_loss 9.777
2023-02-10 19:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 92 updates
2023-02-10 19:50:09 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint20.pt
2023-02-10 19:50:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint20.pt
2023-02-10 19:51:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint20.pt (epoch 20 @ 92 updates, score 9.777) (writing took 64.92146032300661 seconds)
2023-02-10 19:51:14 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-02-10 19:51:14 | INFO | train | epoch 020 | loss 10.56 | ppl 1510.1 | wps 203842 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 92 | lr 1.15977e-05 | gnorm 0.833 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1008
2023-02-10 19:51:14 | INFO | fairseq.trainer | begin training epoch 21
2023-02-10 19:51:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:51:51 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-02-10 19:51:51 | INFO | train | epoch 021 | loss 10.508 | ppl 1456.25 | wps 575454 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 97 | lr 1.22226e-05 | gnorm 0.805 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1045
2023-02-10 19:51:51 | INFO | fairseq.trainer | begin training epoch 22
2023-02-10 19:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:52:18 | INFO | train_inner | epoch 022:      3 / 5 loss=11.308, ppl=2535.66, wps=444080, ups=0.11, wpb=4.15596e+06, bsz=8117.2, num_updates=100, lr=1.25975e-05, gnorm=2.368, loss_scale=0.5, train_wall=786, gb_free=5.4, wall=1072
2023-02-10 19:52:27 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-02-10 19:52:27 | INFO | train | epoch 022 | loss 10.456 | ppl 1404.82 | wps 583110 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 102 | lr 1.28475e-05 | gnorm 0.775 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1081
2023-02-10 19:52:27 | INFO | fairseq.trainer | begin training epoch 23
2023-02-10 19:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:53:03 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-02-10 19:53:03 | INFO | train | epoch 023 | loss 10.406 | ppl 1356.57 | wps 579918 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 107 | lr 1.34723e-05 | gnorm 0.739 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1117
2023-02-10 19:53:03 | INFO | fairseq.trainer | begin training epoch 24
2023-02-10 19:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:53:39 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-02-10 19:53:39 | INFO | train | epoch 024 | loss 10.356 | ppl 1310.56 | wps 579463 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 112 | lr 1.40972e-05 | gnorm 0.706 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1153
2023-02-10 19:53:40 | INFO | fairseq.trainer | begin training epoch 25
2023-02-10 19:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:54:16 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-02-10 19:54:16 | INFO | train | epoch 025 | loss 10.307 | ppl 1266.96 | wps 576338 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 117 | lr 1.47221e-05 | gnorm 0.671 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1190
2023-02-10 19:54:16 | INFO | fairseq.trainer | begin training epoch 26
2023-02-10 19:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:54:53 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-02-10 19:54:53 | INFO | train | epoch 026 | loss 10.26 | ppl 1226.17 | wps 568222 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 122 | lr 1.5347e-05 | gnorm 0.637 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1227
2023-02-10 19:54:53 | INFO | fairseq.trainer | begin training epoch 27
2023-02-10 19:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:55:30 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-02-10 19:55:30 | INFO | train | epoch 027 | loss 10.214 | ppl 1187.44 | wps 572859 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 127 | lr 1.59718e-05 | gnorm 0.617 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1264
2023-02-10 19:55:30 | INFO | fairseq.trainer | begin training epoch 28
2023-02-10 19:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:56:06 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-02-10 19:56:06 | INFO | train | epoch 028 | loss 10.169 | ppl 1151.48 | wps 584082 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 132 | lr 1.65967e-05 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1300
2023-02-10 19:56:06 | INFO | fairseq.trainer | begin training epoch 29
2023-02-10 19:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:56:42 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-02-10 19:56:42 | INFO | train | epoch 029 | loss 10.126 | ppl 1117.63 | wps 573960 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 137 | lr 1.72216e-05 | gnorm 0.544 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1336
2023-02-10 19:56:42 | INFO | fairseq.trainer | begin training epoch 30
2023-02-10 19:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 19:57:21 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.385 | ppl 668.44 | wps 0 | wpb 11230 | bsz 22 | num_updates 142 | best_loss 9.385
2023-02-10 19:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 142 updates
2023-02-10 19:57:21 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint30.pt
2023-02-10 19:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint30.pt
2023-02-10 19:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint30.pt (epoch 30 @ 142 updates, score 9.385) (writing took 60.30506244098069 seconds)
2023-02-10 19:58:21 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-02-10 19:58:21 | INFO | train | epoch 030 | loss 10.085 | ppl 1086.42 | wps 212188 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 142 | lr 1.78465e-05 | gnorm 0.514 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1435
2023-02-10 19:58:22 | INFO | fairseq.trainer | begin training epoch 31
2023-02-10 19:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:58:58 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-02-10 19:58:58 | INFO | train | epoch 031 | loss 10.046 | ppl 1057.22 | wps 578985 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 147 | lr 1.84713e-05 | gnorm 0.476 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1472
2023-02-10 19:58:58 | INFO | fairseq.trainer | begin training epoch 32
2023-02-10 19:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 19:59:34 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-02-10 19:59:34 | INFO | train | epoch 032 | loss 10.009 | ppl 1030.4 | wps 581895 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 152 | lr 1.90962e-05 | gnorm 0.456 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1508
2023-02-10 19:59:34 | INFO | fairseq.trainer | begin training epoch 33
2023-02-10 19:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:00:10 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-02-10 20:00:10 | INFO | train | epoch 033 | loss 9.974 | ppl 1006.02 | wps 581697 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 157 | lr 1.97211e-05 | gnorm 0.45 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1544
2023-02-10 20:00:10 | INFO | fairseq.trainer | begin training epoch 34
2023-02-10 20:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:00:47 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-02-10 20:00:47 | INFO | train | epoch 034 | loss 9.941 | ppl 983.1 | wps 574378 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 162 | lr 2.0346e-05 | gnorm 0.423 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1581
2023-02-10 20:00:47 | INFO | fairseq.trainer | begin training epoch 35
2023-02-10 20:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:01:23 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-02-10 20:01:23 | INFO | train | epoch 035 | loss 9.911 | ppl 962.92 | wps 573340 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 167 | lr 2.09708e-05 | gnorm 0.405 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1617
2023-02-10 20:01:24 | INFO | fairseq.trainer | begin training epoch 36
2023-02-10 20:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:02:00 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-02-10 20:02:00 | INFO | train | epoch 036 | loss 9.883 | ppl 944.29 | wps 570884 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 172 | lr 2.15957e-05 | gnorm 0.363 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1654
2023-02-10 20:02:00 | INFO | fairseq.trainer | begin training epoch 37
2023-02-10 20:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:02:37 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-02-10 20:02:37 | INFO | train | epoch 037 | loss 9.858 | ppl 927.74 | wps 573093 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 177 | lr 2.22206e-05 | gnorm 0.369 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1691
2023-02-10 20:02:37 | INFO | fairseq.trainer | begin training epoch 38
2023-02-10 20:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:03:13 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-02-10 20:03:13 | INFO | train | epoch 038 | loss 9.834 | ppl 912.47 | wps 584530 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 182 | lr 2.28455e-05 | gnorm 0.334 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1727
2023-02-10 20:03:13 | INFO | fairseq.trainer | begin training epoch 39
2023-02-10 20:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:03:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-02-10 20:03:50 | INFO | train | epoch 039 | loss 9.812 | ppl 898.75 | wps 570012 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 187 | lr 2.34703e-05 | gnorm 0.364 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1764
2023-02-10 20:03:50 | INFO | fairseq.trainer | begin training epoch 40
2023-02-10 20:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:04:29 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.129 | ppl 559.95 | wps 0 | wpb 11230 | bsz 22 | num_updates 192 | best_loss 9.129
2023-02-10 20:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 192 updates
2023-02-10 20:04:29 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint40.pt
2023-02-10 20:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint40.pt
2023-02-10 20:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint40.pt (epoch 40 @ 192 updates, score 9.129) (writing took 61.48814366100123 seconds)
2023-02-10 20:05:30 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-02-10 20:05:30 | INFO | train | epoch 040 | loss 9.792 | ppl 886.46 | wps 209260 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 192 | lr 2.40952e-05 | gnorm 0.35 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1864
2023-02-10 20:05:30 | INFO | fairseq.trainer | begin training epoch 41
2023-02-10 20:05:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:06:07 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-02-10 20:06:07 | INFO | train | epoch 041 | loss 9.773 | ppl 874.99 | wps 566311 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 197 | lr 2.47201e-05 | gnorm 0.366 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1902
2023-02-10 20:06:08 | INFO | fairseq.trainer | begin training epoch 42
2023-02-10 20:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:06:36 | INFO | train_inner | epoch 042:      3 / 5 loss=10.034, ppl=1048.76, wps=490543, ups=0.12, wpb=4.20675e+06, bsz=8216.4, num_updates=200, lr=2.5095e-05, gnorm=0.493, loss_scale=0.5, train_wall=663, gb_free=5.4, wall=1930
2023-02-10 20:06:44 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-02-10 20:06:44 | INFO | train | epoch 042 | loss 9.755 | ppl 864.21 | wps 570269 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 202 | lr 2.5345e-05 | gnorm 0.326 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1938
2023-02-10 20:06:44 | INFO | fairseq.trainer | begin training epoch 43
2023-02-10 20:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:07:21 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-02-10 20:07:21 | INFO | train | epoch 043 | loss 9.738 | ppl 853.97 | wps 570191 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 207 | lr 2.59698e-05 | gnorm 0.359 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 1975
2023-02-10 20:07:21 | INFO | fairseq.trainer | begin training epoch 44
2023-02-10 20:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:07:58 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-02-10 20:07:58 | INFO | train | epoch 044 | loss 9.721 | ppl 843.92 | wps 564978 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 212 | lr 2.65947e-05 | gnorm 0.478 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2013
2023-02-10 20:07:59 | INFO | fairseq.trainer | begin training epoch 45
2023-02-10 20:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:08:35 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-02-10 20:08:35 | INFO | train | epoch 045 | loss 9.702 | ppl 832.83 | wps 568664 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 217 | lr 2.72196e-05 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2050
2023-02-10 20:08:36 | INFO | fairseq.trainer | begin training epoch 46
2023-02-10 20:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:09:12 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-02-10 20:09:12 | INFO | train | epoch 046 | loss 9.677 | ppl 818.39 | wps 568988 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 222 | lr 2.78445e-05 | gnorm 0.534 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2086
2023-02-10 20:09:13 | INFO | fairseq.trainer | begin training epoch 47
2023-02-10 20:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:09:49 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-02-10 20:09:49 | INFO | train | epoch 047 | loss 9.65 | ppl 803.14 | wps 571164 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 227 | lr 2.84693e-05 | gnorm 1.112 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2123
2023-02-10 20:09:49 | INFO | fairseq.trainer | begin training epoch 48
2023-02-10 20:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:10:26 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-02-10 20:10:26 | INFO | train | epoch 048 | loss 9.618 | ppl 786.05 | wps 577786 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 232 | lr 2.90942e-05 | gnorm 1.043 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2160
2023-02-10 20:10:26 | INFO | fairseq.trainer | begin training epoch 49
2023-02-10 20:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:11:03 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-02-10 20:11:03 | INFO | train | epoch 049 | loss 9.592 | ppl 771.95 | wps 558610 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 237 | lr 2.97191e-05 | gnorm 1.187 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2197
2023-02-10 20:11:03 | INFO | fairseq.trainer | begin training epoch 50
2023-02-10 20:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:11:43 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.105 | ppl 550.71 | wps 0 | wpb 11230 | bsz 22 | num_updates 242 | best_loss 9.105
2023-02-10 20:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 242 updates
2023-02-10 20:11:43 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint50.pt
2023-02-10 20:11:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint50.pt
2023-02-10 20:12:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint50.pt (epoch 50 @ 242 updates, score 9.105) (writing took 66.36089521399117 seconds)
2023-02-10 20:12:50 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-02-10 20:12:50 | INFO | train | epoch 050 | loss 9.562 | ppl 755.97 | wps 197642 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 242 | lr 3.0344e-05 | gnorm 0.797 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2304
2023-02-10 20:12:50 | INFO | fairseq.trainer | begin training epoch 51
2023-02-10 20:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:13:27 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-02-10 20:13:27 | INFO | train | epoch 051 | loss 9.534 | ppl 741.29 | wps 563450 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 247 | lr 3.09688e-05 | gnorm 0.623 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2341
2023-02-10 20:13:27 | INFO | fairseq.trainer | begin training epoch 52
2023-02-10 20:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:14:04 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-02-10 20:14:04 | INFO | train | epoch 052 | loss 9.503 | ppl 725.66 | wps 566904 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 252 | lr 3.15937e-05 | gnorm 0.554 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 2378
2023-02-10 20:14:04 | INFO | fairseq.trainer | begin training epoch 53
2023-02-10 20:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:14:41 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-02-10 20:14:41 | INFO | train | epoch 053 | loss 9.471 | ppl 709.79 | wps 575646 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 257 | lr 3.22186e-05 | gnorm 0.623 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2415
2023-02-10 20:14:41 | INFO | fairseq.trainer | begin training epoch 54
2023-02-10 20:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:15:18 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-02-10 20:15:18 | INFO | train | epoch 054 | loss 9.438 | ppl 693.64 | wps 567471 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 262 | lr 3.28435e-05 | gnorm 0.698 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2452
2023-02-10 20:15:18 | INFO | fairseq.trainer | begin training epoch 55
2023-02-10 20:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:15:55 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-02-10 20:15:55 | INFO | train | epoch 055 | loss 9.402 | ppl 676.62 | wps 568606 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 267 | lr 3.34683e-05 | gnorm 0.648 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2489
2023-02-10 20:15:55 | INFO | fairseq.trainer | begin training epoch 56
2023-02-10 20:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:16:31 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2023-02-10 20:16:31 | INFO | train | epoch 056 | loss 9.371 | ppl 662.35 | wps 575884 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 272 | lr 3.40932e-05 | gnorm 0.821 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2525
2023-02-10 20:16:31 | INFO | fairseq.trainer | begin training epoch 57
2023-02-10 20:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:17:12 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2023-02-10 20:17:12 | INFO | train | epoch 057 | loss 9.337 | ppl 646.89 | wps 516813 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 277 | lr 3.47181e-05 | gnorm 0.816 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2566
2023-02-10 20:17:12 | INFO | fairseq.trainer | begin training epoch 58
2023-02-10 20:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:17:49 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2023-02-10 20:17:49 | INFO | train | epoch 058 | loss 9.305 | ppl 632.66 | wps 575519 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 282 | lr 3.5343e-05 | gnorm 0.806 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2603
2023-02-10 20:17:49 | INFO | fairseq.trainer | begin training epoch 59
2023-02-10 20:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:18:26 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2023-02-10 20:18:26 | INFO | train | epoch 059 | loss 9.276 | ppl 619.74 | wps 565163 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 287 | lr 3.59678e-05 | gnorm 0.864 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2640
2023-02-10 20:18:26 | INFO | fairseq.trainer | begin training epoch 60
2023-02-10 20:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:19:06 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 8.52 | ppl 367.12 | wps 0 | wpb 11230 | bsz 22 | num_updates 292 | best_loss 8.52
2023-02-10 20:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 292 updates
2023-02-10 20:19:06 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint60.pt
2023-02-10 20:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint60.pt
2023-02-10 20:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint60.pt (epoch 60 @ 292 updates, score 8.52) (writing took 65.33366120699793 seconds)
2023-02-10 20:20:11 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2023-02-10 20:20:11 | INFO | train | epoch 060 | loss 9.243 | ppl 606.03 | wps 199011 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 292 | lr 3.65927e-05 | gnorm 0.675 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2746
2023-02-10 20:20:12 | INFO | fairseq.trainer | begin training epoch 61
2023-02-10 20:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:20:48 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2023-02-10 20:20:48 | INFO | train | epoch 061 | loss 9.212 | ppl 593.23 | wps 570602 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 297 | lr 3.72176e-05 | gnorm 0.686 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2782
2023-02-10 20:20:48 | INFO | fairseq.trainer | begin training epoch 62
2023-02-10 20:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:21:17 | INFO | train_inner | epoch 062:      3 / 5 loss=9.484, ppl=716.24, wps=477535, ups=0.11, wpb=4.20756e+06, bsz=8218, num_updates=300, lr=3.75925e-05, gnorm=0.729, loss_scale=1, train_wall=665, gb_free=5.4, wall=2811
2023-02-10 20:21:25 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2023-02-10 20:21:25 | INFO | train | epoch 062 | loss 9.185 | ppl 582.08 | wps 566404 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 302 | lr 3.78425e-05 | gnorm 0.909 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2820
2023-02-10 20:21:26 | INFO | fairseq.trainer | begin training epoch 63
2023-02-10 20:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:22:02 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2023-02-10 20:22:02 | INFO | train | epoch 063 | loss 9.157 | ppl 570.72 | wps 570307 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 307 | lr 3.84673e-05 | gnorm 0.852 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2856
2023-02-10 20:22:02 | INFO | fairseq.trainer | begin training epoch 64
2023-02-10 20:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:22:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2023-02-10 20:22:39 | INFO | train | epoch 064 | loss 9.127 | ppl 559.23 | wps 567728 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 312 | lr 3.90922e-05 | gnorm 0.825 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2893
2023-02-10 20:22:40 | INFO | fairseq.trainer | begin training epoch 65
2023-02-10 20:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:23:18 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2023-02-10 20:23:18 | INFO | train | epoch 065 | loss 9.097 | ppl 547.56 | wps 546370 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 317 | lr 3.97171e-05 | gnorm 0.589 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2932
2023-02-10 20:23:18 | INFO | fairseq.trainer | begin training epoch 66
2023-02-10 20:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:23:54 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2023-02-10 20:23:54 | INFO | train | epoch 066 | loss 9.069 | ppl 537.15 | wps 575837 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 322 | lr 4.0342e-05 | gnorm 0.649 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 2969
2023-02-10 20:23:55 | INFO | fairseq.trainer | begin training epoch 67
2023-02-10 20:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:24:32 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2023-02-10 20:24:32 | INFO | train | epoch 067 | loss 9.04 | ppl 526.42 | wps 561447 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 327 | lr 4.09668e-05 | gnorm 0.596 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3006
2023-02-10 20:24:32 | INFO | fairseq.trainer | begin training epoch 68
2023-02-10 20:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:25:09 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2023-02-10 20:25:09 | INFO | train | epoch 068 | loss 9.012 | ppl 516.35 | wps 573441 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 332 | lr 4.15917e-05 | gnorm 0.657 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3043
2023-02-10 20:25:09 | INFO | fairseq.trainer | begin training epoch 69
2023-02-10 20:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:25:45 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2023-02-10 20:25:45 | INFO | train | epoch 069 | loss 8.984 | ppl 506.51 | wps 573712 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 337 | lr 4.22166e-05 | gnorm 0.736 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3079
2023-02-10 20:25:45 | INFO | fairseq.trainer | begin training epoch 70
2023-02-10 20:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:26:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:26:26 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 8.024 | ppl 260.3 | wps 0 | wpb 11230 | bsz 22 | num_updates 342 | best_loss 8.024
2023-02-10 20:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 342 updates
2023-02-10 20:26:26 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint70.pt
2023-02-10 20:26:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint70.pt
2023-02-10 20:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint70.pt (epoch 70 @ 342 updates, score 8.024) (writing took 67.16116242701537 seconds)
2023-02-10 20:27:33 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2023-02-10 20:27:33 | INFO | train | epoch 070 | loss 8.957 | ppl 496.96 | wps 195485 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 342 | lr 4.28415e-05 | gnorm 0.724 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3187
2023-02-10 20:27:33 | INFO | fairseq.trainer | begin training epoch 71
2023-02-10 20:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:28:10 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2023-02-10 20:28:10 | INFO | train | epoch 071 | loss 8.928 | ppl 487.18 | wps 572416 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 347 | lr 4.34663e-05 | gnorm 0.664 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3224
2023-02-10 20:28:10 | INFO | fairseq.trainer | begin training epoch 72
2023-02-10 20:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:28:47 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2023-02-10 20:28:47 | INFO | train | epoch 072 | loss 8.901 | ppl 478.01 | wps 566791 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 352 | lr 4.40912e-05 | gnorm 0.748 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3261
2023-02-10 20:28:47 | INFO | fairseq.trainer | begin training epoch 73
2023-02-10 20:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:29:24 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2023-02-10 20:29:24 | INFO | train | epoch 073 | loss 8.873 | ppl 468.81 | wps 562663 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 357 | lr 4.47161e-05 | gnorm 0.754 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3298
2023-02-10 20:29:24 | INFO | fairseq.trainer | begin training epoch 74
2023-02-10 20:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:30:01 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2023-02-10 20:30:01 | INFO | train | epoch 074 | loss 8.845 | ppl 459.75 | wps 567928 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 362 | lr 4.5341e-05 | gnorm 0.738 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3335
2023-02-10 20:30:01 | INFO | fairseq.trainer | begin training epoch 75
2023-02-10 20:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:30:39 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2023-02-10 20:30:39 | INFO | train | epoch 075 | loss 8.816 | ppl 450.76 | wps 559422 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 367 | lr 4.59658e-05 | gnorm 0.736 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3373
2023-02-10 20:30:39 | INFO | fairseq.trainer | begin training epoch 76
2023-02-10 20:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:31:15 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2023-02-10 20:31:15 | INFO | train | epoch 076 | loss 8.787 | ppl 441.66 | wps 572638 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 372 | lr 4.65907e-05 | gnorm 0.602 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3410
2023-02-10 20:31:16 | INFO | fairseq.trainer | begin training epoch 77
2023-02-10 20:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:31:52 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2023-02-10 20:31:52 | INFO | train | epoch 077 | loss 8.758 | ppl 433.06 | wps 569901 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 377 | lr 4.72156e-05 | gnorm 0.733 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3446
2023-02-10 20:31:53 | INFO | fairseq.trainer | begin training epoch 78
2023-02-10 20:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:32:30 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2023-02-10 20:32:30 | INFO | train | epoch 078 | loss 8.732 | ppl 425.19 | wps 554191 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 382 | lr 4.78405e-05 | gnorm 0.768 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3484
2023-02-10 20:32:30 | INFO | fairseq.trainer | begin training epoch 79
2023-02-10 20:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:33:07 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2023-02-10 20:33:07 | INFO | train | epoch 079 | loss 8.701 | ppl 416.25 | wps 571932 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 387 | lr 4.84653e-05 | gnorm 0.68 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3521
2023-02-10 20:33:07 | INFO | fairseq.trainer | begin training epoch 80
2023-02-10 20:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:33:48 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 7.744 | ppl 214.45 | wps 0 | wpb 11230 | bsz 22 | num_updates 392 | best_loss 7.744
2023-02-10 20:33:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 392 updates
2023-02-10 20:33:48 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint80.pt
2023-02-10 20:33:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint80.pt
2023-02-10 20:34:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint80.pt (epoch 80 @ 392 updates, score 7.744) (writing took 61.910332592000486 seconds)
2023-02-10 20:34:49 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2023-02-10 20:34:49 | INFO | train | epoch 080 | loss 8.674 | ppl 408.31 | wps 205607 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 392 | lr 4.90902e-05 | gnorm 0.837 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3623
2023-02-10 20:34:50 | INFO | fairseq.trainer | begin training epoch 81
2023-02-10 20:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:35:27 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2023-02-10 20:35:27 | INFO | train | epoch 081 | loss 8.645 | ppl 400.42 | wps 562929 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 397 | lr 4.97151e-05 | gnorm 0.868 | loss_scale 1 | train_wall 33 | gb_free 36.9 | wall 3661
2023-02-10 20:35:27 | INFO | fairseq.trainer | begin training epoch 82
2023-02-10 20:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:35:55 | INFO | train_inner | epoch 082:      3 / 5 loss=8.893, ppl=475.52, wps=479125, ups=0.11, wpb=4.20615e+06, bsz=8215.2, num_updates=400, lr=5.009e-05, gnorm=0.733, loss_scale=1, train_wall=664, gb_free=5.4, wall=3689
2023-02-10 20:36:03 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2023-02-10 20:36:03 | INFO | train | epoch 082 | loss 8.621 | ppl 393.77 | wps 576150 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 402 | lr 5.034e-05 | gnorm 0.96 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3697
2023-02-10 20:36:04 | INFO | fairseq.trainer | begin training epoch 83
2023-02-10 20:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:36:42 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2023-02-10 20:36:42 | INFO | train | epoch 083 | loss 8.591 | ppl 385.55 | wps 546635 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 407 | lr 5.09648e-05 | gnorm 0.82 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3736
2023-02-10 20:36:42 | INFO | fairseq.trainer | begin training epoch 84
2023-02-10 20:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:37:19 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2023-02-10 20:37:19 | INFO | train | epoch 084 | loss 8.561 | ppl 377.65 | wps 568662 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 412 | lr 5.15897e-05 | gnorm 0.608 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3773
2023-02-10 20:37:19 | INFO | fairseq.trainer | begin training epoch 85
2023-02-10 20:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:37:56 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2023-02-10 20:37:56 | INFO | train | epoch 085 | loss 8.533 | ppl 370.51 | wps 560208 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 417 | lr 5.22146e-05 | gnorm 0.567 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3810
2023-02-10 20:37:56 | INFO | fairseq.trainer | begin training epoch 86
2023-02-10 20:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:38:34 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2023-02-10 20:38:34 | INFO | train | epoch 086 | loss 8.506 | ppl 363.67 | wps 565266 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 422 | lr 5.28395e-05 | gnorm 0.508 | loss_scale 1 | train_wall 34 | gb_free 5.6 | wall 3848
2023-02-10 20:38:34 | INFO | fairseq.trainer | begin training epoch 87
2023-02-10 20:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:39:10 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2023-02-10 20:39:10 | INFO | train | epoch 087 | loss 8.496 | ppl 360.99 | wps 573944 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 427 | lr 5.34643e-05 | gnorm 1.203 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3884
2023-02-10 20:39:10 | INFO | fairseq.trainer | begin training epoch 88
2023-02-10 20:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:39:48 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2023-02-10 20:39:48 | INFO | train | epoch 088 | loss 8.468 | ppl 354.05 | wps 557104 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 432 | lr 5.40892e-05 | gnorm 0.922 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3922
2023-02-10 20:39:48 | INFO | fairseq.trainer | begin training epoch 89
2023-02-10 20:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:40:25 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2023-02-10 20:40:25 | INFO | train | epoch 089 | loss 8.439 | ppl 347.1 | wps 570677 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 437 | lr 5.47141e-05 | gnorm 0.671 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 3959
2023-02-10 20:40:25 | INFO | fairseq.trainer | begin training epoch 90
2023-02-10 20:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:41:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:41:05 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 7.526 | ppl 184.26 | wps 0 | wpb 11230 | bsz 22 | num_updates 442 | best_loss 7.526
2023-02-10 20:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 442 updates
2023-02-10 20:41:05 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint90.pt
2023-02-10 20:41:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint90.pt
2023-02-10 20:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint90.pt (epoch 90 @ 442 updates, score 7.526) (writing took 65.30085659897304 seconds)
2023-02-10 20:42:11 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2023-02-10 20:42:11 | INFO | train | epoch 090 | loss 8.417 | ppl 341.7 | wps 198929 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 442 | lr 5.5339e-05 | gnorm 0.666 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4065
2023-02-10 20:42:11 | INFO | fairseq.trainer | begin training epoch 91
2023-02-10 20:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:43:26 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2023-02-10 20:43:26 | INFO | train | epoch 091 | loss 8.396 | ppl 336.9 | wps 279800 | ups 0.07 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 447 | lr 5.59638e-05 | gnorm 0.778 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4140
2023-02-10 20:43:26 | INFO | fairseq.trainer | begin training epoch 92
2023-02-10 20:43:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:44:03 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2023-02-10 20:44:03 | INFO | train | epoch 092 | loss 8.374 | ppl 331.67 | wps 561027 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 452 | lr 5.65887e-05 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4177
2023-02-10 20:44:03 | INFO | fairseq.trainer | begin training epoch 93
2023-02-10 20:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:44:40 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2023-02-10 20:44:40 | INFO | train | epoch 093 | loss 8.352 | ppl 326.8 | wps 564297 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 457 | lr 5.72136e-05 | gnorm 0.541 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4215
2023-02-10 20:44:41 | INFO | fairseq.trainer | begin training epoch 94
2023-02-10 20:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:45:18 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2023-02-10 20:45:18 | INFO | train | epoch 094 | loss 8.332 | ppl 322.28 | wps 561604 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 462 | lr 5.78385e-05 | gnorm 0.543 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4252
2023-02-10 20:45:18 | INFO | fairseq.trainer | begin training epoch 95
2023-02-10 20:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:45:57 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2023-02-10 20:45:57 | INFO | train | epoch 095 | loss 8.312 | ppl 317.87 | wps 543662 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 467 | lr 5.84633e-05 | gnorm 0.527 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4291
2023-02-10 20:45:57 | INFO | fairseq.trainer | begin training epoch 96
2023-02-10 20:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:46:34 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2023-02-10 20:46:34 | INFO | train | epoch 096 | loss 8.292 | ppl 313.32 | wps 568374 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 472 | lr 5.90882e-05 | gnorm 0.51 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4328
2023-02-10 20:46:34 | INFO | fairseq.trainer | begin training epoch 97
2023-02-10 20:46:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:47:11 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2023-02-10 20:47:11 | INFO | train | epoch 097 | loss 8.29 | ppl 313.01 | wps 560494 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 477 | lr 5.97131e-05 | gnorm 1.307 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4365
2023-02-10 20:47:11 | INFO | fairseq.trainer | begin training epoch 98
2023-02-10 20:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:47:48 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2023-02-10 20:47:48 | INFO | train | epoch 098 | loss 8.262 | ppl 307.05 | wps 568070 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 482 | lr 6.0338e-05 | gnorm 0.865 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4402
2023-02-10 20:47:48 | INFO | fairseq.trainer | begin training epoch 99
2023-02-10 20:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:48:25 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2023-02-10 20:48:25 | INFO | train | epoch 099 | loss 8.241 | ppl 302.48 | wps 573273 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 487 | lr 6.09628e-05 | gnorm 0.775 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4439
2023-02-10 20:48:25 | INFO | fairseq.trainer | begin training epoch 100
2023-02-10 20:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:49:06 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 7.348 | ppl 162.89 | wps 0 | wpb 11230 | bsz 22 | num_updates 492 | best_loss 7.348
2023-02-10 20:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 492 updates
2023-02-10 20:49:06 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint100.pt
2023-02-10 20:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint100.pt
2023-02-10 20:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint100.pt (epoch 100 @ 492 updates, score 7.348) (writing took 67.2500521390175 seconds)
2023-02-10 20:50:13 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2023-02-10 20:50:13 | INFO | train | epoch 100 | loss 8.218 | ppl 297.78 | wps 194632 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 492 | lr 6.15877e-05 | gnorm 0.605 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4547
2023-02-10 20:50:13 | INFO | fairseq.trainer | begin training epoch 101
2023-02-10 20:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:50:51 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2023-02-10 20:50:51 | INFO | train | epoch 101 | loss 8.199 | ppl 293.96 | wps 559080 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 497 | lr 6.22126e-05 | gnorm 0.635 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4585
2023-02-10 20:50:51 | INFO | fairseq.trainer | begin training epoch 102
2023-02-10 20:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:51:19 | INFO | train_inner | epoch 102:      3 / 5 loss=8.379, ppl=332.84, wps=455239, ups=0.11, wpb=4.20655e+06, bsz=8216, num_updates=500, lr=6.25875e-05, gnorm=0.72, loss_scale=1, train_wall=664, gb_free=5.4, wall=4613
2023-02-10 20:51:28 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2023-02-10 20:51:28 | INFO | train | epoch 102 | loss 8.18 | ppl 289.92 | wps 568363 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 502 | lr 6.28375e-05 | gnorm 0.613 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4622
2023-02-10 20:51:28 | INFO | fairseq.trainer | begin training epoch 103
2023-02-10 20:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:52:07 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2023-02-10 20:52:07 | INFO | train | epoch 103 | loss 8.163 | ppl 286.59 | wps 539500 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 507 | lr 6.34623e-05 | gnorm 0.805 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4661
2023-02-10 20:52:07 | INFO | fairseq.trainer | begin training epoch 104
2023-02-10 20:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:52:44 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2023-02-10 20:52:44 | INFO | train | epoch 104 | loss 8.144 | ppl 282.95 | wps 561885 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 512 | lr 6.40872e-05 | gnorm 0.813 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4698
2023-02-10 20:52:44 | INFO | fairseq.trainer | begin training epoch 105
2023-02-10 20:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:53:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-10 20:53:22 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2023-02-10 20:53:22 | INFO | train | epoch 105 | loss 8.128 | ppl 279.74 | wps 419367 | ups 0.11 | wpb 3.97306e+06 | bsz 7760 | num_updates 516 | lr 6.45871e-05 | gnorm 0.968 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 4736
2023-02-10 20:53:22 | INFO | fairseq.trainer | begin training epoch 106
2023-02-10 20:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-10 20:54:01 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2023-02-10 20:54:01 | INFO | train | epoch 106 | loss 8.12 | ppl 278.3 | wps 405591 | ups 0.1 | wpb 3.9529e+06 | bsz 7720.5 | num_updates 520 | lr 6.5087e-05 | gnorm 1.203 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 4775
2023-02-10 20:54:01 | INFO | fairseq.trainer | begin training epoch 107
2023-02-10 20:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:54:38 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2023-02-10 20:54:38 | INFO | train | epoch 107 | loss 8.099 | ppl 274.28 | wps 570397 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 525 | lr 6.57119e-05 | gnorm 1.058 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 4812
2023-02-10 20:54:38 | INFO | fairseq.trainer | begin training epoch 108
2023-02-10 20:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:55:16 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2023-02-10 20:55:16 | INFO | train | epoch 108 | loss 8.076 | ppl 269.91 | wps 551000 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 530 | lr 6.63368e-05 | gnorm 0.785 | loss_scale 0.5 | train_wall 33 | gb_free 36.9 | wall 4850
2023-02-10 20:55:16 | INFO | fairseq.trainer | begin training epoch 109
2023-02-10 20:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:55:53 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2023-02-10 20:55:53 | INFO | train | epoch 109 | loss 8.057 | ppl 266.25 | wps 562736 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 535 | lr 6.69616e-05 | gnorm 0.671 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 4887
2023-02-10 20:55:53 | INFO | fairseq.trainer | begin training epoch 110
2023-02-10 20:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 20:56:35 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 7.176 | ppl 144.64 | wps 0 | wpb 11230 | bsz 22 | num_updates 540 | best_loss 7.176
2023-02-10 20:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 540 updates
2023-02-10 20:56:35 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint110.pt
2023-02-10 20:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint110.pt
2023-02-10 20:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint110.pt (epoch 110 @ 540 updates, score 7.176) (writing took 60.206066180981 seconds)
2023-02-10 20:57:36 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2023-02-10 20:57:36 | INFO | train | epoch 110 | loss 8.036 | ppl 262.39 | wps 205660 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 540 | lr 6.75865e-05 | gnorm 0.565 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 4990
2023-02-10 20:57:36 | INFO | fairseq.trainer | begin training epoch 111
2023-02-10 20:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:58:14 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2023-02-10 20:58:14 | INFO | train | epoch 111 | loss 8.02 | ppl 259.64 | wps 545923 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 545 | lr 6.82114e-05 | gnorm 0.796 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5028
2023-02-10 20:58:14 | INFO | fairseq.trainer | begin training epoch 112
2023-02-10 20:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:58:52 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2023-02-10 20:58:52 | INFO | train | epoch 112 | loss 8.005 | ppl 256.86 | wps 560189 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 550 | lr 6.88363e-05 | gnorm 1.115 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5066
2023-02-10 20:58:52 | INFO | fairseq.trainer | begin training epoch 113
2023-02-10 20:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 20:59:30 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2023-02-10 20:59:30 | INFO | train | epoch 113 | loss 7.988 | ppl 253.82 | wps 555830 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 555 | lr 6.94611e-05 | gnorm 0.896 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5104
2023-02-10 20:59:30 | INFO | fairseq.trainer | begin training epoch 114
2023-02-10 20:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:00:09 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2023-02-10 21:00:09 | INFO | train | epoch 114 | loss 7.963 | ppl 249.45 | wps 538791 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 560 | lr 7.0086e-05 | gnorm 0.538 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5143
2023-02-10 21:00:09 | INFO | fairseq.trainer | begin training epoch 115
2023-02-10 21:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:00:46 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2023-02-10 21:00:46 | INFO | train | epoch 115 | loss 7.947 | ppl 246.74 | wps 569140 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 565 | lr 7.07109e-05 | gnorm 0.734 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5180
2023-02-10 21:00:46 | INFO | fairseq.trainer | begin training epoch 116
2023-02-10 21:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:01:24 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2023-02-10 21:01:24 | INFO | train | epoch 116 | loss 7.928 | ppl 243.6 | wps 551280 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 570 | lr 7.13358e-05 | gnorm 0.67 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5218
2023-02-10 21:01:24 | INFO | fairseq.trainer | begin training epoch 117
2023-02-10 21:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:02:01 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2023-02-10 21:02:01 | INFO | train | epoch 117 | loss 7.909 | ppl 240.4 | wps 566585 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 575 | lr 7.19606e-05 | gnorm 0.547 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5255
2023-02-10 21:02:01 | INFO | fairseq.trainer | begin training epoch 118
2023-02-10 21:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:02:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2023-02-10 21:02:38 | INFO | train | epoch 118 | loss 7.906 | ppl 239.82 | wps 571454 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 580 | lr 7.25855e-05 | gnorm 1.16 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5292
2023-02-10 21:02:38 | INFO | fairseq.trainer | begin training epoch 119
2023-02-10 21:02:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:03:17 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2023-02-10 21:03:17 | INFO | train | epoch 119 | loss 7.882 | ppl 235.85 | wps 531526 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 585 | lr 7.32104e-05 | gnorm 0.756 | loss_scale 0.5 | train_wall 33 | gb_free 13.6 | wall 5331
2023-02-10 21:03:17 | INFO | fairseq.trainer | begin training epoch 120
2023-02-10 21:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:03:59 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 7.039 | ppl 131.48 | wps 0 | wpb 11230 | bsz 22 | num_updates 590 | best_loss 7.039
2023-02-10 21:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 590 updates
2023-02-10 21:03:59 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint120.pt
2023-02-10 21:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint120.pt
2023-02-10 21:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint120.pt (epoch 120 @ 590 updates, score 7.039) (writing took 66.1215921129915 seconds)
2023-02-10 21:05:05 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2023-02-10 21:05:05 | INFO | train | epoch 120 | loss 7.861 | ppl 232.49 | wps 195520 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 590 | lr 7.38353e-05 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5439
2023-02-10 21:05:05 | INFO | fairseq.trainer | begin training epoch 121
2023-02-10 21:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:05:42 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2023-02-10 21:05:42 | INFO | train | epoch 121 | loss 7.844 | ppl 229.76 | wps 567436 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 595 | lr 7.44601e-05 | gnorm 0.547 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5476
2023-02-10 21:05:42 | INFO | fairseq.trainer | begin training epoch 122
2023-02-10 21:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:06:21 | INFO | train_inner | epoch 122:      5 / 5 loss=7.995, ppl=255.04, wps=460788, ups=0.11, wpb=4.15718e+06, bsz=8119.6, num_updates=600, lr=7.5085e-05, gnorm=0.797, loss_scale=0.5, train_wall=672, gb_free=5.6, wall=5515
2023-02-10 21:06:21 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2023-02-10 21:06:21 | INFO | train | epoch 122 | loss 7.834 | ppl 228.13 | wps 540549 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 600 | lr 7.5085e-05 | gnorm 0.932 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5515
2023-02-10 21:06:21 | INFO | fairseq.trainer | begin training epoch 123
2023-02-10 21:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:06:59 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2023-02-10 21:06:59 | INFO | train | epoch 123 | loss 7.815 | ppl 225.15 | wps 547543 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 605 | lr 7.57099e-05 | gnorm 0.632 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5553
2023-02-10 21:06:59 | INFO | fairseq.trainer | begin training epoch 124
2023-02-10 21:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:07:37 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2023-02-10 21:07:37 | INFO | train | epoch 124 | loss 7.799 | ppl 222.74 | wps 560420 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 610 | lr 7.63348e-05 | gnorm 0.757 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5591
2023-02-10 21:07:37 | INFO | fairseq.trainer | begin training epoch 125
2023-02-10 21:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:08:14 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2023-02-10 21:08:14 | INFO | train | epoch 125 | loss 7.785 | ppl 220.6 | wps 564600 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 615 | lr 7.69596e-05 | gnorm 0.679 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5628
2023-02-10 21:08:14 | INFO | fairseq.trainer | begin training epoch 126
2023-02-10 21:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:08:51 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2023-02-10 21:08:51 | INFO | train | epoch 126 | loss 7.769 | ppl 218.16 | wps 567474 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 620 | lr 7.75845e-05 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5665
2023-02-10 21:08:51 | INFO | fairseq.trainer | begin training epoch 127
2023-02-10 21:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:09:29 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2023-02-10 21:09:29 | INFO | train | epoch 127 | loss 7.754 | ppl 215.84 | wps 560181 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 625 | lr 7.82094e-05 | gnorm 0.602 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5703
2023-02-10 21:09:29 | INFO | fairseq.trainer | begin training epoch 128
2023-02-10 21:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:10:05 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2023-02-10 21:10:05 | INFO | train | epoch 128 | loss 7.756 | ppl 216.21 | wps 583752 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 630 | lr 7.88343e-05 | gnorm 1.252 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5739
2023-02-10 21:10:05 | INFO | fairseq.trainer | begin training epoch 129
2023-02-10 21:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:10:43 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2023-02-10 21:10:43 | INFO | train | epoch 129 | loss 7.753 | ppl 215.69 | wps 548155 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 635 | lr 7.94591e-05 | gnorm 1.291 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5777
2023-02-10 21:10:43 | INFO | fairseq.trainer | begin training epoch 130
2023-02-10 21:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:11:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:11:23 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 6.988 | ppl 126.93 | wps 0 | wpb 11230 | bsz 22 | num_updates 640 | best_loss 6.988
2023-02-10 21:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 640 updates
2023-02-10 21:11:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint130.pt
2023-02-10 21:11:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint130.pt
2023-02-10 21:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint130.pt (epoch 130 @ 640 updates, score 6.988) (writing took 64.81140457600122 seconds)
2023-02-10 21:12:28 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2023-02-10 21:12:28 | INFO | train | epoch 130 | loss 7.727 | ppl 211.83 | wps 200071 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 640 | lr 8.0084e-05 | gnorm 0.828 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5882
2023-02-10 21:12:28 | INFO | fairseq.trainer | begin training epoch 131
2023-02-10 21:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:13:06 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2023-02-10 21:13:06 | INFO | train | epoch 131 | loss 7.71 | ppl 209.41 | wps 562288 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 645 | lr 8.07089e-05 | gnorm 0.723 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5920
2023-02-10 21:13:06 | INFO | fairseq.trainer | begin training epoch 132
2023-02-10 21:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:13:45 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2023-02-10 21:13:45 | INFO | train | epoch 132 | loss 7.693 | ppl 207 | wps 539639 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 650 | lr 8.13338e-05 | gnorm 0.553 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5959
2023-02-10 21:13:45 | INFO | fairseq.trainer | begin training epoch 133
2023-02-10 21:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:14:22 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2023-02-10 21:14:22 | INFO | train | epoch 133 | loss 7.68 | ppl 205.14 | wps 562851 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 655 | lr 8.19586e-05 | gnorm 0.513 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 5996
2023-02-10 21:14:22 | INFO | fairseq.trainer | begin training epoch 134
2023-02-10 21:14:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:14:59 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2023-02-10 21:14:59 | INFO | train | epoch 134 | loss 7.667 | ppl 203.21 | wps 565040 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 660 | lr 8.25835e-05 | gnorm 0.501 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6033
2023-02-10 21:14:59 | INFO | fairseq.trainer | begin training epoch 135
2023-02-10 21:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:15:39 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2023-02-10 21:15:39 | INFO | train | epoch 135 | loss 7.654 | ppl 201.47 | wps 526380 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 665 | lr 8.32084e-05 | gnorm 0.544 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6073
2023-02-10 21:15:39 | INFO | fairseq.trainer | begin training epoch 136
2023-02-10 21:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:16:16 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2023-02-10 21:16:16 | INFO | train | epoch 136 | loss 7.645 | ppl 200.1 | wps 563816 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 670 | lr 8.38333e-05 | gnorm 0.674 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6110
2023-02-10 21:16:17 | INFO | fairseq.trainer | begin training epoch 137
2023-02-10 21:16:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:16:54 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2023-02-10 21:16:54 | INFO | train | epoch 137 | loss 7.647 | ppl 200.39 | wps 560579 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 675 | lr 8.44581e-05 | gnorm 1.256 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6148
2023-02-10 21:16:54 | INFO | fairseq.trainer | begin training epoch 138
2023-02-10 21:16:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:17:33 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2023-02-10 21:17:33 | INFO | train | epoch 138 | loss 7.635 | ppl 198.77 | wps 538193 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 680 | lr 8.5083e-05 | gnorm 0.901 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6187
2023-02-10 21:17:33 | INFO | fairseq.trainer | begin training epoch 139
2023-02-10 21:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:18:11 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2023-02-10 21:18:11 | INFO | train | epoch 139 | loss 7.617 | ppl 196.35 | wps 558556 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 685 | lr 8.57079e-05 | gnorm 0.676 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6225
2023-02-10 21:18:11 | INFO | fairseq.trainer | begin training epoch 140
2023-02-10 21:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:18:53 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 6.864 | ppl 116.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 690 | best_loss 6.864
2023-02-10 21:18:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 690 updates
2023-02-10 21:18:53 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint140.pt
2023-02-10 21:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint140.pt
2023-02-10 21:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint140.pt (epoch 140 @ 690 updates, score 6.864) (writing took 61.49084066701471 seconds)
2023-02-10 21:19:55 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2023-02-10 21:19:55 | INFO | train | epoch 140 | loss 7.603 | ppl 194.44 | wps 202386 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 690 | lr 8.63328e-05 | gnorm 0.527 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6329
2023-02-10 21:19:55 | INFO | fairseq.trainer | begin training epoch 141
2023-02-10 21:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:20:33 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2023-02-10 21:20:33 | INFO | train | epoch 141 | loss 7.591 | ppl 192.87 | wps 549333 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 695 | lr 8.69576e-05 | gnorm 0.52 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6367
2023-02-10 21:20:33 | INFO | fairseq.trainer | begin training epoch 142
2023-02-10 21:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:21:10 | INFO | train_inner | epoch 142:      5 / 5 loss=7.694, ppl=207.1, wps=472948, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=700, lr=8.75825e-05, gnorm=0.732, loss_scale=0.5, train_wall=663, gb_free=5.6, wall=6404
2023-02-10 21:21:10 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2023-02-10 21:21:10 | INFO | train | epoch 142 | loss 7.582 | ppl 191.55 | wps 562905 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 700 | lr 8.75825e-05 | gnorm 0.633 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6404
2023-02-10 21:21:10 | INFO | fairseq.trainer | begin training epoch 143
2023-02-10 21:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:21:49 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2023-02-10 21:21:49 | INFO | train | epoch 143 | loss 7.588 | ppl 192.37 | wps 536316 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 705 | lr 8.82074e-05 | gnorm 1.207 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6443
2023-02-10 21:21:50 | INFO | fairseq.trainer | begin training epoch 144
2023-02-10 21:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:22:27 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2023-02-10 21:22:27 | INFO | train | epoch 144 | loss 7.576 | ppl 190.79 | wps 562082 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 710 | lr 8.88323e-05 | gnorm 0.944 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6481
2023-02-10 21:22:27 | INFO | fairseq.trainer | begin training epoch 145
2023-02-10 21:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:23:05 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2023-02-10 21:23:05 | INFO | train | epoch 145 | loss 7.559 | ppl 188.54 | wps 550269 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 715 | lr 8.94571e-05 | gnorm 0.728 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6519
2023-02-10 21:23:05 | INFO | fairseq.trainer | begin training epoch 146
2023-02-10 21:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:23:45 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2023-02-10 21:23:45 | INFO | train | epoch 146 | loss 7.545 | ppl 186.72 | wps 532416 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 720 | lr 9.0082e-05 | gnorm 0.606 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6559
2023-02-10 21:23:45 | INFO | fairseq.trainer | begin training epoch 147
2023-02-10 21:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:24:22 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2023-02-10 21:24:22 | INFO | train | epoch 147 | loss 7.534 | ppl 185.32 | wps 569018 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 725 | lr 9.07069e-05 | gnorm 0.581 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6596
2023-02-10 21:24:22 | INFO | fairseq.trainer | begin training epoch 148
2023-02-10 21:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:25:00 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2023-02-10 21:25:00 | INFO | train | epoch 148 | loss 7.522 | ppl 183.8 | wps 544402 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 730 | lr 9.13318e-05 | gnorm 0.517 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6634
2023-02-10 21:25:00 | INFO | fairseq.trainer | begin training epoch 149
2023-02-10 21:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:25:37 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2023-02-10 21:25:37 | INFO | train | epoch 149 | loss 7.512 | ppl 182.51 | wps 578911 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 735 | lr 9.19566e-05 | gnorm 0.542 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6671
2023-02-10 21:25:37 | INFO | fairseq.trainer | begin training epoch 150
2023-02-10 21:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:26:19 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 6.807 | ppl 111.96 | wps 0 | wpb 11230 | bsz 22 | num_updates 740 | best_loss 6.807
2023-02-10 21:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 740 updates
2023-02-10 21:26:19 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint150.pt
2023-02-10 21:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint150.pt
2023-02-10 21:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint150.pt (epoch 150 @ 740 updates, score 6.807) (writing took 67.2345716439886 seconds)
2023-02-10 21:27:26 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2023-02-10 21:27:26 | INFO | train | epoch 150 | loss 7.527 | ppl 184.42 | wps 191394 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 740 | lr 9.25815e-05 | gnorm 1.196 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6780
2023-02-10 21:27:27 | INFO | fairseq.trainer | begin training epoch 151
2023-02-10 21:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:28:05 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2023-02-10 21:28:05 | INFO | train | epoch 151 | loss 7.516 | ppl 183.05 | wps 545051 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 745 | lr 9.32064e-05 | gnorm 1.124 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6819
2023-02-10 21:28:05 | INFO | fairseq.trainer | begin training epoch 152
2023-02-10 21:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:28:43 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2023-02-10 21:28:43 | INFO | train | epoch 152 | loss 7.495 | ppl 180.44 | wps 560889 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 750 | lr 9.38313e-05 | gnorm 0.7 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6857
2023-02-10 21:28:43 | INFO | fairseq.trainer | begin training epoch 153
2023-02-10 21:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:29:20 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2023-02-10 21:29:20 | INFO | train | epoch 153 | loss 7.482 | ppl 178.76 | wps 557401 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 755 | lr 9.44561e-05 | gnorm 0.529 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6894
2023-02-10 21:29:20 | INFO | fairseq.trainer | begin training epoch 154
2023-02-10 21:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:29:59 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2023-02-10 21:29:59 | INFO | train | epoch 154 | loss 7.47 | ppl 177.29 | wps 536952 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 760 | lr 9.5081e-05 | gnorm 0.429 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6933
2023-02-10 21:30:00 | INFO | fairseq.trainer | begin training epoch 155
2023-02-10 21:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:30:37 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2023-02-10 21:30:37 | INFO | train | epoch 155 | loss 7.459 | ppl 175.95 | wps 564168 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 765 | lr 9.57059e-05 | gnorm 0.384 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 6971
2023-02-10 21:30:37 | INFO | fairseq.trainer | begin training epoch 156
2023-02-10 21:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:31:14 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2023-02-10 21:31:14 | INFO | train | epoch 156 | loss 7.464 | ppl 176.57 | wps 568339 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 770 | lr 9.63308e-05 | gnorm 0.982 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 7008
2023-02-10 21:31:14 | INFO | fairseq.trainer | begin training epoch 157
2023-02-10 21:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:31:50 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2023-02-10 21:31:50 | INFO | train | epoch 157 | loss 7.461 | ppl 176.21 | wps 575006 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 775 | lr 9.69556e-05 | gnorm 1.061 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 7044
2023-02-10 21:31:50 | INFO | fairseq.trainer | begin training epoch 158
2023-02-10 21:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:32:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-10 21:32:27 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2023-02-10 21:32:27 | INFO | train | epoch 158 | loss 7.459 | ppl 175.96 | wps 425287 | ups 0.11 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 779 | lr 9.74555e-05 | gnorm 1.127 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 7082
2023-02-10 21:32:28 | INFO | fairseq.trainer | begin training epoch 159
2023-02-10 21:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-02-10 21:33:07 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2023-02-10 21:33:07 | INFO | train | epoch 159 | loss 7.458 | ppl 175.8 | wps 397068 | ups 0.1 | wpb 3.94778e+06 | bsz 7710.5 | num_updates 783 | lr 9.79554e-05 | gnorm 1.259 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7121
2023-02-10 21:33:07 | INFO | fairseq.trainer | begin training epoch 160
2023-02-10 21:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:33:48 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 6.716 | ppl 105.12 | wps 0 | wpb 11230 | bsz 22 | num_updates 788 | best_loss 6.716
2023-02-10 21:33:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 788 updates
2023-02-10 21:33:48 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint160.pt
2023-02-10 21:33:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint160.pt
2023-02-10 21:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint160.pt (epoch 160 @ 788 updates, score 6.716) (writing took 66.95269776301575 seconds)
2023-02-10 21:34:55 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2023-02-10 21:34:55 | INFO | train | epoch 160 | loss 7.44 | ppl 173.69 | wps 195495 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 788 | lr 9.85803e-05 | gnorm 0.8 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7229
2023-02-10 21:34:55 | INFO | fairseq.trainer | begin training epoch 161
2023-02-10 21:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:35:33 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2023-02-10 21:35:33 | INFO | train | epoch 161 | loss 7.426 | ppl 171.92 | wps 557243 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 793 | lr 9.92052e-05 | gnorm 0.547 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7267
2023-02-10 21:35:33 | INFO | fairseq.trainer | begin training epoch 162
2023-02-10 21:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:36:12 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2023-02-10 21:36:12 | INFO | train | epoch 162 | loss 7.413 | ppl 170.37 | wps 534358 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 798 | lr 9.98301e-05 | gnorm 0.442 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7306
2023-02-10 21:36:12 | INFO | fairseq.trainer | begin training epoch 163
2023-02-10 21:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:36:33 | INFO | train_inner | epoch 163:      2 / 5 loss=7.494, ppl=180.26, wps=456006, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=800, lr=0.00010008, gnorm=0.771, loss_scale=0.25, train_wall=678, gb_free=5.4, wall=7327
2023-02-10 21:36:50 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2023-02-10 21:36:50 | INFO | train | epoch 163 | loss 7.405 | ppl 169.45 | wps 555736 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 803 | lr 0.000100455 | gnorm 0.587 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7344
2023-02-10 21:36:50 | INFO | fairseq.trainer | begin training epoch 164
2023-02-10 21:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:37:29 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2023-02-10 21:37:29 | INFO | train | epoch 164 | loss 7.403 | ppl 169.29 | wps 542016 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 808 | lr 0.00010108 | gnorm 0.823 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7383
2023-02-10 21:37:29 | INFO | fairseq.trainer | begin training epoch 165
2023-02-10 21:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:38:09 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2023-02-10 21:38:09 | INFO | train | epoch 165 | loss 7.388 | ppl 167.54 | wps 522322 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 813 | lr 0.000101705 | gnorm 0.511 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7423
2023-02-10 21:38:09 | INFO | fairseq.trainer | begin training epoch 166
2023-02-10 21:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:38:46 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2023-02-10 21:38:46 | INFO | train | epoch 166 | loss 7.379 | ppl 166.51 | wps 570713 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 818 | lr 0.00010233 | gnorm 0.511 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7460
2023-02-10 21:38:46 | INFO | fairseq.trainer | begin training epoch 167
2023-02-10 21:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:39:24 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2023-02-10 21:39:24 | INFO | train | epoch 167 | loss 7.372 | ppl 165.69 | wps 544254 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 823 | lr 0.000102954 | gnorm 0.58 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7498
2023-02-10 21:39:24 | INFO | fairseq.trainer | begin training epoch 168
2023-02-10 21:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:40:02 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2023-02-10 21:40:02 | INFO | train | epoch 168 | loss 7.363 | ppl 164.64 | wps 553569 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 828 | lr 0.000103579 | gnorm 0.508 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7536
2023-02-10 21:40:03 | INFO | fairseq.trainer | begin training epoch 169
2023-02-10 21:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:40:40 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2023-02-10 21:40:40 | INFO | train | epoch 169 | loss 7.367 | ppl 165.03 | wps 554613 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 833 | lr 0.000104204 | gnorm 0.886 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7574
2023-02-10 21:40:40 | INFO | fairseq.trainer | begin training epoch 170
2023-02-10 21:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:41:23 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 6.648 | ppl 100.29 | wps 0 | wpb 11230 | bsz 22 | num_updates 838 | best_loss 6.648
2023-02-10 21:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 838 updates
2023-02-10 21:41:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint170.pt
2023-02-10 21:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint170.pt
2023-02-10 21:42:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint170.pt (epoch 170 @ 838 updates, score 6.648) (writing took 60.88128044598852 seconds)
2023-02-10 21:42:24 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2023-02-10 21:42:24 | INFO | train | epoch 170 | loss 7.368 | ppl 165.13 | wps 203455 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 838 | lr 0.000104829 | gnorm 1.172 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7678
2023-02-10 21:42:24 | INFO | fairseq.trainer | begin training epoch 171
2023-02-10 21:42:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:43:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2023-02-10 21:43:01 | INFO | train | epoch 171 | loss 7.365 | ppl 164.84 | wps 556614 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 843 | lr 0.000105454 | gnorm 1.029 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7716
2023-02-10 21:43:02 | INFO | fairseq.trainer | begin training epoch 172
2023-02-10 21:43:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:43:39 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2023-02-10 21:43:39 | INFO | train | epoch 172 | loss 7.348 | ppl 162.89 | wps 556214 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 848 | lr 0.000106079 | gnorm 0.755 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7753
2023-02-10 21:43:39 | INFO | fairseq.trainer | begin training epoch 173
2023-02-10 21:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:44:19 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2023-02-10 21:44:19 | INFO | train | epoch 173 | loss 7.337 | ppl 161.64 | wps 523868 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 853 | lr 0.000106704 | gnorm 0.627 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7793
2023-02-10 21:44:20 | INFO | fairseq.trainer | begin training epoch 174
2023-02-10 21:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:44:57 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2023-02-10 21:44:57 | INFO | train | epoch 174 | loss 7.325 | ppl 160.32 | wps 558608 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 858 | lr 0.000107329 | gnorm 0.468 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7831
2023-02-10 21:44:57 | INFO | fairseq.trainer | begin training epoch 175
2023-02-10 21:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:45:36 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2023-02-10 21:45:36 | INFO | train | epoch 175 | loss 7.319 | ppl 159.7 | wps 537165 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 863 | lr 0.000107953 | gnorm 0.576 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7870
2023-02-10 21:45:36 | INFO | fairseq.trainer | begin training epoch 176
2023-02-10 21:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:46:17 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2023-02-10 21:46:17 | INFO | train | epoch 176 | loss 7.31 | ppl 158.71 | wps 522762 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 868 | lr 0.000108578 | gnorm 0.594 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7911
2023-02-10 21:46:17 | INFO | fairseq.trainer | begin training epoch 177
2023-02-10 21:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:46:54 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2023-02-10 21:46:54 | INFO | train | epoch 177 | loss 7.312 | ppl 158.9 | wps 560120 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 873 | lr 0.000109203 | gnorm 0.861 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7948
2023-02-10 21:46:54 | INFO | fairseq.trainer | begin training epoch 178
2023-02-10 21:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:47:33 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2023-02-10 21:47:33 | INFO | train | epoch 178 | loss 7.303 | ppl 157.96 | wps 536732 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 878 | lr 0.000109828 | gnorm 0.718 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 7987
2023-02-10 21:47:33 | INFO | fairseq.trainer | begin training epoch 179
2023-02-10 21:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:48:11 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2023-02-10 21:48:11 | INFO | train | epoch 179 | loss 7.303 | ppl 157.91 | wps 552324 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 883 | lr 0.000110453 | gnorm 0.88 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8025
2023-02-10 21:48:11 | INFO | fairseq.trainer | begin training epoch 180
2023-02-10 21:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:48:56 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 6.681 | ppl 102.62 | wps 0 | wpb 11230 | bsz 22 | num_updates 888 | best_loss 6.648
2023-02-10 21:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 888 updates
2023-02-10 21:48:56 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint180.pt
2023-02-10 21:49:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint180.pt
2023-02-10 21:49:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint180.pt (epoch 180 @ 888 updates, score 6.681) (writing took 57.90675678598927 seconds)
2023-02-10 21:49:54 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2023-02-10 21:49:54 | INFO | train | epoch 180 | loss 7.287 | ppl 156.2 | wps 205456 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 888 | lr 0.000111078 | gnorm 0.635 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8128
2023-02-10 21:49:54 | INFO | fairseq.trainer | begin training epoch 181
2023-02-10 21:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:50:33 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2023-02-10 21:50:33 | INFO | train | epoch 181 | loss 7.28 | ppl 155.47 | wps 536888 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 893 | lr 0.000111703 | gnorm 0.62 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8167
2023-02-10 21:50:33 | INFO | fairseq.trainer | begin training epoch 182
2023-02-10 21:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:51:11 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2023-02-10 21:51:11 | INFO | train | epoch 182 | loss 7.279 | ppl 155.27 | wps 552587 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 898 | lr 0.000112328 | gnorm 0.788 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8205
2023-02-10 21:51:11 | INFO | fairseq.trainer | begin training epoch 183
2023-02-10 21:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:51:33 | INFO | train_inner | epoch 183:      2 / 5 loss=7.337, ppl=161.72, wps=467459, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=900, lr=0.000112578, gnorm=0.711, loss_scale=0.25, train_wall=663, gb_free=5.4, wall=8227
2023-02-10 21:51:50 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2023-02-10 21:51:50 | INFO | train | epoch 183 | loss 7.267 | ppl 154 | wps 543639 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 903 | lr 0.000112952 | gnorm 0.609 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8244
2023-02-10 21:51:50 | INFO | fairseq.trainer | begin training epoch 184
2023-02-10 21:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:52:30 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2023-02-10 21:52:30 | INFO | train | epoch 184 | loss 7.258 | ppl 153.05 | wps 521070 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 908 | lr 0.000113577 | gnorm 0.554 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8284
2023-02-10 21:52:30 | INFO | fairseq.trainer | begin training epoch 185
2023-02-10 21:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:53:07 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2023-02-10 21:53:07 | INFO | train | epoch 185 | loss 7.257 | ppl 152.96 | wps 568282 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 913 | lr 0.000114202 | gnorm 0.74 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8321
2023-02-10 21:53:07 | INFO | fairseq.trainer | begin training epoch 186
2023-02-10 21:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:53:45 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2023-02-10 21:53:45 | INFO | train | epoch 186 | loss 7.252 | ppl 152.47 | wps 557680 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 918 | lr 0.000114827 | gnorm 0.806 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8359
2023-02-10 21:53:45 | INFO | fairseq.trainer | begin training epoch 187
2023-02-10 21:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:54:23 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2023-02-10 21:54:23 | INFO | train | epoch 187 | loss 7.244 | ppl 151.6 | wps 542804 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 923 | lr 0.000115452 | gnorm 0.731 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8398
2023-02-10 21:54:24 | INFO | fairseq.trainer | begin training epoch 188
2023-02-10 21:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:55:01 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2023-02-10 21:55:01 | INFO | train | epoch 188 | loss 7.241 | ppl 151.28 | wps 558481 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 928 | lr 0.000116077 | gnorm 0.79 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8435
2023-02-10 21:55:01 | INFO | fairseq.trainer | begin training epoch 189
2023-02-10 21:55:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:55:41 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2023-02-10 21:55:41 | INFO | train | epoch 189 | loss 7.23 | ppl 150.12 | wps 525151 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 933 | lr 0.000116702 | gnorm 0.631 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8475
2023-02-10 21:55:41 | INFO | fairseq.trainer | begin training epoch 190
2023-02-10 21:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 21:56:23 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 6.586 | ppl 96.1 | wps 0 | wpb 11230 | bsz 22 | num_updates 938 | best_loss 6.586
2023-02-10 21:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 938 updates
2023-02-10 21:56:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint190.pt
2023-02-10 21:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint190.pt
2023-02-10 21:57:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint190.pt (epoch 190 @ 938 updates, score 6.586) (writing took 64.16937883000355 seconds)
2023-02-10 21:57:27 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2023-02-10 21:57:27 | INFO | train | epoch 190 | loss 7.22 | ppl 149.05 | wps 197928 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 938 | lr 0.000117327 | gnorm 0.47 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8582
2023-02-10 21:57:28 | INFO | fairseq.trainer | begin training epoch 191
2023-02-10 21:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:58:05 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2023-02-10 21:58:05 | INFO | train | epoch 191 | loss 7.213 | ppl 148.34 | wps 557189 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 943 | lr 0.000117951 | gnorm 0.572 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8619
2023-02-10 21:58:05 | INFO | fairseq.trainer | begin training epoch 192
2023-02-10 21:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:58:46 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2023-02-10 21:58:46 | INFO | train | epoch 192 | loss 7.239 | ppl 151.06 | wps 520517 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 948 | lr 0.000118576 | gnorm 1.176 | loss_scale 0.25 | train_wall 33 | gb_free 36.9 | wall 8660
2023-02-10 21:58:46 | INFO | fairseq.trainer | begin training epoch 193
2023-02-10 21:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 21:59:24 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2023-02-10 21:59:24 | INFO | train | epoch 193 | loss 7.222 | ppl 149.3 | wps 552731 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 953 | lr 0.000119201 | gnorm 0.727 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8698
2023-02-10 21:59:24 | INFO | fairseq.trainer | begin training epoch 194
2023-02-10 21:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:00:02 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2023-02-10 22:00:02 | INFO | train | epoch 194 | loss 7.209 | ppl 147.99 | wps 555903 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 958 | lr 0.000119826 | gnorm 0.652 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8736
2023-02-10 22:00:02 | INFO | fairseq.trainer | begin training epoch 195
2023-02-10 22:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:00:43 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2023-02-10 22:00:43 | INFO | train | epoch 195 | loss 7.197 | ppl 146.68 | wps 509938 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 963 | lr 0.000120451 | gnorm 0.533 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8777
2023-02-10 22:00:43 | INFO | fairseq.trainer | begin training epoch 196
2023-02-10 22:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:01:21 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2023-02-10 22:01:21 | INFO | train | epoch 196 | loss 7.192 | ppl 146.23 | wps 553952 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 968 | lr 0.000121076 | gnorm 0.714 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8815
2023-02-10 22:01:21 | INFO | fairseq.trainer | begin training epoch 197
2023-02-10 22:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:02:02 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2023-02-10 22:02:02 | INFO | train | epoch 197 | loss 7.183 | ppl 145.35 | wps 504177 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 973 | lr 0.000121701 | gnorm 0.611 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8857
2023-02-10 22:02:03 | INFO | fairseq.trainer | begin training epoch 198
2023-02-10 22:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:02:43 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2023-02-10 22:02:43 | INFO | train | epoch 198 | loss 7.176 | ppl 144.6 | wps 518044 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 978 | lr 0.000122326 | gnorm 0.585 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8897
2023-02-10 22:02:43 | INFO | fairseq.trainer | begin training epoch 199
2023-02-10 22:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:03:20 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2023-02-10 22:03:20 | INFO | train | epoch 199 | loss 7.178 | ppl 144.77 | wps 575962 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 983 | lr 0.00012295 | gnorm 0.871 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 8934
2023-02-10 22:03:20 | INFO | fairseq.trainer | begin training epoch 200
2023-02-10 22:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:04:04 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 6.528 | ppl 92.3 | wps 0 | wpb 11230 | bsz 22 | num_updates 988 | best_loss 6.528
2023-02-10 22:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 988 updates
2023-02-10 22:04:04 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint200.pt
2023-02-10 22:04:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint200.pt
2023-02-10 22:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint200.pt (epoch 200 @ 988 updates, score 6.528) (writing took 59.981680461991346 seconds)
2023-02-10 22:05:04 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2023-02-10 22:05:04 | INFO | train | epoch 200 | loss 7.168 | ppl 143.84 | wps 201147 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 988 | lr 0.000123575 | gnorm 0.672 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9038
2023-02-10 22:05:04 | INFO | fairseq.trainer | begin training epoch 201
2023-02-10 22:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:05:45 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2023-02-10 22:05:45 | INFO | train | epoch 201 | loss 7.162 | ppl 143.22 | wps 512850 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 993 | lr 0.0001242 | gnorm 0.73 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9079
2023-02-10 22:05:45 | INFO | fairseq.trainer | begin training epoch 202
2023-02-10 22:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:06:24 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2023-02-10 22:06:24 | INFO | train | epoch 202 | loss 7.159 | ppl 142.89 | wps 546488 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 998 | lr 0.000124825 | gnorm 0.845 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9118
2023-02-10 22:06:24 | INFO | fairseq.trainer | begin training epoch 203
2023-02-10 22:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:06:46 | INFO | train_inner | epoch 203:      2 / 5 loss=7.211, ppl=148.11, wps=460333, ups=0.11, wpb=4.20655e+06, bsz=8216, num_updates=1000, lr=0.000125075, gnorm=0.705, loss_scale=0.25, train_wall=663, gb_free=5.4, wall=9141
2023-02-10 22:07:04 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2023-02-10 22:07:04 | INFO | train | epoch 203 | loss 7.157 | ppl 142.71 | wps 527079 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1003 | lr 0.00012545 | gnorm 0.829 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9158
2023-02-10 22:07:04 | INFO | fairseq.trainer | begin training epoch 204
2023-02-10 22:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:07:43 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2023-02-10 22:07:43 | INFO | train | epoch 204 | loss 7.142 | ppl 141.19 | wps 529971 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1008 | lr 0.000126075 | gnorm 0.556 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9197
2023-02-10 22:07:43 | INFO | fairseq.trainer | begin training epoch 205
2023-02-10 22:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:08:21 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2023-02-10 22:08:21 | INFO | train | epoch 205 | loss 7.134 | ppl 140.49 | wps 557367 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1013 | lr 0.0001267 | gnorm 0.576 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9235
2023-02-10 22:08:21 | INFO | fairseq.trainer | begin training epoch 206
2023-02-10 22:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:08:58 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2023-02-10 22:08:58 | INFO | train | epoch 206 | loss 7.126 | ppl 139.66 | wps 574452 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1018 | lr 0.000127325 | gnorm 0.516 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9272
2023-02-10 22:08:58 | INFO | fairseq.trainer | begin training epoch 207
2023-02-10 22:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:09:36 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2023-02-10 22:09:36 | INFO | train | epoch 207 | loss 7.118 | ppl 138.95 | wps 553397 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1023 | lr 0.000127949 | gnorm 0.464 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9310
2023-02-10 22:09:36 | INFO | fairseq.trainer | begin training epoch 208
2023-02-10 22:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:10:14 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2023-02-10 22:10:14 | INFO | train | epoch 208 | loss 7.114 | ppl 138.54 | wps 544670 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1028 | lr 0.000128574 | gnorm 0.574 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9348
2023-02-10 22:10:14 | INFO | fairseq.trainer | begin training epoch 209
2023-02-10 22:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:10:55 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2023-02-10 22:10:55 | INFO | train | epoch 209 | loss 7.132 | ppl 140.24 | wps 515888 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1033 | lr 0.000129199 | gnorm 1.149 | loss_scale 0.25 | train_wall 33 | gb_free 5.6 | wall 9389
2023-02-10 22:10:55 | INFO | fairseq.trainer | begin training epoch 210
2023-02-10 22:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:11:40 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 6.471 | ppl 88.7 | wps 0 | wpb 11230 | bsz 22 | num_updates 1038 | best_loss 6.471
2023-02-10 22:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 1038 updates
2023-02-10 22:11:40 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint210.pt
2023-02-10 22:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint210.pt
2023-02-10 22:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint210.pt (epoch 210 @ 1038 updates, score 6.471) (writing took 64.36063349799952 seconds)
2023-02-10 22:12:44 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2023-02-10 22:12:44 | INFO | train | epoch 210 | loss 7.162 | ppl 143.25 | wps 192977 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1038 | lr 0.000129824 | gnorm 1.411 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9498
2023-02-10 22:12:44 | INFO | fairseq.trainer | begin training epoch 211
2023-02-10 22:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:13:22 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2023-02-10 22:13:22 | INFO | train | epoch 211 | loss 7.134 | ppl 140.5 | wps 559412 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1043 | lr 0.000130449 | gnorm 0.826 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9536
2023-02-10 22:13:22 | INFO | fairseq.trainer | begin training epoch 212
2023-02-10 22:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:14:02 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2023-02-10 22:14:02 | INFO | train | epoch 212 | loss 7.112 | ppl 138.32 | wps 519617 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1048 | lr 0.000131074 | gnorm 0.553 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9576
2023-02-10 22:14:02 | INFO | fairseq.trainer | begin training epoch 213
2023-02-10 22:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:14:41 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2023-02-10 22:14:41 | INFO | train | epoch 213 | loss 7.097 | ppl 136.91 | wps 537248 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1053 | lr 0.000131699 | gnorm 0.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9615
2023-02-10 22:14:41 | INFO | fairseq.trainer | begin training epoch 214
2023-02-10 22:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:15:21 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2023-02-10 22:15:21 | INFO | train | epoch 214 | loss 7.088 | ppl 136.05 | wps 534483 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1058 | lr 0.000132324 | gnorm 0.46 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9655
2023-02-10 22:15:21 | INFO | fairseq.trainer | begin training epoch 215
2023-02-10 22:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:16:01 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2023-02-10 22:16:01 | INFO | train | epoch 215 | loss 7.087 | ppl 135.94 | wps 515980 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1063 | lr 0.000132948 | gnorm 0.738 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9695
2023-02-10 22:16:02 | INFO | fairseq.trainer | begin training epoch 216
2023-02-10 22:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:16:39 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2023-02-10 22:16:39 | INFO | train | epoch 216 | loss 7.077 | ppl 135.02 | wps 552345 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1068 | lr 0.000133573 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9734
2023-02-10 22:16:40 | INFO | fairseq.trainer | begin training epoch 217
2023-02-10 22:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:17:19 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2023-02-10 22:17:19 | INFO | train | epoch 217 | loss 7.073 | ppl 134.65 | wps 529184 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1073 | lr 0.000134198 | gnorm 0.706 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9773
2023-02-10 22:17:19 | INFO | fairseq.trainer | begin training epoch 218
2023-02-10 22:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:18:00 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2023-02-10 22:18:00 | INFO | train | epoch 218 | loss 7.067 | ppl 134.09 | wps 520632 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1078 | lr 0.000134823 | gnorm 0.651 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9814
2023-02-10 22:18:00 | INFO | fairseq.trainer | begin training epoch 219
2023-02-10 22:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:18:38 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2023-02-10 22:18:38 | INFO | train | epoch 219 | loss 7.061 | ppl 133.51 | wps 544263 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1083 | lr 0.000135448 | gnorm 0.674 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9852
2023-02-10 22:18:38 | INFO | fairseq.trainer | begin training epoch 220
2023-02-10 22:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:19:23 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 6.384 | ppl 83.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 1088 | best_loss 6.384
2023-02-10 22:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 1088 updates
2023-02-10 22:19:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint220.pt
2023-02-10 22:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint220.pt
2023-02-10 22:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint220.pt (epoch 220 @ 1088 updates, score 6.384) (writing took 66.21307971799979 seconds)
2023-02-10 22:20:29 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2023-02-10 22:20:29 | INFO | train | epoch 220 | loss 7.053 | ppl 132.8 | wps 189876 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1088 | lr 0.000136073 | gnorm 0.608 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 9963
2023-02-10 22:20:29 | INFO | fairseq.trainer | begin training epoch 221
2023-02-10 22:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:21:10 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2023-02-10 22:21:10 | INFO | train | epoch 221 | loss 7.046 | ppl 132.13 | wps 508552 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1093 | lr 0.000136698 | gnorm 0.588 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10004
2023-02-10 22:21:11 | INFO | fairseq.trainer | begin training epoch 222
2023-02-10 22:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:21:49 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2023-02-10 22:21:49 | INFO | train | epoch 222 | loss 7.043 | ppl 131.83 | wps 548123 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1098 | lr 0.000137323 | gnorm 0.659 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10043
2023-02-10 22:21:49 | INFO | fairseq.trainer | begin training epoch 223
2023-02-10 22:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:22:11 | INFO | train_inner | epoch 223:      2 / 5 loss=7.098, ppl=137, wps=454899, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=1100, lr=0.000137573, gnorm=0.674, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=10065
2023-02-10 22:22:28 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2023-02-10 22:22:28 | INFO | train | epoch 223 | loss 7.039 | ppl 131.47 | wps 532906 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1103 | lr 0.000137947 | gnorm 0.69 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10082
2023-02-10 22:22:28 | INFO | fairseq.trainer | begin training epoch 224
2023-02-10 22:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:23:11 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2023-02-10 22:23:11 | INFO | train | epoch 224 | loss 7.036 | ppl 131.23 | wps 489416 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1108 | lr 0.000138572 | gnorm 0.757 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10125
2023-02-10 22:23:11 | INFO | fairseq.trainer | begin training epoch 225
2023-02-10 22:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:23:49 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2023-02-10 22:23:49 | INFO | train | epoch 225 | loss 7.027 | ppl 130.43 | wps 551880 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1113 | lr 0.000139197 | gnorm 0.712 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10163
2023-02-10 22:23:50 | INFO | fairseq.trainer | begin training epoch 226
2023-02-10 22:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:24:29 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2023-02-10 22:24:29 | INFO | train | epoch 226 | loss 7.032 | ppl 130.91 | wps 529104 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1118 | lr 0.000139822 | gnorm 0.921 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10203
2023-02-10 22:24:29 | INFO | fairseq.trainer | begin training epoch 227
2023-02-10 22:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:25:06 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2023-02-10 22:25:06 | INFO | train | epoch 227 | loss 7.019 | ppl 129.72 | wps 572336 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1123 | lr 0.000140447 | gnorm 0.666 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10240
2023-02-10 22:25:06 | INFO | fairseq.trainer | begin training epoch 228
2023-02-10 22:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:25:44 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2023-02-10 22:25:44 | INFO | train | epoch 228 | loss 7.008 | ppl 128.76 | wps 548411 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1128 | lr 0.000141072 | gnorm 0.508 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10278
2023-02-10 22:25:44 | INFO | fairseq.trainer | begin training epoch 229
2023-02-10 22:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:26:26 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2023-02-10 22:26:26 | INFO | train | epoch 229 | loss 6.999 | ppl 127.89 | wps 505973 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1133 | lr 0.000141697 | gnorm 0.489 | loss_scale 0.5 | train_wall 33 | gb_free 36.9 | wall 10320
2023-02-10 22:26:26 | INFO | fairseq.trainer | begin training epoch 230
2023-02-10 22:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:27:08 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 6.318 | ppl 79.81 | wps 0 | wpb 11230 | bsz 22 | num_updates 1138 | best_loss 6.318
2023-02-10 22:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 1138 updates
2023-02-10 22:27:08 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint230.pt
2023-02-10 22:27:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint230.pt
2023-02-10 22:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint230.pt (epoch 230 @ 1138 updates, score 6.318) (writing took 66.30078144397703 seconds)
2023-02-10 22:28:14 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2023-02-10 22:28:14 | INFO | train | epoch 230 | loss 7.008 | ppl 128.67 | wps 194294 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1138 | lr 0.000142322 | gnorm 0.852 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10428
2023-02-10 22:28:14 | INFO | fairseq.trainer | begin training epoch 231
2023-02-10 22:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:28:52 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2023-02-10 22:28:52 | INFO | train | epoch 231 | loss 7.003 | ppl 128.31 | wps 550682 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1143 | lr 0.000142946 | gnorm 0.777 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10466
2023-02-10 22:28:52 | INFO | fairseq.trainer | begin training epoch 232
2023-02-10 22:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:29:32 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2023-02-10 22:29:32 | INFO | train | epoch 232 | loss 6.99 | ppl 127.14 | wps 526070 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1148 | lr 0.000143571 | gnorm 0.583 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10506
2023-02-10 22:29:32 | INFO | fairseq.trainer | begin training epoch 233
2023-02-10 22:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:30:11 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2023-02-10 22:30:11 | INFO | train | epoch 233 | loss 6.991 | ppl 127.22 | wps 541514 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1153 | lr 0.000144196 | gnorm 0.811 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10545
2023-02-10 22:30:11 | INFO | fairseq.trainer | begin training epoch 234
2023-02-10 22:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:30:49 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2023-02-10 22:30:49 | INFO | train | epoch 234 | loss 6.99 | ppl 127.09 | wps 554559 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1158 | lr 0.000144821 | gnorm 0.837 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10583
2023-02-10 22:30:49 | INFO | fairseq.trainer | begin training epoch 235
2023-02-10 22:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:31:31 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2023-02-10 22:31:31 | INFO | train | epoch 235 | loss 6.975 | ppl 125.79 | wps 503876 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1163 | lr 0.000145446 | gnorm 0.582 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10625
2023-02-10 22:31:31 | INFO | fairseq.trainer | begin training epoch 236
2023-02-10 22:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:32:09 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2023-02-10 22:32:09 | INFO | train | epoch 236 | loss 6.966 | ppl 125.05 | wps 549465 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1168 | lr 0.000146071 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10663
2023-02-10 22:32:09 | INFO | fairseq.trainer | begin training epoch 237
2023-02-10 22:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:32:48 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2023-02-10 22:32:48 | INFO | train | epoch 237 | loss 6.961 | ppl 124.59 | wps 544519 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1173 | lr 0.000146696 | gnorm 0.64 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10702
2023-02-10 22:32:48 | INFO | fairseq.trainer | begin training epoch 238
2023-02-10 22:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:33:29 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2023-02-10 22:33:29 | INFO | train | epoch 238 | loss 6.951 | ppl 123.74 | wps 514940 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1178 | lr 0.000147321 | gnorm 0.502 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10743
2023-02-10 22:33:29 | INFO | fairseq.trainer | begin training epoch 239
2023-02-10 22:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:34:08 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2023-02-10 22:34:08 | INFO | train | epoch 239 | loss 6.951 | ppl 123.7 | wps 537628 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1183 | lr 0.000147945 | gnorm 0.729 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10782
2023-02-10 22:34:08 | INFO | fairseq.trainer | begin training epoch 240
2023-02-10 22:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:34:52 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 6.247 | ppl 75.97 | wps 0 | wpb 11230 | bsz 22 | num_updates 1188 | best_loss 6.247
2023-02-10 22:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 1188 updates
2023-02-10 22:34:52 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint240.pt
2023-02-10 22:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint240.pt
2023-02-10 22:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint240.pt (epoch 240 @ 1188 updates, score 6.247) (writing took 67.58157808298711 seconds)
2023-02-10 22:35:59 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2023-02-10 22:35:59 | INFO | train | epoch 240 | loss 6.967 | ppl 125.08 | wps 188266 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1188 | lr 0.00014857 | gnorm 1.039 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10893
2023-02-10 22:36:00 | INFO | fairseq.trainer | begin training epoch 241
2023-02-10 22:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:36:40 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2023-02-10 22:36:40 | INFO | train | epoch 241 | loss 6.948 | ppl 123.44 | wps 514927 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1193 | lr 0.000149195 | gnorm 0.69 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10934
2023-02-10 22:36:40 | INFO | fairseq.trainer | begin training epoch 242
2023-02-10 22:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:37:19 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2023-02-10 22:37:19 | INFO | train | epoch 242 | loss 6.934 | ppl 122.24 | wps 541993 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1198 | lr 0.00014982 | gnorm 0.466 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 10973
2023-02-10 22:37:19 | INFO | fairseq.trainer | begin training epoch 243
2023-02-10 22:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:37:41 | INFO | train_inner | epoch 243:      2 / 5 loss=6.987, ppl=126.86, wps=452720, ups=0.11, wpb=4.20696e+06, bsz=8216.8, num_updates=1200, lr=0.00015007, gnorm=0.688, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=10995
2023-02-10 22:37:58 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2023-02-10 22:37:58 | INFO | train | epoch 243 | loss 6.925 | ppl 121.55 | wps 545515 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1203 | lr 0.000150445 | gnorm 0.457 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11012
2023-02-10 22:37:58 | INFO | fairseq.trainer | begin training epoch 244
2023-02-10 22:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:38:39 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2023-02-10 22:38:39 | INFO | train | epoch 244 | loss 6.923 | ppl 121.35 | wps 510096 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1208 | lr 0.00015107 | gnorm 0.655 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11053
2023-02-10 22:38:39 | INFO | fairseq.trainer | begin training epoch 245
2023-02-10 22:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:39:18 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2023-02-10 22:39:18 | INFO | train | epoch 245 | loss 6.929 | ppl 121.88 | wps 543329 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1213 | lr 0.000151695 | gnorm 0.839 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11092
2023-02-10 22:39:18 | INFO | fairseq.trainer | begin training epoch 246
2023-02-10 22:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:39:55 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2023-02-10 22:39:55 | INFO | train | epoch 246 | loss 6.924 | ppl 121.42 | wps 557730 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1218 | lr 0.00015232 | gnorm 0.824 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11129
2023-02-10 22:39:55 | INFO | fairseq.trainer | begin training epoch 247
2023-02-10 22:39:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:40:38 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2023-02-10 22:40:38 | INFO | train | epoch 247 | loss 6.927 | ppl 121.65 | wps 497042 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1223 | lr 0.000152944 | gnorm 0.883 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11172
2023-02-10 22:40:38 | INFO | fairseq.trainer | begin training epoch 248
2023-02-10 22:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:41:16 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2023-02-10 22:41:16 | INFO | train | epoch 248 | loss 6.908 | ppl 120.1 | wps 548712 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1228 | lr 0.000153569 | gnorm 0.573 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11210
2023-02-10 22:41:16 | INFO | fairseq.trainer | begin training epoch 249
2023-02-10 22:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:41:56 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2023-02-10 22:41:56 | INFO | train | epoch 249 | loss 6.894 | ppl 118.92 | wps 526532 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1233 | lr 0.000154194 | gnorm 0.413 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11250
2023-02-10 22:41:56 | INFO | fairseq.trainer | begin training epoch 250
2023-02-10 22:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:42:43 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 6.198 | ppl 73.43 | wps 0 | wpb 11230 | bsz 22 | num_updates 1238 | best_loss 6.198
2023-02-10 22:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 1238 updates
2023-02-10 22:42:43 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint250.pt
2023-02-10 22:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint250.pt
2023-02-10 22:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint250.pt (epoch 250 @ 1238 updates, score 6.198) (writing took 68.71083242000896 seconds)
2023-02-10 22:43:52 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2023-02-10 22:43:52 | INFO | train | epoch 250 | loss 6.884 | ppl 118.12 | wps 181660 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1238 | lr 0.000154819 | gnorm 0.375 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11366
2023-02-10 22:43:52 | INFO | fairseq.trainer | begin training epoch 251
2023-02-10 22:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:44:30 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2023-02-10 22:44:30 | INFO | train | epoch 251 | loss 6.878 | ppl 117.63 | wps 542386 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1243 | lr 0.000155444 | gnorm 0.49 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11404
2023-02-10 22:44:31 | INFO | fairseq.trainer | begin training epoch 252
2023-02-10 22:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:45:09 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2023-02-10 22:45:09 | INFO | train | epoch 252 | loss 6.913 | ppl 120.49 | wps 551942 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1248 | lr 0.000156069 | gnorm 1.066 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11443
2023-02-10 22:45:09 | INFO | fairseq.trainer | begin training epoch 253
2023-02-10 22:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:45:51 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2023-02-10 22:45:51 | INFO | train | epoch 253 | loss 6.89 | ppl 118.61 | wps 500459 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1253 | lr 0.000156694 | gnorm 0.649 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11485
2023-02-10 22:45:51 | INFO | fairseq.trainer | begin training epoch 254
2023-02-10 22:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:46:30 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2023-02-10 22:46:30 | INFO | train | epoch 254 | loss 6.893 | ppl 118.84 | wps 530948 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1258 | lr 0.000157319 | gnorm 0.897 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11524
2023-02-10 22:46:30 | INFO | fairseq.trainer | begin training epoch 255
2023-02-10 22:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:47:09 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2023-02-10 22:47:09 | INFO | train | epoch 255 | loss 6.881 | ppl 117.82 | wps 547083 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1263 | lr 0.000157943 | gnorm 0.708 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11563
2023-02-10 22:47:09 | INFO | fairseq.trainer | begin training epoch 256
2023-02-10 22:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:47:51 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2023-02-10 22:47:51 | INFO | train | epoch 256 | loss 6.869 | ppl 116.92 | wps 501238 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1268 | lr 0.000158568 | gnorm 0.636 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11605
2023-02-10 22:47:51 | INFO | fairseq.trainer | begin training epoch 257
2023-02-10 22:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:48:28 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2023-02-10 22:48:28 | INFO | train | epoch 257 | loss 6.856 | ppl 115.85 | wps 560038 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1273 | lr 0.000159193 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11642
2023-02-10 22:48:28 | INFO | fairseq.trainer | begin training epoch 258
2023-02-10 22:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:49:08 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2023-02-10 22:49:08 | INFO | train | epoch 258 | loss 6.846 | ppl 115.08 | wps 528126 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1278 | lr 0.000159818 | gnorm 0.459 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11682
2023-02-10 22:49:08 | INFO | fairseq.trainer | begin training epoch 259
2023-02-10 22:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:49:46 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2023-02-10 22:49:46 | INFO | train | epoch 259 | loss 6.838 | ppl 114.39 | wps 557606 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1283 | lr 0.000160443 | gnorm 0.422 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11720
2023-02-10 22:49:46 | INFO | fairseq.trainer | begin training epoch 260
2023-02-10 22:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:50:31 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 6.145 | ppl 70.76 | wps 0 | wpb 11230 | bsz 22 | num_updates 1288 | best_loss 6.145
2023-02-10 22:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 1288 updates
2023-02-10 22:50:31 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint260.pt
2023-02-10 22:50:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint260.pt
2023-02-10 22:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint260.pt (epoch 260 @ 1288 updates, score 6.145) (writing took 66.16219896299299 seconds)
2023-02-10 22:51:37 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2023-02-10 22:51:37 | INFO | train | epoch 260 | loss 6.835 | ppl 114.14 | wps 189025 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1288 | lr 0.000161068 | gnorm 0.611 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 11831
2023-02-10 22:51:37 | INFO | fairseq.trainer | begin training epoch 261
2023-02-10 22:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:52:16 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2023-02-10 22:52:16 | INFO | train | epoch 261 | loss 6.847 | ppl 115.12 | wps 544427 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1293 | lr 0.000161693 | gnorm 0.952 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 11870
2023-02-10 22:52:16 | INFO | fairseq.trainer | begin training epoch 262
2023-02-10 22:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:52:58 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2023-02-10 22:52:58 | INFO | train | epoch 262 | loss 6.845 | ppl 114.98 | wps 500886 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1298 | lr 0.000162318 | gnorm 0.788 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 11912
2023-02-10 22:52:58 | INFO | fairseq.trainer | begin training epoch 263
2023-02-10 22:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:53:20 | INFO | train_inner | epoch 263:      2 / 5 loss=6.883, ppl=118.04, wps=447535, ups=0.11, wpb=4.20574e+06, bsz=8214.4, num_updates=1300, lr=0.000162568, gnorm=0.666, loss_scale=1, train_wall=662, gb_free=5.4, wall=11934
2023-02-10 22:53:37 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2023-02-10 22:53:37 | INFO | train | epoch 263 | loss 6.835 | ppl 114.13 | wps 529788 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1303 | lr 0.000162942 | gnorm 0.711 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 11951
2023-02-10 22:53:37 | INFO | fairseq.trainer | begin training epoch 264
2023-02-10 22:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:54:18 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2023-02-10 22:54:18 | INFO | train | epoch 264 | loss 6.821 | ppl 113.03 | wps 521127 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1308 | lr 0.000163567 | gnorm 0.53 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 11992
2023-02-10 22:54:18 | INFO | fairseq.trainer | begin training epoch 265
2023-02-10 22:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:55:00 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2023-02-10 22:55:00 | INFO | train | epoch 265 | loss 6.809 | ppl 112.14 | wps 496241 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1313 | lr 0.000164192 | gnorm 0.441 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12034
2023-02-10 22:55:00 | INFO | fairseq.trainer | begin training epoch 266
2023-02-10 22:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:55:40 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2023-02-10 22:55:40 | INFO | train | epoch 266 | loss 6.802 | ppl 111.6 | wps 533206 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1318 | lr 0.000164817 | gnorm 0.474 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12074
2023-02-10 22:55:40 | INFO | fairseq.trainer | begin training epoch 267
2023-02-10 22:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:56:18 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2023-02-10 22:56:18 | INFO | train | epoch 267 | loss 6.8 | ppl 111.44 | wps 547141 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1323 | lr 0.000165442 | gnorm 0.58 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12112
2023-02-10 22:56:18 | INFO | fairseq.trainer | begin training epoch 268
2023-02-10 22:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:56:57 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2023-02-10 22:56:57 | INFO | train | epoch 268 | loss 6.82 | ppl 112.95 | wps 545676 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1328 | lr 0.000166067 | gnorm 1.111 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12151
2023-02-10 22:56:57 | INFO | fairseq.trainer | begin training epoch 269
2023-02-10 22:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:57:35 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2023-02-10 22:57:35 | INFO | train | epoch 269 | loss 6.858 | ppl 116.03 | wps 547921 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1333 | lr 0.000166692 | gnorm 1.342 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12189
2023-02-10 22:57:35 | INFO | fairseq.trainer | begin training epoch 270
2023-02-10 22:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 22:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 22:58:17 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 6.104 | ppl 68.79 | wps 0 | wpb 11230 | bsz 22 | num_updates 1338 | best_loss 6.104
2023-02-10 22:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 1338 updates
2023-02-10 22:58:17 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint270.pt
2023-02-10 22:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint270.pt
2023-02-10 22:59:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint270.pt (epoch 270 @ 1338 updates, score 6.104) (writing took 77.26373995200265 seconds)
2023-02-10 22:59:34 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2023-02-10 22:59:34 | INFO | train | epoch 270 | loss 6.83 | ppl 113.75 | wps 175920 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1338 | lr 0.000167317 | gnorm 0.699 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12309
2023-02-10 22:59:35 | INFO | fairseq.trainer | begin training epoch 271
2023-02-10 22:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:00:16 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2023-02-10 23:00:16 | INFO | train | epoch 271 | loss 6.802 | ppl 111.56 | wps 503819 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1343 | lr 0.000167941 | gnorm 0.441 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12350
2023-02-10 23:00:16 | INFO | fairseq.trainer | begin training epoch 272
2023-02-10 23:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:00:55 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2023-02-10 23:00:55 | INFO | train | epoch 272 | loss 6.785 | ppl 110.3 | wps 536811 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1348 | lr 0.000168566 | gnorm 0.396 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12389
2023-02-10 23:00:56 | INFO | fairseq.trainer | begin training epoch 273
2023-02-10 23:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:01:34 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2023-02-10 23:01:34 | INFO | train | epoch 273 | loss 6.781 | ppl 109.97 | wps 543604 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1353 | lr 0.000169191 | gnorm 0.594 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12428
2023-02-10 23:01:34 | INFO | fairseq.trainer | begin training epoch 274
2023-02-10 23:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:02:16 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2023-02-10 23:02:16 | INFO | train | epoch 274 | loss 6.768 | ppl 108.99 | wps 497613 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1358 | lr 0.000169816 | gnorm 0.478 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12470
2023-02-10 23:02:17 | INFO | fairseq.trainer | begin training epoch 275
2023-02-10 23:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:02:55 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2023-02-10 23:02:55 | INFO | train | epoch 275 | loss 6.764 | ppl 108.71 | wps 537515 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1363 | lr 0.000170441 | gnorm 0.603 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12510
2023-02-10 23:02:56 | INFO | fairseq.trainer | begin training epoch 276
2023-02-10 23:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:03:34 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2023-02-10 23:03:34 | INFO | train | epoch 276 | loss 6.756 | ppl 108.05 | wps 550819 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1368 | lr 0.000171066 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12548
2023-02-10 23:03:34 | INFO | fairseq.trainer | begin training epoch 277
2023-02-10 23:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:04:11 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2023-02-10 23:04:11 | INFO | train | epoch 277 | loss 6.748 | ppl 107.51 | wps 566451 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1373 | lr 0.000171691 | gnorm 0.502 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12585
2023-02-10 23:04:11 | INFO | fairseq.trainer | begin training epoch 278
2023-02-10 23:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:04:50 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2023-02-10 23:04:50 | INFO | train | epoch 278 | loss 6.741 | ppl 106.98 | wps 540273 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1378 | lr 0.000172316 | gnorm 0.459 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12624
2023-02-10 23:04:50 | INFO | fairseq.trainer | begin training epoch 279
2023-02-10 23:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:05:27 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2023-02-10 23:05:27 | INFO | train | epoch 279 | loss 6.733 | ppl 106.4 | wps 562836 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1383 | lr 0.00017294 | gnorm 0.419 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12661
2023-02-10 23:05:27 | INFO | fairseq.trainer | begin training epoch 280
2023-02-10 23:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:06:10 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 6.053 | ppl 66.4 | wps 0 | wpb 11230 | bsz 22 | num_updates 1388 | best_loss 6.053
2023-02-10 23:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 1388 updates
2023-02-10 23:06:10 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint280.pt
2023-02-10 23:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint280.pt
2023-02-10 23:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint280.pt (epoch 280 @ 1388 updates, score 6.053) (writing took 70.04811087998678 seconds)
2023-02-10 23:07:20 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2023-02-10 23:07:20 | INFO | train | epoch 280 | loss 6.742 | ppl 107.03 | wps 185729 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1388 | lr 0.000173565 | gnorm 0.717 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12774
2023-02-10 23:07:21 | INFO | fairseq.trainer | begin training epoch 281
2023-02-10 23:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:08:01 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2023-02-10 23:08:01 | INFO | train | epoch 281 | loss 6.745 | ppl 107.29 | wps 523145 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1393 | lr 0.00017419 | gnorm 0.868 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 12815
2023-02-10 23:08:01 | INFO | fairseq.trainer | begin training epoch 282
2023-02-10 23:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:08:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-10 23:08:39 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2023-02-10 23:08:39 | INFO | train | epoch 282 | loss 6.744 | ppl 107.19 | wps 411686 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 1397 | lr 0.00017469 | gnorm 0.96 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 12853
2023-02-10 23:08:39 | INFO | fairseq.trainer | begin training epoch 283
2023-02-10 23:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:09:12 | INFO | train_inner | epoch 283:      3 / 5 loss=6.782, ppl=110.05, wps=441818, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=1400, lr=0.000175065, gnorm=0.646, loss_scale=0.5, train_wall=670, gb_free=5.4, wall=12886
2023-02-10 23:09:21 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2023-02-10 23:09:21 | INFO | train | epoch 283 | loss 6.743 | ppl 107.12 | wps 495656 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1402 | lr 0.000175315 | gnorm 0.795 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 12895
2023-02-10 23:09:22 | INFO | fairseq.trainer | begin training epoch 284
2023-02-10 23:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:09:59 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2023-02-10 23:09:59 | INFO | train | epoch 284 | loss 6.728 | ppl 106.03 | wps 562681 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1407 | lr 0.00017594 | gnorm 0.658 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 12933
2023-02-10 23:09:59 | INFO | fairseq.trainer | begin training epoch 285
2023-02-10 23:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:10:39 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2023-02-10 23:10:39 | INFO | train | epoch 285 | loss 6.717 | ppl 105.19 | wps 523226 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1412 | lr 0.000176565 | gnorm 0.551 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 12973
2023-02-10 23:10:39 | INFO | fairseq.trainer | begin training epoch 286
2023-02-10 23:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:11:16 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2023-02-10 23:11:16 | INFO | train | epoch 286 | loss 6.715 | ppl 105.08 | wps 572879 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1417 | lr 0.00017719 | gnorm 0.71 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13010
2023-02-10 23:11:16 | INFO | fairseq.trainer | begin training epoch 287
2023-02-10 23:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:11:57 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2023-02-10 23:11:57 | INFO | train | epoch 287 | loss 6.706 | ppl 104.42 | wps 508886 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1422 | lr 0.000177814 | gnorm 0.543 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13051
2023-02-10 23:11:57 | INFO | fairseq.trainer | begin training epoch 288
2023-02-10 23:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:12:37 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2023-02-10 23:12:37 | INFO | train | epoch 288 | loss 6.693 | ppl 103.45 | wps 528803 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1427 | lr 0.000178439 | gnorm 0.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13091
2023-02-10 23:12:37 | INFO | fairseq.trainer | begin training epoch 289
2023-02-10 23:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:13:14 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2023-02-10 23:13:14 | INFO | train | epoch 289 | loss 6.688 | ppl 103.09 | wps 566030 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1432 | lr 0.000179064 | gnorm 0.567 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13128
2023-02-10 23:13:14 | INFO | fairseq.trainer | begin training epoch 290
2023-02-10 23:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:14:01 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 6.033 | ppl 65.46 | wps 0 | wpb 11230 | bsz 22 | num_updates 1437 | best_loss 6.033
2023-02-10 23:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 1437 updates
2023-02-10 23:14:01 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint290.pt
2023-02-10 23:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint290.pt
2023-02-10 23:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint290.pt (epoch 290 @ 1437 updates, score 6.033) (writing took 58.5376769839786 seconds)
2023-02-10 23:15:00 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2023-02-10 23:15:00 | INFO | train | epoch 290 | loss 6.698 | ppl 103.86 | wps 199257 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1437 | lr 0.000179689 | gnorm 0.819 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13234
2023-02-10 23:15:00 | INFO | fairseq.trainer | begin training epoch 291
2023-02-10 23:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:15:42 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2023-02-10 23:15:42 | INFO | train | epoch 291 | loss 6.722 | ppl 105.57 | wps 490189 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1442 | lr 0.000180314 | gnorm 1.065 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13276
2023-02-10 23:15:43 | INFO | fairseq.trainer | begin training epoch 292
2023-02-10 23:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:16:23 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2023-02-10 23:16:23 | INFO | train | epoch 292 | loss 6.697 | ppl 103.78 | wps 523671 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1447 | lr 0.000180939 | gnorm 0.64 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13317
2023-02-10 23:16:23 | INFO | fairseq.trainer | begin training epoch 293
2023-02-10 23:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:17:01 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2023-02-10 23:17:01 | INFO | train | epoch 293 | loss 6.679 | ppl 102.47 | wps 541727 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1452 | lr 0.000181564 | gnorm 0.456 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13355
2023-02-10 23:17:02 | INFO | fairseq.trainer | begin training epoch 294
2023-02-10 23:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:17:39 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2023-02-10 23:17:39 | INFO | train | epoch 294 | loss 6.666 | ppl 101.54 | wps 552729 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1457 | lr 0.000182189 | gnorm 0.343 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13394
2023-02-10 23:17:40 | INFO | fairseq.trainer | begin training epoch 295
2023-02-10 23:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:18:19 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2023-02-10 23:18:19 | INFO | train | epoch 295 | loss 6.663 | ppl 101.33 | wps 536388 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1462 | lr 0.000182813 | gnorm 0.58 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13433
2023-02-10 23:18:19 | INFO | fairseq.trainer | begin training epoch 296
2023-02-10 23:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:18:56 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2023-02-10 23:18:56 | INFO | train | epoch 296 | loss 6.661 | ppl 101.17 | wps 564265 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1467 | lr 0.000183438 | gnorm 0.6 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13470
2023-02-10 23:18:56 | INFO | fairseq.trainer | begin training epoch 297
2023-02-10 23:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:19:37 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2023-02-10 23:19:37 | INFO | train | epoch 297 | loss 6.653 | ppl 100.61 | wps 513873 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1472 | lr 0.000184063 | gnorm 0.533 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13511
2023-02-10 23:19:38 | INFO | fairseq.trainer | begin training epoch 298
2023-02-10 23:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:20:16 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2023-02-10 23:20:16 | INFO | train | epoch 298 | loss 6.663 | ppl 101.36 | wps 533903 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1477 | lr 0.000184688 | gnorm 0.857 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13550
2023-02-10 23:20:17 | INFO | fairseq.trainer | begin training epoch 299
2023-02-10 23:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:20:54 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2023-02-10 23:20:54 | INFO | train | epoch 299 | loss 6.656 | ppl 100.86 | wps 560916 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1482 | lr 0.000185313 | gnorm 0.671 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13588
2023-02-10 23:20:54 | INFO | fairseq.trainer | begin training epoch 300
2023-02-10 23:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:21:41 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 5.97 | ppl 62.7 | wps 0 | wpb 11230 | bsz 22 | num_updates 1487 | best_loss 5.97
2023-02-10 23:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 1487 updates
2023-02-10 23:21:41 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint300.pt
2023-02-10 23:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint300.pt
2023-02-10 23:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint300.pt (epoch 300 @ 1487 updates, score 5.97) (writing took 58.852363816986326 seconds)
2023-02-10 23:22:40 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2023-02-10 23:22:40 | INFO | train | epoch 300 | loss 6.645 | ppl 100.05 | wps 198172 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1487 | lr 0.000185938 | gnorm 0.591 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13694
2023-02-10 23:22:40 | INFO | fairseq.trainer | begin training epoch 301
2023-02-10 23:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:23:19 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2023-02-10 23:23:19 | INFO | train | epoch 301 | loss 6.636 | ppl 99.46 | wps 534658 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1492 | lr 0.000186563 | gnorm 0.587 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13733
2023-02-10 23:23:19 | INFO | fairseq.trainer | begin training epoch 302
2023-02-10 23:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:23:58 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2023-02-10 23:23:58 | INFO | train | epoch 302 | loss 6.634 | ppl 99.31 | wps 544396 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1497 | lr 0.000187188 | gnorm 0.642 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13772
2023-02-10 23:23:58 | INFO | fairseq.trainer | begin training epoch 303
2023-02-10 23:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:24:27 | INFO | train_inner | epoch 303:      3 / 5 loss=6.679, ppl=102.44, wps=460145, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=1500, lr=0.000187563, gnorm=0.623, loss_scale=0.5, train_wall=663, gb_free=5.4, wall=13801
2023-02-10 23:24:35 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2023-02-10 23:24:35 | INFO | train | epoch 303 | loss 6.623 | ppl 98.56 | wps 560173 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1502 | lr 0.000187812 | gnorm 0.53 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13810
2023-02-10 23:24:36 | INFO | fairseq.trainer | begin training epoch 304
2023-02-10 23:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:25:15 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2023-02-10 23:25:15 | INFO | train | epoch 304 | loss 6.619 | ppl 98.3 | wps 537652 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1507 | lr 0.000188437 | gnorm 0.59 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13849
2023-02-10 23:25:15 | INFO | fairseq.trainer | begin training epoch 305
2023-02-10 23:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:25:52 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2023-02-10 23:25:52 | INFO | train | epoch 305 | loss 6.611 | ppl 97.77 | wps 562859 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1512 | lr 0.000189062 | gnorm 0.572 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13886
2023-02-10 23:25:52 | INFO | fairseq.trainer | begin training epoch 306
2023-02-10 23:25:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:26:32 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2023-02-10 23:26:32 | INFO | train | epoch 306 | loss 6.622 | ppl 98.5 | wps 524387 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1517 | lr 0.000189687 | gnorm 0.776 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13926
2023-02-10 23:26:32 | INFO | fairseq.trainer | begin training epoch 307
2023-02-10 23:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:27:12 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2023-02-10 23:27:12 | INFO | train | epoch 307 | loss 6.61 | ppl 97.66 | wps 532374 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1522 | lr 0.000190312 | gnorm 0.603 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 13966
2023-02-10 23:27:12 | INFO | fairseq.trainer | begin training epoch 308
2023-02-10 23:27:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:27:49 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2023-02-10 23:27:49 | INFO | train | epoch 308 | loss 6.597 | ppl 96.82 | wps 562493 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1527 | lr 0.000190937 | gnorm 0.509 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14003
2023-02-10 23:27:49 | INFO | fairseq.trainer | begin training epoch 309
2023-02-10 23:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:28:29 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2023-02-10 23:28:29 | INFO | train | epoch 309 | loss 6.59 | ppl 96.36 | wps 531370 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1532 | lr 0.000191562 | gnorm 0.513 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14043
2023-02-10 23:28:29 | INFO | fairseq.trainer | begin training epoch 310
2023-02-10 23:28:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:29:13 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 5.947 | ppl 61.7 | wps 0 | wpb 11230 | bsz 22 | num_updates 1537 | best_loss 5.947
2023-02-10 23:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 1537 updates
2023-02-10 23:29:13 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint310.pt
2023-02-10 23:29:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint310.pt
2023-02-10 23:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint310.pt (epoch 310 @ 1537 updates, score 5.947) (writing took 55.13735399799771 seconds)
2023-02-10 23:30:08 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2023-02-10 23:30:08 | INFO | train | epoch 310 | loss 6.587 | ppl 96.13 | wps 212265 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1537 | lr 0.000192187 | gnorm 0.609 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14142
2023-02-10 23:30:08 | INFO | fairseq.trainer | begin training epoch 311
2023-02-10 23:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:30:50 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2023-02-10 23:30:50 | INFO | train | epoch 311 | loss 6.593 | ppl 96.52 | wps 492473 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1542 | lr 0.000192811 | gnorm 0.747 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14184
2023-02-10 23:30:51 | INFO | fairseq.trainer | begin training epoch 312
2023-02-10 23:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:31:28 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2023-02-10 23:31:28 | INFO | train | epoch 312 | loss 6.591 | ppl 96.4 | wps 553114 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1547 | lr 0.000193436 | gnorm 0.737 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14222
2023-02-10 23:31:29 | INFO | fairseq.trainer | begin training epoch 313
2023-02-10 23:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:32:06 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2023-02-10 23:32:06 | INFO | train | epoch 313 | loss 6.577 | ppl 95.47 | wps 564694 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1552 | lr 0.000194061 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14260
2023-02-10 23:32:06 | INFO | fairseq.trainer | begin training epoch 314
2023-02-10 23:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:32:46 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2023-02-10 23:32:46 | INFO | train | epoch 314 | loss 6.574 | ppl 95.25 | wps 525899 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1557 | lr 0.000194686 | gnorm 0.598 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14300
2023-02-10 23:32:46 | INFO | fairseq.trainer | begin training epoch 315
2023-02-10 23:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:33:25 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2023-02-10 23:33:25 | INFO | train | epoch 315 | loss 6.587 | ppl 96.13 | wps 531490 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1562 | lr 0.000195311 | gnorm 0.891 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14339
2023-02-10 23:33:25 | INFO | fairseq.trainer | begin training epoch 316
2023-02-10 23:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:34:03 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2023-02-10 23:34:03 | INFO | train | epoch 316 | loss 6.579 | ppl 95.59 | wps 563291 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1567 | lr 0.000195936 | gnorm 0.71 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14377
2023-02-10 23:34:03 | INFO | fairseq.trainer | begin training epoch 317
2023-02-10 23:34:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:34:42 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2023-02-10 23:34:42 | INFO | train | epoch 317 | loss 6.565 | ppl 94.67 | wps 537098 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1572 | lr 0.000196561 | gnorm 0.585 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14416
2023-02-10 23:34:42 | INFO | fairseq.trainer | begin training epoch 318
2023-02-10 23:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:35:19 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2023-02-10 23:35:19 | INFO | train | epoch 318 | loss 6.552 | ppl 93.84 | wps 562421 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1577 | lr 0.000197186 | gnorm 0.508 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14453
2023-02-10 23:35:19 | INFO | fairseq.trainer | begin training epoch 319
2023-02-10 23:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:36:00 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2023-02-10 23:36:00 | INFO | train | epoch 319 | loss 6.541 | ppl 93.09 | wps 513631 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1582 | lr 0.00019781 | gnorm 0.404 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14494
2023-02-10 23:36:00 | INFO | fairseq.trainer | begin training epoch 320
2023-02-10 23:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:36:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:36:44 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 5.891 | ppl 59.34 | wps 0 | wpb 11230 | bsz 22 | num_updates 1587 | best_loss 5.891
2023-02-10 23:36:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 1587 updates
2023-02-10 23:36:44 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint320.pt
2023-02-10 23:36:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint320.pt
2023-02-10 23:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint320.pt (epoch 320 @ 1587 updates, score 5.891) (writing took 60.164220068982104 seconds)
2023-02-10 23:37:44 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2023-02-10 23:37:44 | INFO | train | epoch 320 | loss 6.536 | ppl 92.82 | wps 202229 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1587 | lr 0.000198435 | gnorm 0.487 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14598
2023-02-10 23:37:44 | INFO | fairseq.trainer | begin training epoch 321
2023-02-10 23:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:38:23 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2023-02-10 23:38:23 | INFO | train | epoch 321 | loss 6.539 | ppl 92.96 | wps 547009 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1592 | lr 0.00019906 | gnorm 0.669 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14637
2023-02-10 23:38:23 | INFO | fairseq.trainer | begin training epoch 322
2023-02-10 23:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:39:00 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2023-02-10 23:39:00 | INFO | train | epoch 322 | loss 6.533 | ppl 92.58 | wps 556053 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1597 | lr 0.000199685 | gnorm 0.618 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14674
2023-02-10 23:39:01 | INFO | fairseq.trainer | begin training epoch 323
2023-02-10 23:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:39:31 | INFO | train_inner | epoch 323:      3 / 5 loss=6.578, ppl=95.52, wps=465119, ups=0.11, wpb=4.20756e+06, bsz=8218, num_updates=1600, lr=0.00020006, gnorm=0.614, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=14705
2023-02-10 23:39:40 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2023-02-10 23:39:40 | INFO | train | epoch 323 | loss 6.528 | ppl 92.3 | wps 530089 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1602 | lr 0.00020031 | gnorm 0.601 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14714
2023-02-10 23:39:40 | INFO | fairseq.trainer | begin training epoch 324
2023-02-10 23:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:40:17 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2023-02-10 23:40:17 | INFO | train | epoch 324 | loss 6.522 | ppl 91.89 | wps 566100 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1607 | lr 0.000200935 | gnorm 0.611 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14751
2023-02-10 23:40:17 | INFO | fairseq.trainer | begin training epoch 325
2023-02-10 23:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:40:58 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2023-02-10 23:40:58 | INFO | train | epoch 325 | loss 6.528 | ppl 92.3 | wps 522080 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1612 | lr 0.00020156 | gnorm 0.776 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14792
2023-02-10 23:40:58 | INFO | fairseq.trainer | begin training epoch 326
2023-02-10 23:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:41:37 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2023-02-10 23:41:37 | INFO | train | epoch 326 | loss 6.527 | ppl 92.2 | wps 539245 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1617 | lr 0.000202185 | gnorm 0.766 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14831
2023-02-10 23:41:37 | INFO | fairseq.trainer | begin training epoch 327
2023-02-10 23:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:42:14 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2023-02-10 23:42:14 | INFO | train | epoch 327 | loss 6.518 | ppl 91.62 | wps 556872 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1622 | lr 0.000202809 | gnorm 0.65 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14868
2023-02-10 23:42:14 | INFO | fairseq.trainer | begin training epoch 328
2023-02-10 23:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:42:55 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2023-02-10 23:42:55 | INFO | train | epoch 328 | loss 6.502 | ppl 90.66 | wps 519621 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1627 | lr 0.000203434 | gnorm 0.516 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 14909
2023-02-10 23:42:55 | INFO | fairseq.trainer | begin training epoch 329
2023-02-10 23:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:43:32 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2023-02-10 23:43:32 | INFO | train | epoch 329 | loss 6.499 | ppl 90.43 | wps 571270 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1632 | lr 0.000204059 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 13.6 | wall 14946
2023-02-10 23:43:32 | INFO | fairseq.trainer | begin training epoch 330
2023-02-10 23:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:44:18 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 5.852 | ppl 57.78 | wps 0 | wpb 11230 | bsz 22 | num_updates 1637 | best_loss 5.852
2023-02-10 23:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 1637 updates
2023-02-10 23:44:18 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint330.pt
2023-02-10 23:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint330.pt
2023-02-10 23:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint330.pt (epoch 330 @ 1637 updates, score 5.852) (writing took 66.386784006987 seconds)
2023-02-10 23:45:24 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2023-02-10 23:45:24 | INFO | train | epoch 330 | loss 6.494 | ppl 90.16 | wps 187247 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1637 | lr 0.000204684 | gnorm 0.604 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 15058
2023-02-10 23:45:24 | INFO | fairseq.trainer | begin training epoch 331
2023-02-10 23:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:46:08 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2023-02-10 23:46:08 | INFO | train | epoch 331 | loss 6.487 | ppl 89.72 | wps 476154 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1642 | lr 0.000205309 | gnorm 0.576 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 15102
2023-02-10 23:46:08 | INFO | fairseq.trainer | begin training epoch 332
2023-02-10 23:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:46:47 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2023-02-10 23:46:47 | INFO | train | epoch 332 | loss 6.478 | ppl 89.13 | wps 544965 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1647 | lr 0.000205934 | gnorm 0.465 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 15141
2023-02-10 23:46:47 | INFO | fairseq.trainer | begin training epoch 333
2023-02-10 23:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:47:27 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2023-02-10 23:47:27 | INFO | train | epoch 333 | loss 6.472 | ppl 88.77 | wps 525051 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1652 | lr 0.000206559 | gnorm 0.509 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15181
2023-02-10 23:47:27 | INFO | fairseq.trainer | begin training epoch 334
2023-02-10 23:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:48:08 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2023-02-10 23:48:08 | INFO | train | epoch 334 | loss 6.465 | ppl 88.35 | wps 513182 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1657 | lr 0.000207184 | gnorm 0.465 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15222
2023-02-10 23:48:08 | INFO | fairseq.trainer | begin training epoch 335
2023-02-10 23:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:48:47 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2023-02-10 23:48:47 | INFO | train | epoch 335 | loss 6.478 | ppl 89.15 | wps 538185 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1662 | lr 0.000207808 | gnorm 0.734 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15261
2023-02-10 23:48:47 | INFO | fairseq.trainer | begin training epoch 336
2023-02-10 23:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:49:25 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2023-02-10 23:49:25 | INFO | train | epoch 336 | loss 6.475 | ppl 88.96 | wps 557166 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1667 | lr 0.000208433 | gnorm 0.798 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15299
2023-02-10 23:49:25 | INFO | fairseq.trainer | begin training epoch 337
2023-02-10 23:49:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:50:04 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2023-02-10 23:50:04 | INFO | train | epoch 337 | loss 6.485 | ppl 89.58 | wps 530490 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1672 | lr 0.000209058 | gnorm 0.895 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15338
2023-02-10 23:50:04 | INFO | fairseq.trainer | begin training epoch 338
2023-02-10 23:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:50:41 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2023-02-10 23:50:41 | INFO | train | epoch 338 | loss 6.473 | ppl 88.83 | wps 567663 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1677 | lr 0.000209683 | gnorm 0.761 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15375
2023-02-10 23:50:42 | INFO | fairseq.trainer | begin training epoch 339
2023-02-10 23:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:51:22 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2023-02-10 23:51:22 | INFO | train | epoch 339 | loss 6.452 | ppl 87.57 | wps 514933 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1682 | lr 0.000210308 | gnorm 0.434 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15416
2023-02-10 23:51:22 | INFO | fairseq.trainer | begin training epoch 340
2023-02-10 23:51:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:52:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:52:05 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 5.82 | ppl 56.48 | wps 0 | wpb 11230 | bsz 22 | num_updates 1687 | best_loss 5.82
2023-02-10 23:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 1687 updates
2023-02-10 23:52:05 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint340.pt
2023-02-10 23:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint340.pt
2023-02-10 23:53:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint340.pt (epoch 340 @ 1687 updates, score 5.82) (writing took 61.73827141197398 seconds)
2023-02-10 23:53:07 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2023-02-10 23:53:07 | INFO | train | epoch 340 | loss 6.44 | ppl 86.81 | wps 200785 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1687 | lr 0.000210933 | gnorm 0.358 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15521
2023-02-10 23:53:07 | INFO | fairseq.trainer | begin training epoch 341
2023-02-10 23:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:53:46 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2023-02-10 23:53:46 | INFO | train | epoch 341 | loss 6.439 | ppl 86.75 | wps 537950 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1692 | lr 0.000211558 | gnorm 0.625 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15560
2023-02-10 23:53:46 | INFO | fairseq.trainer | begin training epoch 342
2023-02-10 23:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:54:26 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2023-02-10 23:54:26 | INFO | train | epoch 342 | loss 6.447 | ppl 87.26 | wps 521911 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1697 | lr 0.000212183 | gnorm 0.754 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15600
2023-02-10 23:54:27 | INFO | fairseq.trainer | begin training epoch 343
2023-02-10 23:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:54:57 | INFO | train_inner | epoch 343:      3 / 5 loss=6.482, ppl=89.41, wps=454285, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=1700, lr=0.000212558, gnorm=0.625, loss_scale=1, train_wall=663, gb_free=5.4, wall=15631
2023-02-10 23:55:06 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2023-02-10 23:55:06 | INFO | train | epoch 343 | loss 6.444 | ppl 87.08 | wps 529847 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1702 | lr 0.000212807 | gnorm 0.67 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15640
2023-02-10 23:55:06 | INFO | fairseq.trainer | begin training epoch 344
2023-02-10 23:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:55:43 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2023-02-10 23:55:43 | INFO | train | epoch 344 | loss 6.431 | ppl 86.29 | wps 563239 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1707 | lr 0.000213432 | gnorm 0.551 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15677
2023-02-10 23:55:44 | INFO | fairseq.trainer | begin training epoch 345
2023-02-10 23:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:56:24 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2023-02-10 23:56:24 | INFO | train | epoch 345 | loss 6.418 | ppl 85.54 | wps 516051 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1712 | lr 0.000214057 | gnorm 0.472 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15718
2023-02-10 23:56:24 | INFO | fairseq.trainer | begin training epoch 346
2023-02-10 23:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:57:03 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2023-02-10 23:57:03 | INFO | train | epoch 346 | loss 6.41 | ppl 85.02 | wps 536340 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1717 | lr 0.000214682 | gnorm 0.471 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15757
2023-02-10 23:57:04 | INFO | fairseq.trainer | begin training epoch 347
2023-02-10 23:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:57:41 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2023-02-10 23:57:41 | INFO | train | epoch 347 | loss 6.411 | ppl 85.09 | wps 561484 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1722 | lr 0.000215307 | gnorm 0.635 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15795
2023-02-10 23:57:41 | INFO | fairseq.trainer | begin training epoch 348
2023-02-10 23:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:58:22 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2023-02-10 23:58:22 | INFO | train | epoch 348 | loss 6.423 | ppl 85.8 | wps 513433 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1727 | lr 0.000215932 | gnorm 0.88 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15836
2023-02-10 23:58:22 | INFO | fairseq.trainer | begin training epoch 349
2023-02-10 23:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:59:01 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2023-02-10 23:59:01 | INFO | train | epoch 349 | loss 6.427 | ppl 86.03 | wps 539539 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1732 | lr 0.000216557 | gnorm 0.799 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15875
2023-02-10 23:59:01 | INFO | fairseq.trainer | begin training epoch 350
2023-02-10 23:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-10 23:59:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-10 23:59:45 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 5.804 | ppl 55.86 | wps 0 | wpb 11230 | bsz 22 | num_updates 1737 | best_loss 5.804
2023-02-10 23:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 1737 updates
2023-02-10 23:59:45 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint350.pt
2023-02-10 23:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint350.pt
2023-02-11 00:00:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint350.pt (epoch 350 @ 1737 updates, score 5.804) (writing took 61.6177260770055 seconds)
2023-02-11 00:00:46 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2023-02-11 00:00:46 | INFO | train | epoch 350 | loss 6.402 | ppl 84.54 | wps 198988 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1737 | lr 0.000217182 | gnorm 0.47 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 15981
2023-02-11 00:00:47 | INFO | fairseq.trainer | begin training epoch 351
2023-02-11 00:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:01:49 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2023-02-11 00:01:49 | INFO | train | epoch 351 | loss 6.389 | ppl 83.78 | wps 336072 | ups 0.08 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1742 | lr 0.000217806 | gnorm 0.409 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 16043
2023-02-11 00:01:49 | INFO | fairseq.trainer | begin training epoch 352
2023-02-11 00:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:02:28 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2023-02-11 00:02:28 | INFO | train | epoch 352 | loss 6.379 | ppl 83.23 | wps 542094 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1747 | lr 0.000218431 | gnorm 0.379 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 16082
2023-02-11 00:02:28 | INFO | fairseq.trainer | begin training epoch 353
2023-02-11 00:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:03:07 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2023-02-11 00:03:07 | INFO | train | epoch 353 | loss 6.375 | ppl 82.97 | wps 535669 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1752 | lr 0.000219056 | gnorm 0.522 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 16121
2023-02-11 00:03:07 | INFO | fairseq.trainer | begin training epoch 354
2023-02-11 00:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:03:45 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2023-02-11 00:03:45 | INFO | train | epoch 354 | loss 6.402 | ppl 84.56 | wps 559326 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1757 | lr 0.000219681 | gnorm 0.91 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 16159
2023-02-11 00:03:45 | INFO | fairseq.trainer | begin training epoch 355
2023-02-11 00:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:04:25 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2023-02-11 00:04:25 | INFO | train | epoch 355 | loss 6.399 | ppl 84.38 | wps 527973 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1762 | lr 0.000220306 | gnorm 0.825 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 16199
2023-02-11 00:04:25 | INFO | fairseq.trainer | begin training epoch 356
2023-02-11 00:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 00:05:01 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2023-02-11 00:05:01 | INFO | train | epoch 356 | loss 6.39 | ppl 83.89 | wps 431796 | ups 0.11 | wpb 3.96794e+06 | bsz 7750 | num_updates 1766 | lr 0.000220806 | gnorm 0.767 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16235
2023-02-11 00:05:01 | INFO | fairseq.trainer | begin training epoch 357
2023-02-11 00:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:05:42 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2023-02-11 00:05:42 | INFO | train | epoch 357 | loss 6.381 | ppl 83.34 | wps 514330 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1771 | lr 0.000221431 | gnorm 0.663 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16276
2023-02-11 00:05:42 | INFO | fairseq.trainer | begin training epoch 358
2023-02-11 00:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:06:22 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2023-02-11 00:06:22 | INFO | train | epoch 358 | loss 6.366 | ppl 82.51 | wps 528876 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1776 | lr 0.000222056 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16316
2023-02-11 00:06:22 | INFO | fairseq.trainer | begin training epoch 359
2023-02-11 00:06:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:06:59 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2023-02-11 00:06:59 | INFO | train | epoch 359 | loss 6.351 | ppl 81.61 | wps 567657 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1781 | lr 0.00022268 | gnorm 0.393 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16353
2023-02-11 00:06:59 | INFO | fairseq.trainer | begin training epoch 360
2023-02-11 00:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:07:45 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 5.766 | ppl 54.41 | wps 0 | wpb 11230 | bsz 22 | num_updates 1786 | best_loss 5.766
2023-02-11 00:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 1786 updates
2023-02-11 00:07:45 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint360.pt
2023-02-11 00:07:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint360.pt
2023-02-11 00:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint360.pt (epoch 360 @ 1786 updates, score 5.766) (writing took 67.17297273498843 seconds)
2023-02-11 00:08:53 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2023-02-11 00:08:53 | INFO | train | epoch 360 | loss 6.342 | ppl 81.11 | wps 185206 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1786 | lr 0.000223305 | gnorm 0.366 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16467
2023-02-11 00:08:53 | INFO | fairseq.trainer | begin training epoch 361
2023-02-11 00:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:10:11 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2023-02-11 00:10:11 | INFO | train | epoch 361 | loss 6.337 | ppl 80.81 | wps 267429 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1791 | lr 0.00022393 | gnorm 0.445 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16545
2023-02-11 00:10:12 | INFO | fairseq.trainer | begin training epoch 362
2023-02-11 00:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:10:50 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2023-02-11 00:10:50 | INFO | train | epoch 362 | loss 6.342 | ppl 81.13 | wps 546266 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1796 | lr 0.000224555 | gnorm 0.673 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16584
2023-02-11 00:10:50 | INFO | fairseq.trainer | begin training epoch 363
2023-02-11 00:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:11:29 | INFO | train_inner | epoch 363:      4 / 5 loss=6.387, ppl=83.67, wps=424126, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=1800, lr=0.000225055, gnorm=0.594, loss_scale=0.5, train_wall=671, gb_free=5.4, wall=16623
2023-02-11 00:11:30 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2023-02-11 00:11:30 | INFO | train | epoch 363 | loss 6.347 | ppl 81.4 | wps 526893 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1801 | lr 0.00022518 | gnorm 0.767 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16624
2023-02-11 00:11:30 | INFO | fairseq.trainer | begin training epoch 364
2023-02-11 00:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:12:06 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2023-02-11 00:12:06 | INFO | train | epoch 364 | loss 6.335 | ppl 80.74 | wps 573700 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1806 | lr 0.000225805 | gnorm 0.575 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16660
2023-02-11 00:12:07 | INFO | fairseq.trainer | begin training epoch 365
2023-02-11 00:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:12:47 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2023-02-11 00:12:47 | INFO | train | epoch 365 | loss 6.324 | ppl 80.1 | wps 515102 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1811 | lr 0.00022643 | gnorm 0.481 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16701
2023-02-11 00:12:47 | INFO | fairseq.trainer | begin training epoch 366
2023-02-11 00:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:13:27 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2023-02-11 00:13:27 | INFO | train | epoch 366 | loss 6.323 | ppl 80.08 | wps 530103 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1816 | lr 0.000227055 | gnorm 0.658 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16741
2023-02-11 00:13:27 | INFO | fairseq.trainer | begin training epoch 367
2023-02-11 00:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:14:04 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2023-02-11 00:14:04 | INFO | train | epoch 367 | loss 6.325 | ppl 80.19 | wps 560202 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1821 | lr 0.000227679 | gnorm 0.648 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16778
2023-02-11 00:14:05 | INFO | fairseq.trainer | begin training epoch 368
2023-02-11 00:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:14:45 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2023-02-11 00:14:45 | INFO | train | epoch 368 | loss 6.321 | ppl 79.92 | wps 516821 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1826 | lr 0.000228304 | gnorm 0.643 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16819
2023-02-11 00:14:45 | INFO | fairseq.trainer | begin training epoch 369
2023-02-11 00:14:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:15:24 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2023-02-11 00:15:24 | INFO | train | epoch 369 | loss 6.311 | ppl 79.39 | wps 534917 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1831 | lr 0.000228929 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16858
2023-02-11 00:15:25 | INFO | fairseq.trainer | begin training epoch 370
2023-02-11 00:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:16:08 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 5.743 | ppl 53.54 | wps 0 | wpb 11230 | bsz 22 | num_updates 1836 | best_loss 5.743
2023-02-11 00:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 1836 updates
2023-02-11 00:16:08 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint370.pt
2023-02-11 00:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint370.pt
2023-02-11 00:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint370.pt (epoch 370 @ 1836 updates, score 5.743) (writing took 64.54658774100244 seconds)
2023-02-11 00:17:13 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2023-02-11 00:17:13 | INFO | train | epoch 370 | loss 6.297 | ppl 78.63 | wps 193852 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1836 | lr 0.000229554 | gnorm 0.411 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 16967
2023-02-11 00:17:13 | INFO | fairseq.trainer | begin training epoch 371
2023-02-11 00:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:17:57 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2023-02-11 00:17:57 | INFO | train | epoch 371 | loss 6.289 | ppl 78.21 | wps 479784 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1841 | lr 0.000230179 | gnorm 0.415 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17011
2023-02-11 00:17:57 | INFO | fairseq.trainer | begin training epoch 372
2023-02-11 00:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:18:37 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2023-02-11 00:18:37 | INFO | train | epoch 372 | loss 6.292 | ppl 78.35 | wps 526599 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1846 | lr 0.000230804 | gnorm 0.571 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17051
2023-02-11 00:18:37 | INFO | fairseq.trainer | begin training epoch 373
2023-02-11 00:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:19:17 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2023-02-11 00:19:17 | INFO | train | epoch 373 | loss 6.283 | ppl 77.88 | wps 523498 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1851 | lr 0.000231429 | gnorm 0.476 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17091
2023-02-11 00:19:17 | INFO | fairseq.trainer | begin training epoch 374
2023-02-11 00:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:20:01 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2023-02-11 00:20:01 | INFO | train | epoch 374 | loss 6.279 | ppl 77.64 | wps 478342 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1856 | lr 0.000232054 | gnorm 0.52 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17135
2023-02-11 00:20:01 | INFO | fairseq.trainer | begin training epoch 375
2023-02-11 00:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:20:38 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2023-02-11 00:20:38 | INFO | train | epoch 375 | loss 6.288 | ppl 78.13 | wps 560553 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1861 | lr 0.000232678 | gnorm 0.719 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17172
2023-02-11 00:20:39 | INFO | fairseq.trainer | begin training epoch 376
2023-02-11 00:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:21:17 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2023-02-11 00:21:17 | INFO | train | epoch 376 | loss 6.285 | ppl 78 | wps 542051 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1866 | lr 0.000233303 | gnorm 0.649 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17211
2023-02-11 00:21:17 | INFO | fairseq.trainer | begin training epoch 377
2023-02-11 00:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:21:56 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2023-02-11 00:21:56 | INFO | train | epoch 377 | loss 6.287 | ppl 78.08 | wps 548513 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1871 | lr 0.000233928 | gnorm 0.785 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17250
2023-02-11 00:21:56 | INFO | fairseq.trainer | begin training epoch 378
2023-02-11 00:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:22:36 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2023-02-11 00:22:36 | INFO | train | epoch 378 | loss 6.293 | ppl 78.41 | wps 525006 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1876 | lr 0.000234553 | gnorm 0.823 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17290
2023-02-11 00:22:36 | INFO | fairseq.trainer | begin training epoch 379
2023-02-11 00:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:23:13 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2023-02-11 00:23:13 | INFO | train | epoch 379 | loss 6.281 | ppl 77.78 | wps 566068 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1881 | lr 0.000235178 | gnorm 0.653 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17327
2023-02-11 00:23:13 | INFO | fairseq.trainer | begin training epoch 380
2023-02-11 00:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:23:58 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 5.705 | ppl 52.17 | wps 0 | wpb 11230 | bsz 22 | num_updates 1886 | best_loss 5.705
2023-02-11 00:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 1886 updates
2023-02-11 00:23:58 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint380.pt
2023-02-11 00:24:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint380.pt
2023-02-11 00:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint380.pt (epoch 380 @ 1886 updates, score 5.705) (writing took 67.33596766597475 seconds)
2023-02-11 00:25:06 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2023-02-11 00:25:06 | INFO | train | epoch 380 | loss 6.261 | ppl 76.68 | wps 186630 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1886 | lr 0.000235803 | gnorm 0.434 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17440
2023-02-11 00:25:06 | INFO | fairseq.trainer | begin training epoch 381
2023-02-11 00:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:26:22 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2023-02-11 00:26:22 | INFO | train | epoch 381 | loss 6.255 | ppl 76.39 | wps 274150 | ups 0.07 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1891 | lr 0.000236428 | gnorm 0.51 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17516
2023-02-11 00:26:22 | INFO | fairseq.trainer | begin training epoch 382
2023-02-11 00:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:27:08 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2023-02-11 00:27:08 | INFO | train | epoch 382 | loss 6.246 | ppl 75.9 | wps 459288 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1896 | lr 0.000237053 | gnorm 0.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17562
2023-02-11 00:27:08 | INFO | fairseq.trainer | begin training epoch 383
2023-02-11 00:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:27:47 | INFO | train_inner | epoch 383:      4 / 5 loss=6.291, ppl=78.3, wps=430154, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=1900, lr=0.000237553, gnorm=0.577, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=17601
2023-02-11 00:27:48 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2023-02-11 00:27:48 | INFO | train | epoch 383 | loss 6.244 | ppl 75.77 | wps 530622 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1901 | lr 0.000237677 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17602
2023-02-11 00:27:48 | INFO | fairseq.trainer | begin training epoch 384
2023-02-11 00:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:28:25 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2023-02-11 00:28:25 | INFO | train | epoch 384 | loss 6.254 | ppl 76.32 | wps 569515 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1906 | lr 0.000238302 | gnorm 0.705 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17639
2023-02-11 00:28:25 | INFO | fairseq.trainer | begin training epoch 385
2023-02-11 00:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:29:09 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2023-02-11 00:29:09 | INFO | train | epoch 385 | loss 6.24 | ppl 75.57 | wps 468778 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1911 | lr 0.000238927 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17684
2023-02-11 00:29:10 | INFO | fairseq.trainer | begin training epoch 386
2023-02-11 00:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:29:46 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2023-02-11 00:29:46 | INFO | train | epoch 386 | loss 6.233 | ppl 75.23 | wps 570004 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1916 | lr 0.000239552 | gnorm 0.558 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17720
2023-02-11 00:29:47 | INFO | fairseq.trainer | begin training epoch 387
2023-02-11 00:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:30:29 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2023-02-11 00:30:29 | INFO | train | epoch 387 | loss 6.232 | ppl 75.14 | wps 497198 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1921 | lr 0.000240177 | gnorm 0.577 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17763
2023-02-11 00:30:29 | INFO | fairseq.trainer | begin training epoch 388
2023-02-11 00:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:31:08 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2023-02-11 00:31:08 | INFO | train | epoch 388 | loss 6.225 | ppl 74.81 | wps 530899 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1926 | lr 0.000240802 | gnorm 0.569 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17802
2023-02-11 00:31:08 | INFO | fairseq.trainer | begin training epoch 389
2023-02-11 00:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:31:48 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2023-02-11 00:31:48 | INFO | train | epoch 389 | loss 6.22 | ppl 74.53 | wps 528171 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1931 | lr 0.000241427 | gnorm 0.53 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17842
2023-02-11 00:31:48 | INFO | fairseq.trainer | begin training epoch 390
2023-02-11 00:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:32:32 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 5.687 | ppl 51.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 1936 | best_loss 5.687
2023-02-11 00:32:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 1936 updates
2023-02-11 00:32:32 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint390.pt
2023-02-11 00:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint390.pt
2023-02-11 00:33:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint390.pt (epoch 390 @ 1936 updates, score 5.687) (writing took 60.76167302799877 seconds)
2023-02-11 00:33:33 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2023-02-11 00:33:33 | INFO | train | epoch 390 | loss 6.217 | ppl 74.37 | wps 201254 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1936 | lr 0.000242052 | gnorm 0.585 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17947
2023-02-11 00:33:33 | INFO | fairseq.trainer | begin training epoch 391
2023-02-11 00:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:34:18 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2023-02-11 00:34:18 | INFO | train | epoch 391 | loss 6.215 | ppl 74.29 | wps 468771 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1941 | lr 0.000242676 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 17992
2023-02-11 00:34:18 | INFO | fairseq.trainer | begin training epoch 392
2023-02-11 00:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:34:57 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2023-02-11 00:34:57 | INFO | train | epoch 392 | loss 6.21 | ppl 74.05 | wps 529142 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1946 | lr 0.000243301 | gnorm 0.598 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18031
2023-02-11 00:34:57 | INFO | fairseq.trainer | begin training epoch 393
2023-02-11 00:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:35:37 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2023-02-11 00:35:37 | INFO | train | epoch 393 | loss 6.207 | ppl 73.87 | wps 530976 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1951 | lr 0.000243926 | gnorm 0.544 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18071
2023-02-11 00:35:37 | INFO | fairseq.trainer | begin training epoch 394
2023-02-11 00:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:36:23 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2023-02-11 00:36:23 | INFO | train | epoch 394 | loss 6.203 | ppl 73.67 | wps 455718 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1956 | lr 0.000244551 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18117
2023-02-11 00:36:23 | INFO | fairseq.trainer | begin training epoch 395
2023-02-11 00:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:37:03 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2023-02-11 00:37:03 | INFO | train | epoch 395 | loss 6.199 | ppl 73.47 | wps 525712 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1961 | lr 0.000245176 | gnorm 0.59 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18157
2023-02-11 00:37:03 | INFO | fairseq.trainer | begin training epoch 396
2023-02-11 00:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:37:43 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2023-02-11 00:37:43 | INFO | train | epoch 396 | loss 6.209 | ppl 73.99 | wps 526487 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1966 | lr 0.000245801 | gnorm 0.746 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18197
2023-02-11 00:37:43 | INFO | fairseq.trainer | begin training epoch 397
2023-02-11 00:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:38:28 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2023-02-11 00:38:28 | INFO | train | epoch 397 | loss 6.201 | ppl 73.55 | wps 468993 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1971 | lr 0.000246426 | gnorm 0.598 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18242
2023-02-11 00:38:28 | INFO | fairseq.trainer | begin training epoch 398
2023-02-11 00:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:39:04 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2023-02-11 00:39:04 | INFO | train | epoch 398 | loss 6.186 | ppl 72.81 | wps 575798 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1976 | lr 0.000247051 | gnorm 0.494 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18278
2023-02-11 00:39:05 | INFO | fairseq.trainer | begin training epoch 399
2023-02-11 00:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:39:44 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2023-02-11 00:39:44 | INFO | train | epoch 399 | loss 6.184 | ppl 72.73 | wps 536128 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1981 | lr 0.000247675 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18318
2023-02-11 00:39:44 | INFO | fairseq.trainer | begin training epoch 400
2023-02-11 00:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:40:28 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 5.642 | ppl 49.92 | wps 0 | wpb 11230 | bsz 22 | num_updates 1986 | best_loss 5.642
2023-02-11 00:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 1986 updates
2023-02-11 00:40:28 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint400.pt
2023-02-11 00:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint400.pt
2023-02-11 00:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint400.pt (epoch 400 @ 1986 updates, score 5.642) (writing took 63.199973873008275 seconds)
2023-02-11 00:41:31 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2023-02-11 00:41:31 | INFO | train | epoch 400 | loss 6.175 | ppl 72.23 | wps 195665 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1986 | lr 0.0002483 | gnorm 0.472 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18425
2023-02-11 00:41:31 | INFO | fairseq.trainer | begin training epoch 401
2023-02-11 00:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:42:11 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2023-02-11 00:42:11 | INFO | train | epoch 401 | loss 6.167 | ppl 71.86 | wps 529353 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1991 | lr 0.000248925 | gnorm 0.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18465
2023-02-11 00:42:11 | INFO | fairseq.trainer | begin training epoch 402
2023-02-11 00:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:42:50 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2023-02-11 00:42:50 | INFO | train | epoch 402 | loss 6.186 | ppl 72.81 | wps 531806 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 1996 | lr 0.00024955 | gnorm 0.719 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18504
2023-02-11 00:42:51 | INFO | fairseq.trainer | begin training epoch 403
2023-02-11 00:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:43:35 | INFO | train_inner | epoch 403:      4 / 5 loss=6.207, ppl=73.86, wps=443665, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=2000, lr=0.00025005, gnorm=0.584, loss_scale=0.5, train_wall=663, gb_free=5.4, wall=18549
2023-02-11 00:43:36 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2023-02-11 00:43:36 | INFO | train | epoch 403 | loss 6.172 | ppl 72.09 | wps 462897 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2001 | lr 0.000250175 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18550
2023-02-11 00:43:36 | INFO | fairseq.trainer | begin training epoch 404
2023-02-11 00:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:44:16 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2023-02-11 00:44:16 | INFO | train | epoch 404 | loss 6.16 | ppl 71.5 | wps 519756 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2006 | lr 0.0002508 | gnorm 0.447 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18590
2023-02-11 00:44:17 | INFO | fairseq.trainer | begin training epoch 405
2023-02-11 00:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:44:55 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2023-02-11 00:44:55 | INFO | train | epoch 405 | loss 6.161 | ppl 71.53 | wps 540168 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2011 | lr 0.000251425 | gnorm 0.554 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18629
2023-02-11 00:44:56 | INFO | fairseq.trainer | begin training epoch 406
2023-02-11 00:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:45:34 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2023-02-11 00:45:34 | INFO | train | epoch 406 | loss 6.162 | ppl 71.62 | wps 549095 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2016 | lr 0.00025205 | gnorm 0.647 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 18668
2023-02-11 00:45:34 | INFO | fairseq.trainer | begin training epoch 407
2023-02-11 00:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:46:14 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2023-02-11 00:46:14 | INFO | train | epoch 407 | loss 6.169 | ppl 71.96 | wps 526738 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2021 | lr 0.000252674 | gnorm 0.757 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18708
2023-02-11 00:46:14 | INFO | fairseq.trainer | begin training epoch 408
2023-02-11 00:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:46:50 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2023-02-11 00:46:50 | INFO | train | epoch 408 | loss 6.17 | ppl 72.02 | wps 569257 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2026 | lr 0.000253299 | gnorm 0.788 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18745
2023-02-11 00:46:51 | INFO | fairseq.trainer | begin training epoch 409
2023-02-11 00:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:47:36 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2023-02-11 00:47:36 | INFO | train | epoch 409 | loss 6.157 | ppl 71.35 | wps 458276 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2031 | lr 0.000253924 | gnorm 0.596 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18790
2023-02-11 00:47:37 | INFO | fairseq.trainer | begin training epoch 410
2023-02-11 00:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:48:23 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 5.622 | ppl 49.24 | wps 0 | wpb 11230 | bsz 22 | num_updates 2036 | best_loss 5.622
2023-02-11 00:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 2036 updates
2023-02-11 00:48:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint410.pt
2023-02-11 00:48:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint410.pt
2023-02-11 00:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint410.pt (epoch 410 @ 2036 updates, score 5.622) (writing took 63.088747315021465 seconds)
2023-02-11 00:49:26 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2023-02-11 00:49:26 | INFO | train | epoch 410 | loss 6.14 | ppl 70.52 | wps 191089 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2036 | lr 0.000254549 | gnorm 0.388 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18900
2023-02-11 00:49:27 | INFO | fairseq.trainer | begin training epoch 411
2023-02-11 00:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:50:14 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2023-02-11 00:50:14 | INFO | train | epoch 411 | loss 6.131 | ppl 70.06 | wps 446670 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2041 | lr 0.000255174 | gnorm 0.378 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18948
2023-02-11 00:50:14 | INFO | fairseq.trainer | begin training epoch 412
2023-02-11 00:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:50:57 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2023-02-11 00:50:57 | INFO | train | epoch 412 | loss 6.126 | ppl 69.85 | wps 483119 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2046 | lr 0.000255799 | gnorm 0.435 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 18991
2023-02-11 00:50:57 | INFO | fairseq.trainer | begin training epoch 413
2023-02-11 00:50:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:51:43 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2023-02-11 00:51:43 | INFO | train | epoch 413 | loss 6.127 | ppl 69.91 | wps 459902 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2051 | lr 0.000256424 | gnorm 0.576 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19037
2023-02-11 00:51:43 | INFO | fairseq.trainer | begin training epoch 414
2023-02-11 00:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:52:23 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2023-02-11 00:52:23 | INFO | train | epoch 414 | loss 6.138 | ppl 70.41 | wps 520444 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2056 | lr 0.000257049 | gnorm 0.669 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19077
2023-02-11 00:52:23 | INFO | fairseq.trainer | begin training epoch 415
2023-02-11 00:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:53:06 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2023-02-11 00:53:06 | INFO | train | epoch 415 | loss 6.127 | ppl 69.9 | wps 491853 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2061 | lr 0.000257673 | gnorm 0.52 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19120
2023-02-11 00:53:06 | INFO | fairseq.trainer | begin training epoch 416
2023-02-11 00:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:53:45 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2023-02-11 00:53:45 | INFO | train | epoch 416 | loss 6.12 | ppl 69.54 | wps 536620 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2066 | lr 0.000258298 | gnorm 0.518 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19159
2023-02-11 00:53:45 | INFO | fairseq.trainer | begin training epoch 417
2023-02-11 00:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:54:26 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2023-02-11 00:54:26 | INFO | train | epoch 417 | loss 6.117 | ppl 69.42 | wps 518025 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2071 | lr 0.000258923 | gnorm 0.61 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19200
2023-02-11 00:54:26 | INFO | fairseq.trainer | begin training epoch 418
2023-02-11 00:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:55:06 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2023-02-11 00:55:06 | INFO | train | epoch 418 | loss 6.117 | ppl 69.42 | wps 518847 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2076 | lr 0.000259548 | gnorm 0.632 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19240
2023-02-11 00:55:08 | INFO | fairseq.trainer | begin training epoch 419
2023-02-11 00:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:55:48 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2023-02-11 00:55:48 | INFO | train | epoch 419 | loss 6.118 | ppl 69.47 | wps 504327 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2081 | lr 0.000260173 | gnorm 0.633 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19282
2023-02-11 00:55:48 | INFO | fairseq.trainer | begin training epoch 420
2023-02-11 00:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 00:56:32 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 5.621 | ppl 49.22 | wps 0 | wpb 11230 | bsz 22 | num_updates 2086 | best_loss 5.621
2023-02-11 00:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 2086 updates
2023-02-11 00:56:32 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint420.pt
2023-02-11 00:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint420.pt
2023-02-11 00:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint420.pt (epoch 420 @ 2086 updates, score 5.621) (writing took 65.76255268300883 seconds)
2023-02-11 00:57:38 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2023-02-11 00:57:38 | INFO | train | epoch 420 | loss 6.124 | ppl 69.73 | wps 191152 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2086 | lr 0.000260798 | gnorm 0.723 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19392
2023-02-11 00:57:38 | INFO | fairseq.trainer | begin training epoch 421
2023-02-11 00:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:59:06 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2023-02-11 00:59:06 | INFO | train | epoch 421 | loss 6.109 | ppl 69.02 | wps 240452 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2091 | lr 0.000261423 | gnorm 0.544 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19480
2023-02-11 00:59:06 | INFO | fairseq.trainer | begin training epoch 422
2023-02-11 00:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 00:59:44 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2023-02-11 00:59:44 | INFO | train | epoch 422 | loss 6.099 | ppl 68.53 | wps 553989 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2096 | lr 0.000262048 | gnorm 0.45 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19518
2023-02-11 00:59:44 | INFO | fairseq.trainer | begin training epoch 423
2023-02-11 00:59:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:00:22 | INFO | train_inner | epoch 423:      4 / 5 loss=6.133, ppl=70.18, wps=417681, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=2100, lr=0.000262548, gnorm=0.564, loss_scale=1, train_wall=662, gb_free=5.4, wall=19557
2023-02-11 01:00:23 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2023-02-11 01:00:23 | INFO | train | epoch 423 | loss 6.089 | ppl 68.07 | wps 532430 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2101 | lr 0.000262672 | gnorm 0.386 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19557
2023-02-11 01:00:23 | INFO | fairseq.trainer | begin training epoch 424
2023-02-11 01:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:01:01 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2023-02-11 01:01:01 | INFO | train | epoch 424 | loss 6.083 | ppl 67.79 | wps 560586 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2106 | lr 0.000263297 | gnorm 0.4 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19595
2023-02-11 01:01:01 | INFO | fairseq.trainer | begin training epoch 425
2023-02-11 01:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:01:41 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2023-02-11 01:01:41 | INFO | train | epoch 425 | loss 6.084 | ppl 67.85 | wps 518186 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2111 | lr 0.000263922 | gnorm 0.483 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19635
2023-02-11 01:01:41 | INFO | fairseq.trainer | begin training epoch 426
2023-02-11 01:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:02:20 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2023-02-11 01:02:20 | INFO | train | epoch 426 | loss 6.09 | ppl 68.12 | wps 540749 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2116 | lr 0.000264547 | gnorm 0.686 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19674
2023-02-11 01:02:20 | INFO | fairseq.trainer | begin training epoch 427
2023-02-11 01:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:02:58 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2023-02-11 01:02:58 | INFO | train | epoch 427 | loss 6.114 | ppl 69.26 | wps 549935 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2121 | lr 0.000265172 | gnorm 0.889 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19712
2023-02-11 01:02:58 | INFO | fairseq.trainer | begin training epoch 428
2023-02-11 01:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:03:39 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2023-02-11 01:03:39 | INFO | train | epoch 428 | loss 6.108 | ppl 68.99 | wps 517442 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2126 | lr 0.000265797 | gnorm 0.706 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19753
2023-02-11 01:03:39 | INFO | fairseq.trainer | begin training epoch 429
2023-02-11 01:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:04:19 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2023-02-11 01:04:19 | INFO | train | epoch 429 | loss 6.086 | ppl 67.92 | wps 519119 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2131 | lr 0.000266422 | gnorm 0.457 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19794
2023-02-11 01:04:20 | INFO | fairseq.trainer | begin training epoch 430
2023-02-11 01:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:05:03 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 5.57 | ppl 47.51 | wps 0 | wpb 11230 | bsz 22 | num_updates 2136 | best_loss 5.57
2023-02-11 01:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 2136 updates
2023-02-11 01:05:03 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint430.pt
2023-02-11 01:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint430.pt
2023-02-11 01:06:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint430.pt (epoch 430 @ 2136 updates, score 5.57) (writing took 69.93298372501158 seconds)
2023-02-11 01:06:13 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2023-02-11 01:06:13 | INFO | train | epoch 430 | loss 6.073 | ppl 67.34 | wps 185274 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2136 | lr 0.000267047 | gnorm 0.384 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19907
2023-02-11 01:06:13 | INFO | fairseq.trainer | begin training epoch 431
2023-02-11 01:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:06:54 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2023-02-11 01:06:54 | INFO | train | epoch 431 | loss 6.064 | ppl 66.89 | wps 510489 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2141 | lr 0.000267671 | gnorm 0.356 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19948
2023-02-11 01:06:54 | INFO | fairseq.trainer | begin training epoch 432
2023-02-11 01:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:07:34 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2023-02-11 01:07:34 | INFO | train | epoch 432 | loss 6.06 | ppl 66.73 | wps 531075 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2146 | lr 0.000268296 | gnorm 0.439 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 19988
2023-02-11 01:07:34 | INFO | fairseq.trainer | begin training epoch 433
2023-02-11 01:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:08:11 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2023-02-11 01:08:11 | INFO | train | epoch 433 | loss 6.068 | ppl 67.08 | wps 559650 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2151 | lr 0.000268921 | gnorm 0.609 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20025
2023-02-11 01:08:12 | INFO | fairseq.trainer | begin training epoch 434
2023-02-11 01:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:08:51 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2023-02-11 01:08:51 | INFO | train | epoch 434 | loss 6.063 | ppl 66.88 | wps 534612 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2156 | lr 0.000269546 | gnorm 0.607 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20065
2023-02-11 01:08:52 | INFO | fairseq.trainer | begin training epoch 435
2023-02-11 01:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:09:31 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2023-02-11 01:09:31 | INFO | train | epoch 435 | loss 6.057 | ppl 66.6 | wps 521490 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2161 | lr 0.000270171 | gnorm 0.55 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20105
2023-02-11 01:09:31 | INFO | fairseq.trainer | begin training epoch 436
2023-02-11 01:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:10:09 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2023-02-11 01:10:09 | INFO | train | epoch 436 | loss 6.068 | ppl 67.08 | wps 561409 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2166 | lr 0.000270796 | gnorm 0.723 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20143
2023-02-11 01:10:09 | INFO | fairseq.trainer | begin training epoch 437
2023-02-11 01:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:10:48 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2023-02-11 01:10:48 | INFO | train | epoch 437 | loss 6.056 | ppl 66.54 | wps 526948 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2171 | lr 0.000271421 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20183
2023-02-11 01:10:50 | INFO | fairseq.trainer | begin training epoch 438
2023-02-11 01:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:11:30 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2023-02-11 01:11:30 | INFO | train | epoch 438 | loss 6.058 | ppl 66.61 | wps 511774 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2176 | lr 0.000272046 | gnorm 0.609 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20224
2023-02-11 01:11:30 | INFO | fairseq.trainer | begin training epoch 439
2023-02-11 01:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:12:11 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2023-02-11 01:12:11 | INFO | train | epoch 439 | loss 6.046 | ppl 66.08 | wps 508080 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2181 | lr 0.00027267 | gnorm 0.533 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20265
2023-02-11 01:12:11 | INFO | fairseq.trainer | begin training epoch 440
2023-02-11 01:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:12:54 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 5.543 | ppl 46.63 | wps 0 | wpb 11230 | bsz 22 | num_updates 2186 | best_loss 5.543
2023-02-11 01:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 2186 updates
2023-02-11 01:12:54 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint440.pt
2023-02-11 01:12:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint440.pt
2023-02-11 01:13:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint440.pt (epoch 440 @ 2186 updates, score 5.543) (writing took 64.46859657700406 seconds)
2023-02-11 01:13:59 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2023-02-11 01:13:59 | INFO | train | epoch 440 | loss 6.042 | ppl 65.88 | wps 195167 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2186 | lr 0.000273295 | gnorm 0.511 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20373
2023-02-11 01:13:59 | INFO | fairseq.trainer | begin training epoch 441
2023-02-11 01:13:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:14:38 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2023-02-11 01:14:38 | INFO | train | epoch 441 | loss 6.033 | ppl 65.5 | wps 529849 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2191 | lr 0.00027392 | gnorm 0.46 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20412
2023-02-11 01:14:39 | INFO | fairseq.trainer | begin training epoch 442
2023-02-11 01:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:15:16 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2023-02-11 01:15:16 | INFO | train | epoch 442 | loss 6.039 | ppl 65.77 | wps 563417 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2196 | lr 0.000274545 | gnorm 0.662 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20450
2023-02-11 01:15:16 | INFO | fairseq.trainer | begin training epoch 443
2023-02-11 01:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:15:56 | INFO | train_inner | epoch 443:      4 / 5 loss=6.067, ppl=67.03, wps=450863, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=2200, lr=0.000275045, gnorm=0.559, loss_scale=1, train_wall=662, gb_free=5.4, wall=20490
2023-02-11 01:15:56 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2023-02-11 01:15:56 | INFO | train | epoch 443 | loss 6.041 | ppl 65.85 | wps 521826 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2201 | lr 0.00027517 | gnorm 0.547 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20490
2023-02-11 01:15:56 | INFO | fairseq.trainer | begin training epoch 444
2023-02-11 01:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:16:36 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2023-02-11 01:16:36 | INFO | train | epoch 444 | loss 6.03 | ppl 65.32 | wps 533190 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2206 | lr 0.000275795 | gnorm 0.489 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20530
2023-02-11 01:16:36 | INFO | fairseq.trainer | begin training epoch 445
2023-02-11 01:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:17:14 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2023-02-11 01:17:14 | INFO | train | epoch 445 | loss 6.025 | ppl 65.12 | wps 548266 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2211 | lr 0.00027642 | gnorm 0.522 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20568
2023-02-11 01:17:14 | INFO | fairseq.trainer | begin training epoch 446
2023-02-11 01:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:17:54 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2023-02-11 01:17:54 | INFO | train | epoch 446 | loss 6.033 | ppl 65.49 | wps 527920 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2216 | lr 0.000277045 | gnorm 0.689 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20608
2023-02-11 01:17:54 | INFO | fairseq.trainer | begin training epoch 447
2023-02-11 01:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:18:35 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2023-02-11 01:18:35 | INFO | train | epoch 447 | loss 6.057 | ppl 66.56 | wps 513251 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2221 | lr 0.000277669 | gnorm 0.894 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20649
2023-02-11 01:18:35 | INFO | fairseq.trainer | begin training epoch 448
2023-02-11 01:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:19:16 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2023-02-11 01:19:16 | INFO | train | epoch 448 | loss 6.045 | ppl 66.02 | wps 510416 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2226 | lr 0.000278294 | gnorm 0.588 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20690
2023-02-11 01:19:16 | INFO | fairseq.trainer | begin training epoch 449
2023-02-11 01:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:19:56 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2023-02-11 01:19:56 | INFO | train | epoch 449 | loss 6.023 | ppl 65.02 | wps 522922 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2231 | lr 0.000278919 | gnorm 0.432 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20730
2023-02-11 01:19:56 | INFO | fairseq.trainer | begin training epoch 450
2023-02-11 01:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:20:39 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 5.532 | ppl 46.27 | wps 0 | wpb 11230 | bsz 22 | num_updates 2236 | best_loss 5.532
2023-02-11 01:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 2236 updates
2023-02-11 01:20:39 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint450.pt
2023-02-11 01:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint450.pt
2023-02-11 01:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint450.pt (epoch 450 @ 2236 updates, score 5.532) (writing took 62.746587224974064 seconds)
2023-02-11 01:21:42 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2023-02-11 01:21:42 | INFO | train | epoch 450 | loss 6.011 | ppl 64.5 | wps 198402 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2236 | lr 0.000279544 | gnorm 0.39 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20836
2023-02-11 01:21:42 | INFO | fairseq.trainer | begin training epoch 451
2023-02-11 01:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:22:28 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2023-02-11 01:22:28 | INFO | train | epoch 451 | loss 6.003 | ppl 64.12 | wps 456749 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2241 | lr 0.000280169 | gnorm 0.394 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20882
2023-02-11 01:22:28 | INFO | fairseq.trainer | begin training epoch 452
2023-02-11 01:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:23:06 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2023-02-11 01:23:06 | INFO | train | epoch 452 | loss 6.003 | ppl 64.13 | wps 553336 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2246 | lr 0.000280794 | gnorm 0.479 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20920
2023-02-11 01:23:06 | INFO | fairseq.trainer | begin training epoch 453
2023-02-11 01:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:23:46 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2023-02-11 01:23:46 | INFO | train | epoch 453 | loss 6.007 | ppl 64.31 | wps 534023 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2251 | lr 0.000281419 | gnorm 0.6 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20960
2023-02-11 01:23:46 | INFO | fairseq.trainer | begin training epoch 454
2023-02-11 01:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:24:23 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2023-02-11 01:24:23 | INFO | train | epoch 454 | loss 6.014 | ppl 64.61 | wps 559169 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2256 | lr 0.000282044 | gnorm 0.69 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 20997
2023-02-11 01:24:23 | INFO | fairseq.trainer | begin training epoch 455
2023-02-11 01:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:25:03 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2023-02-11 01:25:03 | INFO | train | epoch 455 | loss 6.012 | ppl 64.52 | wps 526987 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2261 | lr 0.000282668 | gnorm 0.647 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21037
2023-02-11 01:25:03 | INFO | fairseq.trainer | begin training epoch 456
2023-02-11 01:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:25:40 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2023-02-11 01:25:40 | INFO | train | epoch 456 | loss 6.003 | ppl 64.13 | wps 567756 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2266 | lr 0.000283293 | gnorm 0.611 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21074
2023-02-11 01:25:40 | INFO | fairseq.trainer | begin training epoch 457
2023-02-11 01:25:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:26:22 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2023-02-11 01:26:22 | INFO | train | epoch 457 | loss 5.991 | ppl 63.62 | wps 506746 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2271 | lr 0.000283918 | gnorm 0.483 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21116
2023-02-11 01:26:22 | INFO | fairseq.trainer | begin training epoch 458
2023-02-11 01:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:27:03 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2023-02-11 01:27:03 | INFO | train | epoch 458 | loss 5.99 | ppl 63.55 | wps 508890 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2276 | lr 0.000284543 | gnorm 0.527 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 21157
2023-02-11 01:27:03 | INFO | fairseq.trainer | begin training epoch 459
2023-02-11 01:27:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:27:43 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2023-02-11 01:27:43 | INFO | train | epoch 459 | loss 5.985 | ppl 63.33 | wps 532459 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2281 | lr 0.000285168 | gnorm 0.547 | loss_scale 2 | train_wall 33 | gb_free 36.9 | wall 21197
2023-02-11 01:27:43 | INFO | fairseq.trainer | begin training epoch 460
2023-02-11 01:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:28:30 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 5.513 | ppl 45.66 | wps 0 | wpb 11230 | bsz 22 | num_updates 2286 | best_loss 5.513
2023-02-11 01:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 2286 updates
2023-02-11 01:28:30 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint460.pt
2023-02-11 01:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint460.pt
2023-02-11 01:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint460.pt (epoch 460 @ 2286 updates, score 5.513) (writing took 71.36145328197745 seconds)
2023-02-11 01:29:41 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2023-02-11 01:29:41 | INFO | train | epoch 460 | loss 5.991 | ppl 63.61 | wps 176937 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2286 | lr 0.000285793 | gnorm 0.57 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 21315
2023-02-11 01:29:42 | INFO | fairseq.trainer | begin training epoch 461
2023-02-11 01:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:30:22 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2023-02-11 01:30:22 | INFO | train | epoch 461 | loss 5.984 | ppl 63.28 | wps 516905 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2291 | lr 0.000286418 | gnorm 0.517 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 21356
2023-02-11 01:30:22 | INFO | fairseq.trainer | begin training epoch 462
2023-02-11 01:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:31:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 01:31:02 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2023-02-11 01:31:02 | INFO | train | epoch 462 | loss 5.983 | ppl 63.23 | wps 397842 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 2295 | lr 0.000286918 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.4 | wall 21396
2023-02-11 01:31:02 | INFO | fairseq.trainer | begin training epoch 463
2023-02-11 01:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:31:40 | INFO | train_inner | epoch 463:      5 / 5 loss=6.009, ppl=64.38, wps=440151, ups=0.11, wpb=4.15596e+06, bsz=8117.2, num_updates=2300, lr=0.000287543, gnorm=0.557, loss_scale=1, train_wall=663, gb_free=5.6, wall=21434
2023-02-11 01:31:40 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2023-02-11 01:31:40 | INFO | train | epoch 463 | loss 5.978 | ppl 63.03 | wps 554762 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2300 | lr 0.000287543 | gnorm 0.489 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21434
2023-02-11 01:31:40 | INFO | fairseq.trainer | begin training epoch 464
2023-02-11 01:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:32:19 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2023-02-11 01:32:19 | INFO | train | epoch 464 | loss 5.967 | ppl 62.57 | wps 535481 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2305 | lr 0.000288167 | gnorm 0.408 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21473
2023-02-11 01:32:19 | INFO | fairseq.trainer | begin training epoch 465
2023-02-11 01:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:33:00 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2023-02-11 01:33:00 | INFO | train | epoch 465 | loss 5.965 | ppl 62.48 | wps 513831 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2310 | lr 0.000288792 | gnorm 0.514 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21514
2023-02-11 01:33:00 | INFO | fairseq.trainer | begin training epoch 466
2023-02-11 01:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:33:41 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2023-02-11 01:33:41 | INFO | train | epoch 466 | loss 5.968 | ppl 62.59 | wps 508066 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2315 | lr 0.000289417 | gnorm 0.61 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21555
2023-02-11 01:33:42 | INFO | fairseq.trainer | begin training epoch 467
2023-02-11 01:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:34:22 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2023-02-11 01:34:22 | INFO | train | epoch 467 | loss 5.973 | ppl 62.81 | wps 523887 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2320 | lr 0.000290042 | gnorm 0.67 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21596
2023-02-11 01:34:22 | INFO | fairseq.trainer | begin training epoch 468
2023-02-11 01:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:34:58 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2023-02-11 01:34:58 | INFO | train | epoch 468 | loss 5.967 | ppl 62.53 | wps 569507 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2325 | lr 0.000290667 | gnorm 0.593 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21632
2023-02-11 01:34:59 | INFO | fairseq.trainer | begin training epoch 469
2023-02-11 01:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:35:39 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2023-02-11 01:35:39 | INFO | train | epoch 469 | loss 5.959 | ppl 62.23 | wps 517536 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2330 | lr 0.000291292 | gnorm 0.511 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21673
2023-02-11 01:35:39 | INFO | fairseq.trainer | begin training epoch 470
2023-02-11 01:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:36:22 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 5.495 | ppl 45.09 | wps 0 | wpb 11230 | bsz 22 | num_updates 2335 | best_loss 5.495
2023-02-11 01:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 2335 updates
2023-02-11 01:36:22 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint470.pt
2023-02-11 01:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint470.pt
2023-02-11 01:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint470.pt (epoch 470 @ 2335 updates, score 5.495) (writing took 67.64508739300072 seconds)
2023-02-11 01:37:30 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2023-02-11 01:37:30 | INFO | train | epoch 470 | loss 5.957 | ppl 62.12 | wps 189418 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2335 | lr 0.000291917 | gnorm 0.55 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21784
2023-02-11 01:37:30 | INFO | fairseq.trainer | begin training epoch 471
2023-02-11 01:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:38:12 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2023-02-11 01:38:12 | INFO | train | epoch 471 | loss 5.951 | ppl 61.85 | wps 507355 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2340 | lr 0.000292542 | gnorm 0.462 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21826
2023-02-11 01:38:12 | INFO | fairseq.trainer | begin training epoch 472
2023-02-11 01:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:38:49 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2023-02-11 01:38:49 | INFO | train | epoch 472 | loss 5.942 | ppl 61.48 | wps 564823 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2345 | lr 0.000293166 | gnorm 0.414 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21863
2023-02-11 01:38:49 | INFO | fairseq.trainer | begin training epoch 473
2023-02-11 01:38:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:39:29 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2023-02-11 01:39:29 | INFO | train | epoch 473 | loss 5.94 | ppl 61.38 | wps 523877 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2350 | lr 0.000293791 | gnorm 0.492 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21903
2023-02-11 01:39:29 | INFO | fairseq.trainer | begin training epoch 474
2023-02-11 01:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:40:10 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2023-02-11 01:40:10 | INFO | train | epoch 474 | loss 5.946 | ppl 61.64 | wps 512414 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2355 | lr 0.000294416 | gnorm 0.637 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21944
2023-02-11 01:40:10 | INFO | fairseq.trainer | begin training epoch 475
2023-02-11 01:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:40:51 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2023-02-11 01:40:51 | INFO | train | epoch 475 | loss 5.961 | ppl 62.28 | wps 510513 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2360 | lr 0.000295041 | gnorm 0.712 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 21985
2023-02-11 01:40:51 | INFO | fairseq.trainer | begin training epoch 476
2023-02-11 01:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:41:32 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2023-02-11 01:41:32 | INFO | train | epoch 476 | loss 5.96 | ppl 62.26 | wps 520884 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2365 | lr 0.000295666 | gnorm 0.724 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22026
2023-02-11 01:41:32 | INFO | fairseq.trainer | begin training epoch 477
2023-02-11 01:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:42:12 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2023-02-11 01:42:12 | INFO | train | epoch 477 | loss 5.952 | ppl 61.9 | wps 515309 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2370 | lr 0.000296291 | gnorm 0.611 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22066
2023-02-11 01:42:13 | INFO | fairseq.trainer | begin training epoch 478
2023-02-11 01:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:42:50 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2023-02-11 01:42:50 | INFO | train | epoch 478 | loss 5.946 | ppl 61.65 | wps 563743 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2375 | lr 0.000296916 | gnorm 0.548 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22104
2023-02-11 01:42:50 | INFO | fairseq.trainer | begin training epoch 479
2023-02-11 01:42:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:43:29 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2023-02-11 01:43:29 | INFO | train | epoch 479 | loss 5.934 | ppl 61.13 | wps 530398 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2380 | lr 0.000297541 | gnorm 0.462 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22143
2023-02-11 01:43:31 | INFO | fairseq.trainer | begin training epoch 480
2023-02-11 01:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:44:18 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 5.468 | ppl 44.28 | wps 0 | wpb 11230 | bsz 22 | num_updates 2385 | best_loss 5.468
2023-02-11 01:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 2385 updates
2023-02-11 01:44:18 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint480.pt
2023-02-11 01:44:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint480.pt
2023-02-11 01:45:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint480.pt (epoch 480 @ 2385 updates, score 5.468) (writing took 69.4549325669941 seconds)
2023-02-11 01:45:28 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2023-02-11 01:45:28 | INFO | train | epoch 480 | loss 5.924 | ppl 60.71 | wps 177839 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2385 | lr 0.000298165 | gnorm 0.411 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22262
2023-02-11 01:45:28 | INFO | fairseq.trainer | begin training epoch 481
2023-02-11 01:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:46:12 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2023-02-11 01:46:12 | INFO | train | epoch 481 | loss 5.916 | ppl 60.39 | wps 475949 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2390 | lr 0.00029879 | gnorm 0.362 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22306
2023-02-11 01:46:12 | INFO | fairseq.trainer | begin training epoch 482
2023-02-11 01:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:46:50 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2023-02-11 01:46:50 | INFO | train | epoch 482 | loss 5.91 | ppl 60.13 | wps 551823 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2395 | lr 0.000299415 | gnorm 0.331 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22344
2023-02-11 01:46:50 | INFO | fairseq.trainer | begin training epoch 483
2023-02-11 01:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:47:30 | INFO | train_inner | epoch 483:      5 / 5 loss=5.948, ppl=61.75, wps=442618, ups=0.11, wpb=4.20675e+06, bsz=8216.4, num_updates=2400, lr=0.00030004, gnorm=0.536, loss_scale=1, train_wall=662, gb_free=5.6, wall=22384
2023-02-11 01:47:30 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2023-02-11 01:47:30 | INFO | train | epoch 483 | loss 5.929 | ppl 60.93 | wps 523703 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2400 | lr 0.00030004 | gnorm 0.704 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22384
2023-02-11 01:47:30 | INFO | fairseq.trainer | begin training epoch 484
2023-02-11 01:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:48:11 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2023-02-11 01:48:11 | INFO | train | epoch 484 | loss 5.934 | ppl 61.14 | wps 509151 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2405 | lr 0.000300665 | gnorm 0.721 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22426
2023-02-11 01:48:12 | INFO | fairseq.trainer | begin training epoch 485
2023-02-11 01:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:48:52 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2023-02-11 01:48:52 | INFO | train | epoch 485 | loss 5.942 | ppl 61.46 | wps 516481 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2410 | lr 0.00030129 | gnorm 0.709 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22466
2023-02-11 01:48:52 | INFO | fairseq.trainer | begin training epoch 486
2023-02-11 01:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:49:33 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2023-02-11 01:49:33 | INFO | train | epoch 486 | loss 5.926 | ppl 60.81 | wps 516071 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2415 | lr 0.000301915 | gnorm 0.584 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22507
2023-02-11 01:49:34 | INFO | fairseq.trainer | begin training epoch 487
2023-02-11 01:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:50:14 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2023-02-11 01:50:14 | INFO | train | epoch 487 | loss 5.913 | ppl 60.26 | wps 507428 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2420 | lr 0.00030254 | gnorm 0.467 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22548
2023-02-11 01:50:15 | INFO | fairseq.trainer | begin training epoch 488
2023-02-11 01:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:50:55 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2023-02-11 01:50:55 | INFO | train | epoch 488 | loss 5.905 | ppl 59.93 | wps 515479 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2425 | lr 0.000303164 | gnorm 0.492 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22589
2023-02-11 01:50:55 | INFO | fairseq.trainer | begin training epoch 489
2023-02-11 01:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:51:35 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2023-02-11 01:51:35 | INFO | train | epoch 489 | loss 5.903 | ppl 59.85 | wps 524343 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2430 | lr 0.000303789 | gnorm 0.504 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22629
2023-02-11 01:51:36 | INFO | fairseq.trainer | begin training epoch 490
2023-02-11 01:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 01:52:19 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 5.454 | ppl 43.83 | wps 0 | wpb 11230 | bsz 22 | num_updates 2435 | best_loss 5.454
2023-02-11 01:52:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 2435 updates
2023-02-11 01:52:19 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint490.pt
2023-02-11 01:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint490.pt
2023-02-11 01:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint490.pt (epoch 490 @ 2435 updates, score 5.454) (writing took 64.05914712199592 seconds)
2023-02-11 01:53:23 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2023-02-11 01:53:23 | INFO | train | epoch 490 | loss 5.898 | ppl 59.64 | wps 195351 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2435 | lr 0.000304414 | gnorm 0.471 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22737
2023-02-11 01:53:23 | INFO | fairseq.trainer | begin training epoch 491
2023-02-11 01:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:54:41 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2023-02-11 01:54:41 | INFO | train | epoch 491 | loss 5.889 | ppl 59.28 | wps 270943 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2440 | lr 0.000305039 | gnorm 0.376 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22815
2023-02-11 01:54:41 | INFO | fairseq.trainer | begin training epoch 492
2023-02-11 01:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:55:22 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2023-02-11 01:55:22 | INFO | train | epoch 492 | loss 5.889 | ppl 59.27 | wps 510551 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2445 | lr 0.000305664 | gnorm 0.506 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22856
2023-02-11 01:55:22 | INFO | fairseq.trainer | begin training epoch 493
2023-02-11 01:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:56:02 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2023-02-11 01:56:02 | INFO | train | epoch 493 | loss 5.898 | ppl 59.65 | wps 521676 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2450 | lr 0.000306289 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22896
2023-02-11 01:56:03 | INFO | fairseq.trainer | begin training epoch 494
2023-02-11 01:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:56:43 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2023-02-11 01:56:43 | INFO | train | epoch 494 | loss 5.902 | ppl 59.78 | wps 519291 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2455 | lr 0.000306914 | gnorm 0.656 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22937
2023-02-11 01:56:43 | INFO | fairseq.trainer | begin training epoch 495
2023-02-11 01:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:57:20 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2023-02-11 01:57:20 | INFO | train | epoch 495 | loss 5.894 | ppl 59.48 | wps 562133 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2460 | lr 0.000307539 | gnorm 0.584 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 22974
2023-02-11 01:57:20 | INFO | fairseq.trainer | begin training epoch 496
2023-02-11 01:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:58:00 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2023-02-11 01:58:00 | INFO | train | epoch 496 | loss 5.895 | ppl 59.52 | wps 525148 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2465 | lr 0.000308163 | gnorm 0.629 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23014
2023-02-11 01:58:00 | INFO | fairseq.trainer | begin training epoch 497
2023-02-11 01:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:58:40 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2023-02-11 01:58:40 | INFO | train | epoch 497 | loss 5.886 | ppl 59.13 | wps 526671 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2470 | lr 0.000308788 | gnorm 0.506 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23054
2023-02-11 01:58:40 | INFO | fairseq.trainer | begin training epoch 498
2023-02-11 01:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:59:18 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2023-02-11 01:59:18 | INFO | train | epoch 498 | loss 5.887 | ppl 59.16 | wps 554014 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2475 | lr 0.000309413 | gnorm 0.636 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23092
2023-02-11 01:59:18 | INFO | fairseq.trainer | begin training epoch 499
2023-02-11 01:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 01:59:58 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2023-02-11 01:59:58 | INFO | train | epoch 499 | loss 5.885 | ppl 59.1 | wps 526219 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2480 | lr 0.000310038 | gnorm 0.558 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23132
2023-02-11 01:59:58 | INFO | fairseq.trainer | begin training epoch 500
2023-02-11 01:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:00:47 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 5.428 | ppl 43.06 | wps 0 | wpb 11230 | bsz 22 | num_updates 2485 | best_loss 5.428
2023-02-11 02:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 2485 updates
2023-02-11 02:00:47 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint500.pt
2023-02-11 02:00:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint500.pt
2023-02-11 02:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint500.pt (epoch 500 @ 2485 updates, score 5.428) (writing took 60.82540807797341 seconds)
2023-02-11 02:01:47 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2023-02-11 02:01:47 | INFO | train | epoch 500 | loss 5.872 | ppl 58.55 | wps 192345 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2485 | lr 0.000310663 | gnorm 0.399 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23241
2023-02-11 02:01:48 | INFO | fairseq.trainer | begin training epoch 501
2023-02-11 02:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:02:30 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2023-02-11 02:02:30 | INFO | train | epoch 501 | loss 5.865 | ppl 58.3 | wps 494038 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2490 | lr 0.000311288 | gnorm 0.396 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23284
2023-02-11 02:02:30 | INFO | fairseq.trainer | begin training epoch 502
2023-02-11 02:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:03:08 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2023-02-11 02:03:08 | INFO | train | epoch 502 | loss 5.869 | ppl 58.43 | wps 554741 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2495 | lr 0.000311913 | gnorm 0.526 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23322
2023-02-11 02:03:08 | INFO | fairseq.trainer | begin training epoch 503
2023-02-11 02:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:03:48 | INFO | train_inner | epoch 503:      5 / 5 loss=5.896, ppl=59.55, wps=430270, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=2500, lr=0.000312538, gnorm=0.544, loss_scale=1, train_wall=663, gb_free=5.6, wall=23362
2023-02-11 02:03:48 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2023-02-11 02:03:48 | INFO | train | epoch 503 | loss 5.867 | ppl 58.37 | wps 525997 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2500 | lr 0.000312538 | gnorm 0.548 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23362
2023-02-11 02:03:48 | INFO | fairseq.trainer | begin training epoch 504
2023-02-11 02:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:04:25 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2023-02-11 02:04:25 | INFO | train | epoch 504 | loss 5.878 | ppl 58.81 | wps 564142 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2505 | lr 0.000313162 | gnorm 0.766 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23399
2023-02-11 02:04:25 | INFO | fairseq.trainer | begin training epoch 505
2023-02-11 02:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:05:05 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2023-02-11 02:05:05 | INFO | train | epoch 505 | loss 5.883 | ppl 59.03 | wps 527529 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2510 | lr 0.000313787 | gnorm 0.672 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23439
2023-02-11 02:05:05 | INFO | fairseq.trainer | begin training epoch 506
2023-02-11 02:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:05:45 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2023-02-11 02:05:45 | INFO | train | epoch 506 | loss 5.87 | ppl 58.5 | wps 520757 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2515 | lr 0.000314412 | gnorm 0.544 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23479
2023-02-11 02:05:46 | INFO | fairseq.trainer | begin training epoch 507
2023-02-11 02:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:06:23 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2023-02-11 02:06:23 | INFO | train | epoch 507 | loss 5.862 | ppl 58.17 | wps 556916 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2520 | lr 0.000315037 | gnorm 0.48 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23517
2023-02-11 02:06:23 | INFO | fairseq.trainer | begin training epoch 508
2023-02-11 02:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:07:03 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2023-02-11 02:07:03 | INFO | train | epoch 508 | loss 5.854 | ppl 57.83 | wps 532041 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2525 | lr 0.000315662 | gnorm 0.462 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23557
2023-02-11 02:07:03 | INFO | fairseq.trainer | begin training epoch 509
2023-02-11 02:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:07:43 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2023-02-11 02:07:43 | INFO | train | epoch 509 | loss 5.851 | ppl 57.7 | wps 516667 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2530 | lr 0.000316287 | gnorm 0.54 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23597
2023-02-11 02:07:44 | INFO | fairseq.trainer | begin training epoch 510
2023-02-11 02:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:08:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:08:27 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 5.414 | ppl 42.64 | wps 0 | wpb 11230 | bsz 22 | num_updates 2535 | best_loss 5.414
2023-02-11 02:08:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 2535 updates
2023-02-11 02:08:27 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint510.pt
2023-02-11 02:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint510.pt
2023-02-11 02:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint510.pt (epoch 510 @ 2535 updates, score 5.414) (writing took 62.79386983299628 seconds)
2023-02-11 02:09:30 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2023-02-11 02:09:30 | INFO | train | epoch 510 | loss 5.856 | ppl 57.94 | wps 198311 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2535 | lr 0.000316912 | gnorm 0.547 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23704
2023-02-11 02:09:30 | INFO | fairseq.trainer | begin training epoch 511
2023-02-11 02:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:10:11 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2023-02-11 02:10:11 | INFO | train | epoch 511 | loss 5.845 | ppl 57.47 | wps 510795 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2540 | lr 0.000317537 | gnorm 0.44 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23745
2023-02-11 02:10:11 | INFO | fairseq.trainer | begin training epoch 512
2023-02-11 02:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:10:48 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2023-02-11 02:10:48 | INFO | train | epoch 512 | loss 5.842 | ppl 57.34 | wps 563488 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2545 | lr 0.000318161 | gnorm 0.519 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 23782
2023-02-11 02:10:48 | INFO | fairseq.trainer | begin training epoch 513
2023-02-11 02:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:11:29 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2023-02-11 02:11:29 | INFO | train | epoch 513 | loss 5.847 | ppl 57.55 | wps 508730 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2550 | lr 0.000318786 | gnorm 0.568 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 23823
2023-02-11 02:11:30 | INFO | fairseq.trainer | begin training epoch 514
2023-02-11 02:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:12:10 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2023-02-11 02:12:10 | INFO | train | epoch 514 | loss 5.842 | ppl 57.36 | wps 512529 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2555 | lr 0.000319411 | gnorm 0.514 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 23864
2023-02-11 02:12:11 | INFO | fairseq.trainer | begin training epoch 515
2023-02-11 02:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:12:51 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2023-02-11 02:12:51 | INFO | train | epoch 515 | loss 5.838 | ppl 57.21 | wps 513085 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2560 | lr 0.000320036 | gnorm 0.552 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 23905
2023-02-11 02:12:52 | INFO | fairseq.trainer | begin training epoch 516
2023-02-11 02:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:13:32 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2023-02-11 02:13:32 | INFO | train | epoch 516 | loss 5.835 | ppl 57.1 | wps 513358 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2565 | lr 0.000320661 | gnorm 0.527 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 23946
2023-02-11 02:13:33 | INFO | fairseq.trainer | begin training epoch 517
2023-02-11 02:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:14:13 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2023-02-11 02:14:13 | INFO | train | epoch 517 | loss 5.829 | ppl 56.85 | wps 521576 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2570 | lr 0.000321286 | gnorm 0.482 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 23987
2023-02-11 02:14:14 | INFO | fairseq.trainer | begin training epoch 518
2023-02-11 02:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:14:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 02:14:54 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2023-02-11 02:14:54 | INFO | train | epoch 518 | loss 5.843 | ppl 57.4 | wps 385942 | ups 0.1 | wpb 3.95284e+06 | bsz 7720.5 | num_updates 2574 | lr 0.000321786 | gnorm 0.7 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24028
2023-02-11 02:14:55 | INFO | fairseq.trainer | begin training epoch 519
2023-02-11 02:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:15:36 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2023-02-11 02:15:36 | INFO | train | epoch 519 | loss 5.836 | ppl 57.14 | wps 500159 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2579 | lr 0.000322411 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24070
2023-02-11 02:15:36 | INFO | fairseq.trainer | begin training epoch 520
2023-02-11 02:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:16:23 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 5.4 | ppl 42.21 | wps 0 | wpb 11230 | bsz 22 | num_updates 2584 | best_loss 5.4
2023-02-11 02:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 2584 updates
2023-02-11 02:16:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint520.pt
2023-02-11 02:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint520.pt
2023-02-11 02:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint520.pt (epoch 520 @ 2584 updates, score 5.4) (writing took 60.5874288600171 seconds)
2023-02-11 02:17:24 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2023-02-11 02:17:24 | INFO | train | epoch 520 | loss 5.833 | ppl 57.01 | wps 194753 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2584 | lr 0.000323035 | gnorm 0.623 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24178
2023-02-11 02:17:24 | INFO | fairseq.trainer | begin training epoch 521
2023-02-11 02:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:18:04 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2023-02-11 02:18:04 | INFO | train | epoch 521 | loss 5.829 | ppl 56.87 | wps 522886 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2589 | lr 0.00032366 | gnorm 0.558 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24218
2023-02-11 02:18:04 | INFO | fairseq.trainer | begin training epoch 522
2023-02-11 02:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:18:45 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2023-02-11 02:18:45 | INFO | train | epoch 522 | loss 5.822 | ppl 56.55 | wps 513758 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2594 | lr 0.000324285 | gnorm 0.505 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24259
2023-02-11 02:18:45 | INFO | fairseq.trainer | begin training epoch 523
2023-02-11 02:18:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:19:25 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2023-02-11 02:19:25 | INFO | train | epoch 523 | loss 5.813 | ppl 56.21 | wps 523714 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2599 | lr 0.00032491 | gnorm 0.399 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24299
2023-02-11 02:19:25 | INFO | fairseq.trainer | begin training epoch 524
2023-02-11 02:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:19:41 | INFO | train_inner | epoch 524:      1 / 5 loss=5.845, ppl=57.48, wps=441509, ups=0.1, wpb=4.20696e+06, bsz=8216.8, num_updates=2600, lr=0.000325035, gnorm=0.547, loss_scale=1, train_wall=670, gb_free=5.4, wall=24315
2023-02-11 02:20:06 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2023-02-11 02:20:06 | INFO | train | epoch 524 | loss 5.813 | ppl 56.22 | wps 513425 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2604 | lr 0.000325535 | gnorm 0.476 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24340
2023-02-11 02:20:06 | INFO | fairseq.trainer | begin training epoch 525
2023-02-11 02:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:20:48 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2023-02-11 02:20:48 | INFO | train | epoch 525 | loss 5.827 | ppl 56.75 | wps 505691 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2609 | lr 0.00032616 | gnorm 0.71 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24382
2023-02-11 02:20:48 | INFO | fairseq.trainer | begin training epoch 526
2023-02-11 02:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:21:28 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2023-02-11 02:21:28 | INFO | train | epoch 526 | loss 5.829 | ppl 56.86 | wps 519514 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2614 | lr 0.000326785 | gnorm 0.624 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24422
2023-02-11 02:21:28 | INFO | fairseq.trainer | begin training epoch 527
2023-02-11 02:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:22:09 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2023-02-11 02:22:09 | INFO | train | epoch 527 | loss 5.815 | ppl 56.3 | wps 511722 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2619 | lr 0.00032741 | gnorm 0.51 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24463
2023-02-11 02:22:09 | INFO | fairseq.trainer | begin training epoch 528
2023-02-11 02:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:22:51 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2023-02-11 02:22:51 | INFO | train | epoch 528 | loss 5.811 | ppl 56.12 | wps 509073 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2624 | lr 0.000328034 | gnorm 0.519 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24505
2023-02-11 02:22:51 | INFO | fairseq.trainer | begin training epoch 529
2023-02-11 02:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:23:31 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2023-02-11 02:23:31 | INFO | train | epoch 529 | loss 5.804 | ppl 55.85 | wps 521430 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2629 | lr 0.000328659 | gnorm 0.475 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24545
2023-02-11 02:23:31 | INFO | fairseq.trainer | begin training epoch 530
2023-02-11 02:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:24:15 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 5.386 | ppl 41.8 | wps 0 | wpb 11230 | bsz 22 | num_updates 2634 | best_loss 5.386
2023-02-11 02:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 2634 updates
2023-02-11 02:24:15 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint530.pt
2023-02-11 02:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint530.pt
2023-02-11 02:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint530.pt (epoch 530 @ 2634 updates, score 5.386) (writing took 68.07847847600351 seconds)
2023-02-11 02:25:23 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2023-02-11 02:25:23 | INFO | train | epoch 530 | loss 5.807 | ppl 55.99 | wps 187499 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2634 | lr 0.000329284 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24657
2023-02-11 02:25:23 | INFO | fairseq.trainer | begin training epoch 531
2023-02-11 02:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:26:08 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2023-02-11 02:26:08 | INFO | train | epoch 531 | loss 5.808 | ppl 56.02 | wps 467518 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2639 | lr 0.000329909 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24702
2023-02-11 02:26:08 | INFO | fairseq.trainer | begin training epoch 532
2023-02-11 02:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:26:46 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2023-02-11 02:26:46 | INFO | train | epoch 532 | loss 5.802 | ppl 55.77 | wps 552886 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2644 | lr 0.000330534 | gnorm 0.529 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24740
2023-02-11 02:26:46 | INFO | fairseq.trainer | begin training epoch 533
2023-02-11 02:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:27:26 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2023-02-11 02:27:26 | INFO | train | epoch 533 | loss 5.795 | ppl 55.54 | wps 522665 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2649 | lr 0.000331159 | gnorm 0.469 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24780
2023-02-11 02:27:27 | INFO | fairseq.trainer | begin training epoch 534
2023-02-11 02:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:28:07 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2023-02-11 02:28:07 | INFO | train | epoch 534 | loss 5.786 | ppl 55.19 | wps 513801 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2654 | lr 0.000331784 | gnorm 0.423 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24821
2023-02-11 02:28:07 | INFO | fairseq.trainer | begin training epoch 535
2023-02-11 02:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:28:48 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2023-02-11 02:28:48 | INFO | train | epoch 535 | loss 5.79 | ppl 55.32 | wps 514566 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2659 | lr 0.000332409 | gnorm 0.548 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24862
2023-02-11 02:28:49 | INFO | fairseq.trainer | begin training epoch 536
2023-02-11 02:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:29:29 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2023-02-11 02:29:29 | INFO | train | epoch 536 | loss 5.794 | ppl 55.47 | wps 514504 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2664 | lr 0.000333033 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24903
2023-02-11 02:29:29 | INFO | fairseq.trainer | begin training epoch 537
2023-02-11 02:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:30:07 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2023-02-11 02:30:07 | INFO | train | epoch 537 | loss 5.785 | ppl 55.15 | wps 558092 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2669 | lr 0.000333658 | gnorm 0.468 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24941
2023-02-11 02:30:07 | INFO | fairseq.trainer | begin training epoch 538
2023-02-11 02:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:30:46 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2023-02-11 02:30:46 | INFO | train | epoch 538 | loss 5.778 | ppl 54.86 | wps 532285 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2674 | lr 0.000334283 | gnorm 0.442 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 24980
2023-02-11 02:30:47 | INFO | fairseq.trainer | begin training epoch 539
2023-02-11 02:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:31:27 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2023-02-11 02:31:27 | INFO | train | epoch 539 | loss 5.776 | ppl 54.8 | wps 517206 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2679 | lr 0.000334908 | gnorm 0.535 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25021
2023-02-11 02:31:27 | INFO | fairseq.trainer | begin training epoch 540
2023-02-11 02:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:32:15 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 5.384 | ppl 41.75 | wps 0 | wpb 11230 | bsz 22 | num_updates 2684 | best_loss 5.384
2023-02-11 02:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 2684 updates
2023-02-11 02:32:15 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint540.pt
2023-02-11 02:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint540.pt
2023-02-11 02:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint540.pt (epoch 540 @ 2684 updates, score 5.384) (writing took 61.17646169100772 seconds)
2023-02-11 02:33:16 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2023-02-11 02:33:16 | INFO | train | epoch 540 | loss 5.788 | ppl 55.24 | wps 192445 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2684 | lr 0.000335533 | gnorm 0.684 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25130
2023-02-11 02:33:16 | INFO | fairseq.trainer | begin training epoch 541
2023-02-11 02:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:34:00 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2023-02-11 02:34:00 | INFO | train | epoch 541 | loss 5.794 | ppl 55.49 | wps 477810 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2689 | lr 0.000336158 | gnorm 0.68 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25174
2023-02-11 02:34:01 | INFO | fairseq.trainer | begin training epoch 542
2023-02-11 02:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:34:37 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2023-02-11 02:34:37 | INFO | train | epoch 542 | loss 5.791 | ppl 55.37 | wps 570393 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2694 | lr 0.000336783 | gnorm 0.643 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25211
2023-02-11 02:34:37 | INFO | fairseq.trainer | begin training epoch 543
2023-02-11 02:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:35:18 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2023-02-11 02:35:18 | INFO | train | epoch 543 | loss 5.792 | ppl 55.39 | wps 516632 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2699 | lr 0.000337408 | gnorm 0.675 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25252
2023-02-11 02:35:18 | INFO | fairseq.trainer | begin training epoch 544
2023-02-11 02:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:35:33 | INFO | train_inner | epoch 544:      1 / 5 loss=5.799, ppl=55.67, wps=441678, ups=0.11, wpb=4.20594e+06, bsz=8214.8, num_updates=2700, lr=0.000337533, gnorm=0.559, loss_scale=1, train_wall=662, gb_free=5.4, wall=25267
2023-02-11 02:35:58 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2023-02-11 02:35:58 | INFO | train | epoch 544 | loss 5.775 | ppl 54.75 | wps 519274 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2704 | lr 0.000338032 | gnorm 0.459 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25292
2023-02-11 02:35:59 | INFO | fairseq.trainer | begin training epoch 545
2023-02-11 02:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:36:40 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2023-02-11 02:36:40 | INFO | train | epoch 545 | loss 5.764 | ppl 54.34 | wps 510008 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2709 | lr 0.000338657 | gnorm 0.35 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25334
2023-02-11 02:36:40 | INFO | fairseq.trainer | begin training epoch 546
2023-02-11 02:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:37:21 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2023-02-11 02:37:21 | INFO | train | epoch 546 | loss 5.763 | ppl 54.29 | wps 513896 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2714 | lr 0.000339282 | gnorm 0.465 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25375
2023-02-11 02:37:21 | INFO | fairseq.trainer | begin training epoch 547
2023-02-11 02:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:38:01 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2023-02-11 02:38:01 | INFO | train | epoch 547 | loss 5.762 | ppl 54.28 | wps 515807 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2719 | lr 0.000339907 | gnorm 0.519 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25415
2023-02-11 02:38:02 | INFO | fairseq.trainer | begin training epoch 548
2023-02-11 02:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:38:42 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2023-02-11 02:38:42 | INFO | train | epoch 548 | loss 5.76 | ppl 54.19 | wps 516058 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2724 | lr 0.000340532 | gnorm 0.497 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25456
2023-02-11 02:38:44 | INFO | fairseq.trainer | begin training epoch 549
2023-02-11 02:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:39:24 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2023-02-11 02:39:24 | INFO | train | epoch 549 | loss 5.761 | ppl 54.21 | wps 503564 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2729 | lr 0.000341157 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25498
2023-02-11 02:39:24 | INFO | fairseq.trainer | begin training epoch 550
2023-02-11 02:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:40:11 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 5.385 | ppl 41.79 | wps 0 | wpb 11230 | bsz 22 | num_updates 2734 | best_loss 5.384
2023-02-11 02:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 2734 updates
2023-02-11 02:40:11 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint550.pt
2023-02-11 02:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint550.pt
2023-02-11 02:41:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint550.pt (epoch 550 @ 2734 updates, score 5.385) (writing took 65.93269018499996 seconds)
2023-02-11 02:41:17 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2023-02-11 02:41:17 | INFO | train | epoch 550 | loss 5.769 | ppl 54.55 | wps 185795 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2734 | lr 0.000341782 | gnorm 0.687 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25611
2023-02-11 02:41:17 | INFO | fairseq.trainer | begin training epoch 551
2023-02-11 02:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:41:59 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2023-02-11 02:41:59 | INFO | train | epoch 551 | loss 5.771 | ppl 54.59 | wps 499139 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2739 | lr 0.000342407 | gnorm 0.606 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25653
2023-02-11 02:41:59 | INFO | fairseq.trainer | begin training epoch 552
2023-02-11 02:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:42:38 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2023-02-11 02:42:38 | INFO | train | epoch 552 | loss 5.755 | ppl 54 | wps 545132 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2744 | lr 0.000343031 | gnorm 0.438 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25692
2023-02-11 02:42:38 | INFO | fairseq.trainer | begin training epoch 553
2023-02-11 02:42:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:43:20 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2023-02-11 02:43:20 | INFO | train | epoch 553 | loss 5.747 | ppl 53.71 | wps 504221 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2749 | lr 0.000343656 | gnorm 0.409 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25734
2023-02-11 02:43:20 | INFO | fairseq.trainer | begin training epoch 554
2023-02-11 02:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:44:00 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2023-02-11 02:44:00 | INFO | train | epoch 554 | loss 5.743 | ppl 53.55 | wps 522008 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2754 | lr 0.000344281 | gnorm 0.446 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25774
2023-02-11 02:44:00 | INFO | fairseq.trainer | begin training epoch 555
2023-02-11 02:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:44:41 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2023-02-11 02:44:41 | INFO | train | epoch 555 | loss 5.748 | ppl 53.76 | wps 511950 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2759 | lr 0.000344906 | gnorm 0.594 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25815
2023-02-11 02:44:41 | INFO | fairseq.trainer | begin training epoch 556
2023-02-11 02:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:45:22 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2023-02-11 02:45:22 | INFO | train | epoch 556 | loss 5.746 | ppl 53.68 | wps 507153 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2764 | lr 0.000345531 | gnorm 0.564 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25856
2023-02-11 02:45:23 | INFO | fairseq.trainer | begin training epoch 557
2023-02-11 02:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:46:03 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2023-02-11 02:46:03 | INFO | train | epoch 557 | loss 5.762 | ppl 54.28 | wps 522338 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2769 | lr 0.000346156 | gnorm 0.747 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25897
2023-02-11 02:46:03 | INFO | fairseq.trainer | begin training epoch 558
2023-02-11 02:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:46:43 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2023-02-11 02:46:43 | INFO | train | epoch 558 | loss 5.76 | ppl 54.18 | wps 517560 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2774 | lr 0.000346781 | gnorm 0.735 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25937
2023-02-11 02:46:44 | INFO | fairseq.trainer | begin training epoch 559
2023-02-11 02:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:47:21 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2023-02-11 02:47:21 | INFO | train | epoch 559 | loss 5.75 | ppl 53.82 | wps 551333 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2779 | lr 0.000347406 | gnorm 0.519 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 25975
2023-02-11 02:47:22 | INFO | fairseq.trainer | begin training epoch 560
2023-02-11 02:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:48:08 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 5.346 | ppl 40.67 | wps 0 | wpb 11230 | bsz 22 | num_updates 2784 | best_loss 5.346
2023-02-11 02:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 2784 updates
2023-02-11 02:48:08 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint560.pt
2023-02-11 02:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint560.pt
2023-02-11 02:49:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint560.pt (epoch 560 @ 2784 updates, score 5.346) (writing took 63.17506562298513 seconds)
2023-02-11 02:49:11 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2023-02-11 02:49:11 | INFO | train | epoch 560 | loss 5.738 | ppl 53.36 | wps 192033 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2784 | lr 0.00034803 | gnorm 0.441 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26085
2023-02-11 02:49:11 | INFO | fairseq.trainer | begin training epoch 561
2023-02-11 02:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:49:51 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2023-02-11 02:49:51 | INFO | train | epoch 561 | loss 5.732 | ppl 53.15 | wps 520081 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2789 | lr 0.000348655 | gnorm 0.472 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26125
2023-02-11 02:49:52 | INFO | fairseq.trainer | begin training epoch 562
2023-02-11 02:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:50:39 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2023-02-11 02:50:39 | INFO | train | epoch 562 | loss 5.725 | ppl 52.88 | wps 443796 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2794 | lr 0.00034928 | gnorm 0.417 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26173
2023-02-11 02:50:41 | INFO | fairseq.trainer | begin training epoch 563
2023-02-11 02:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:51:21 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2023-02-11 02:51:21 | INFO | train | epoch 563 | loss 5.733 | ppl 53.18 | wps 504421 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2799 | lr 0.000349905 | gnorm 0.587 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26215
2023-02-11 02:51:21 | INFO | fairseq.trainer | begin training epoch 564
2023-02-11 02:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:51:36 | INFO | train_inner | epoch 564:      1 / 5 loss=5.753, ppl=53.91, wps=437132, ups=0.1, wpb=4.20756e+06, bsz=8218, num_updates=2800, lr=0.00035003, gnorm=0.527, loss_scale=1, train_wall=662, gb_free=5.4, wall=26230
2023-02-11 02:52:01 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2023-02-11 02:52:01 | INFO | train | epoch 564 | loss 5.734 | ppl 53.21 | wps 522998 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2804 | lr 0.00035053 | gnorm 0.584 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26255
2023-02-11 02:52:02 | INFO | fairseq.trainer | begin training epoch 565
2023-02-11 02:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:52:42 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2023-02-11 02:52:42 | INFO | train | epoch 565 | loss 5.726 | ppl 52.93 | wps 505512 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2809 | lr 0.000351155 | gnorm 0.474 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26296
2023-02-11 02:52:43 | INFO | fairseq.trainer | begin training epoch 566
2023-02-11 02:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:53:23 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2023-02-11 02:53:23 | INFO | train | epoch 566 | loss 5.718 | ppl 52.64 | wps 518646 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2814 | lr 0.00035178 | gnorm 0.452 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26337
2023-02-11 02:53:23 | INFO | fairseq.trainer | begin training epoch 567
2023-02-11 02:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:54:04 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2023-02-11 02:54:04 | INFO | train | epoch 567 | loss 5.725 | ppl 52.9 | wps 515559 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2819 | lr 0.000352405 | gnorm 0.63 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26378
2023-02-11 02:54:04 | INFO | fairseq.trainer | begin training epoch 568
2023-02-11 02:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:54:46 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2023-02-11 02:54:46 | INFO | train | epoch 568 | loss 5.727 | ppl 52.96 | wps 503299 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2824 | lr 0.000353029 | gnorm 0.637 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26420
2023-02-11 02:54:46 | INFO | fairseq.trainer | begin training epoch 569
2023-02-11 02:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:55:26 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2023-02-11 02:55:26 | INFO | train | epoch 569 | loss 5.72 | ppl 52.69 | wps 520190 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2829 | lr 0.000353654 | gnorm 0.585 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 26460
2023-02-11 02:55:26 | INFO | fairseq.trainer | begin training epoch 570
2023-02-11 02:55:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 02:56:10 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 5.349 | ppl 40.75 | wps 0 | wpb 11230 | bsz 22 | num_updates 2834 | best_loss 5.346
2023-02-11 02:56:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 2834 updates
2023-02-11 02:56:10 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint570.pt
2023-02-11 02:56:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint570.pt
2023-02-11 02:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint570.pt (epoch 570 @ 2834 updates, score 5.349) (writing took 65.94949890798307 seconds)
2023-02-11 02:57:16 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2023-02-11 02:57:16 | INFO | train | epoch 570 | loss 5.723 | ppl 52.81 | wps 190333 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2834 | lr 0.000354279 | gnorm 0.551 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 26570
2023-02-11 02:57:17 | INFO | fairseq.trainer | begin training epoch 571
2023-02-11 02:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:58:29 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2023-02-11 02:58:29 | INFO | train | epoch 571 | loss 5.714 | ppl 52.51 | wps 289564 | ups 0.07 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2839 | lr 0.000354904 | gnorm 0.522 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 26643
2023-02-11 02:58:29 | INFO | fairseq.trainer | begin training epoch 572
2023-02-11 02:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 02:59:06 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2023-02-11 02:59:06 | INFO | train | epoch 572 | loss 5.717 | ppl 52.59 | wps 429492 | ups 0.11 | wpb 3.96794e+06 | bsz 7750 | num_updates 2843 | lr 0.000355404 | gnorm 0.566 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26680
2023-02-11 02:59:06 | INFO | fairseq.trainer | begin training epoch 573
2023-02-11 02:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 02:59:48 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2023-02-11 02:59:48 | INFO | train | epoch 573 | loss 5.717 | ppl 52.6 | wps 506146 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2848 | lr 0.000356029 | gnorm 0.616 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26722
2023-02-11 02:59:48 | INFO | fairseq.trainer | begin training epoch 574
2023-02-11 02:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:00:28 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2023-02-11 03:00:28 | INFO | train | epoch 574 | loss 5.733 | ppl 53.18 | wps 518680 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2853 | lr 0.000356654 | gnorm 0.72 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26762
2023-02-11 03:00:28 | INFO | fairseq.trainer | begin training epoch 575
2023-02-11 03:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:01:08 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2023-02-11 03:01:08 | INFO | train | epoch 575 | loss 5.714 | ppl 52.48 | wps 523552 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2858 | lr 0.000357279 | gnorm 0.453 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26802
2023-02-11 03:01:09 | INFO | fairseq.trainer | begin training epoch 576
2023-02-11 03:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:01:46 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2023-02-11 03:01:46 | INFO | train | epoch 576 | loss 5.705 | ppl 52.17 | wps 557681 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2863 | lr 0.000357903 | gnorm 0.461 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26840
2023-02-11 03:01:46 | INFO | fairseq.trainer | begin training epoch 577
2023-02-11 03:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:02:26 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2023-02-11 03:02:26 | INFO | train | epoch 577 | loss 5.696 | ppl 51.86 | wps 525571 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2868 | lr 0.000358528 | gnorm 0.423 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26880
2023-02-11 03:02:26 | INFO | fairseq.trainer | begin training epoch 578
2023-02-11 03:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:03:07 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2023-02-11 03:03:07 | INFO | train | epoch 578 | loss 5.696 | ppl 51.85 | wps 516544 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2873 | lr 0.000359153 | gnorm 0.496 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26921
2023-02-11 03:03:07 | INFO | fairseq.trainer | begin training epoch 579
2023-02-11 03:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:03:48 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2023-02-11 03:03:48 | INFO | train | epoch 579 | loss 5.696 | ppl 51.83 | wps 506504 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2878 | lr 0.000359778 | gnorm 0.529 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 26962
2023-02-11 03:03:49 | INFO | fairseq.trainer | begin training epoch 580
2023-02-11 03:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:04:31 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 5.334 | ppl 40.35 | wps 0 | wpb 11230 | bsz 22 | num_updates 2883 | best_loss 5.334
2023-02-11 03:04:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 2883 updates
2023-02-11 03:04:31 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint580.pt
2023-02-11 03:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint580.pt
2023-02-11 03:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint580.pt (epoch 580 @ 2883 updates, score 5.334) (writing took 68.03254767099861 seconds)
2023-02-11 03:05:39 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2023-02-11 03:05:39 | INFO | train | epoch 580 | loss 5.692 | ppl 51.7 | wps 189971 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2883 | lr 0.000360403 | gnorm 0.515 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27073
2023-02-11 03:05:39 | INFO | fairseq.trainer | begin training epoch 581
2023-02-11 03:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:06:57 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2023-02-11 03:06:57 | INFO | train | epoch 581 | loss 5.707 | ppl 52.24 | wps 269894 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2888 | lr 0.000361028 | gnorm 0.737 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27151
2023-02-11 03:06:57 | INFO | fairseq.trainer | begin training epoch 582
2023-02-11 03:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:07:39 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2023-02-11 03:07:39 | INFO | train | epoch 582 | loss 5.712 | ppl 52.42 | wps 497887 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2893 | lr 0.000361653 | gnorm 0.689 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27193
2023-02-11 03:07:39 | INFO | fairseq.trainer | begin training epoch 583
2023-02-11 03:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:08:19 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2023-02-11 03:08:19 | INFO | train | epoch 583 | loss 5.701 | ppl 52 | wps 527870 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2898 | lr 0.000362278 | gnorm 0.535 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27233
2023-02-11 03:08:19 | INFO | fairseq.trainer | begin training epoch 584
2023-02-11 03:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:08:43 | INFO | train_inner | epoch 584:      2 / 5 loss=5.713, ppl=52.45, wps=409364, ups=0.1, wpb=4.20655e+06, bsz=8216, num_updates=2900, lr=0.000362528, gnorm=0.555, loss_scale=1, train_wall=669, gb_free=5.4, wall=27257
2023-02-11 03:09:00 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2023-02-11 03:09:00 | INFO | train | epoch 584 | loss 5.685 | ppl 51.44 | wps 511599 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2903 | lr 0.000362902 | gnorm 0.402 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27274
2023-02-11 03:09:00 | INFO | fairseq.trainer | begin training epoch 585
2023-02-11 03:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:09:41 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2023-02-11 03:09:41 | INFO | train | epoch 585 | loss 5.69 | ppl 51.61 | wps 518438 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2908 | lr 0.000363527 | gnorm 0.507 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27315
2023-02-11 03:09:41 | INFO | fairseq.trainer | begin training epoch 586
2023-02-11 03:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:10:22 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2023-02-11 03:10:22 | INFO | train | epoch 586 | loss 5.681 | ppl 51.29 | wps 515700 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2913 | lr 0.000364152 | gnorm 0.477 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27356
2023-02-11 03:10:24 | INFO | fairseq.trainer | begin training epoch 587
2023-02-11 03:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:11:03 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2023-02-11 03:11:03 | INFO | train | epoch 587 | loss 5.676 | ppl 51.11 | wps 503239 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2918 | lr 0.000364777 | gnorm 0.434 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27397
2023-02-11 03:11:04 | INFO | fairseq.trainer | begin training epoch 588
2023-02-11 03:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:11:44 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2023-02-11 03:11:44 | INFO | train | epoch 588 | loss 5.674 | ppl 51.06 | wps 518276 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2923 | lr 0.000365402 | gnorm 0.534 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27438
2023-02-11 03:11:44 | INFO | fairseq.trainer | begin training epoch 589
2023-02-11 03:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:12:25 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2023-02-11 03:12:25 | INFO | train | epoch 589 | loss 5.685 | ppl 51.43 | wps 515600 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2928 | lr 0.000366027 | gnorm 0.624 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27479
2023-02-11 03:12:25 | INFO | fairseq.trainer | begin training epoch 590
2023-02-11 03:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:13:13 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 5.308 | ppl 39.63 | wps 0 | wpb 11230 | bsz 22 | num_updates 2933 | best_loss 5.308
2023-02-11 03:13:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 2933 updates
2023-02-11 03:13:13 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint590.pt
2023-02-11 03:13:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint590.pt
2023-02-11 03:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint590.pt (epoch 590 @ 2933 updates, score 5.308) (writing took 65.47464252699865 seconds)
2023-02-11 03:14:18 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2023-02-11 03:14:18 | INFO | train | epoch 590 | loss 5.685 | ppl 51.43 | wps 185265 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2933 | lr 0.000366652 | gnorm 0.609 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27592
2023-02-11 03:14:19 | INFO | fairseq.trainer | begin training epoch 591
2023-02-11 03:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:15:09 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2023-02-11 03:15:09 | INFO | train | epoch 591 | loss 5.675 | ppl 51.11 | wps 414769 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2938 | lr 0.000367277 | gnorm 0.478 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27643
2023-02-11 03:15:09 | INFO | fairseq.trainer | begin training epoch 592
2023-02-11 03:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:15:51 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2023-02-11 03:15:51 | INFO | train | epoch 592 | loss 5.672 | ppl 50.99 | wps 502208 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2943 | lr 0.000367901 | gnorm 0.512 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27685
2023-02-11 03:15:51 | INFO | fairseq.trainer | begin training epoch 593
2023-02-11 03:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:16:31 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2023-02-11 03:16:31 | INFO | train | epoch 593 | loss 5.665 | ppl 50.75 | wps 530277 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2948 | lr 0.000368526 | gnorm 0.471 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27725
2023-02-11 03:16:31 | INFO | fairseq.trainer | begin training epoch 594
2023-02-11 03:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:17:12 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2023-02-11 03:17:12 | INFO | train | epoch 594 | loss 5.667 | ppl 50.79 | wps 504710 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2953 | lr 0.000369151 | gnorm 0.564 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27766
2023-02-11 03:17:12 | INFO | fairseq.trainer | begin training epoch 595
2023-02-11 03:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:17:53 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2023-02-11 03:17:53 | INFO | train | epoch 595 | loss 5.671 | ppl 50.96 | wps 521076 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2958 | lr 0.000369776 | gnorm 0.615 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27807
2023-02-11 03:17:53 | INFO | fairseq.trainer | begin training epoch 596
2023-02-11 03:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:18:33 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2023-02-11 03:18:33 | INFO | train | epoch 596 | loss 5.664 | ppl 50.7 | wps 519142 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2963 | lr 0.000370401 | gnorm 0.517 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27847
2023-02-11 03:18:35 | INFO | fairseq.trainer | begin training epoch 597
2023-02-11 03:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:19:15 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2023-02-11 03:19:15 | INFO | train | epoch 597 | loss 5.68 | ppl 51.28 | wps 501751 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2968 | lr 0.000371026 | gnorm 0.675 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27889
2023-02-11 03:19:15 | INFO | fairseq.trainer | begin training epoch 598
2023-02-11 03:19:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:19:56 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2023-02-11 03:19:56 | INFO | train | epoch 598 | loss 5.662 | ppl 50.63 | wps 519431 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2973 | lr 0.000371651 | gnorm 0.463 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27930
2023-02-11 03:19:56 | INFO | fairseq.trainer | begin training epoch 599
2023-02-11 03:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:20:36 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2023-02-11 03:20:36 | INFO | train | epoch 599 | loss 5.654 | ppl 50.36 | wps 525036 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2978 | lr 0.000372276 | gnorm 0.419 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 27970
2023-02-11 03:20:36 | INFO | fairseq.trainer | begin training epoch 600
2023-02-11 03:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:21:19 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 5.322 | ppl 40 | wps 0 | wpb 11230 | bsz 22 | num_updates 2983 | best_loss 5.308
2023-02-11 03:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 2983 updates
2023-02-11 03:21:19 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint600.pt
2023-02-11 03:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint600.pt
2023-02-11 03:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint600.pt (epoch 600 @ 2983 updates, score 5.322) (writing took 62.43631812199601 seconds)
2023-02-11 03:22:22 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2023-02-11 03:22:22 | INFO | train | epoch 600 | loss 5.658 | ppl 50.51 | wps 197901 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2983 | lr 0.0003729 | gnorm 0.624 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28076
2023-02-11 03:22:22 | INFO | fairseq.trainer | begin training epoch 601
2023-02-11 03:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:23:08 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2023-02-11 03:23:08 | INFO | train | epoch 601 | loss 5.673 | ppl 51.02 | wps 459017 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2988 | lr 0.000373525 | gnorm 0.713 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28122
2023-02-11 03:23:08 | INFO | fairseq.trainer | begin training epoch 602
2023-02-11 03:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:23:46 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2023-02-11 03:23:46 | INFO | train | epoch 602 | loss 5.671 | ppl 50.95 | wps 547227 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2993 | lr 0.00037415 | gnorm 0.638 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28160
2023-02-11 03:23:46 | INFO | fairseq.trainer | begin training epoch 603
2023-02-11 03:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:24:27 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2023-02-11 03:24:27 | INFO | train | epoch 603 | loss 5.66 | ppl 50.57 | wps 515298 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 2998 | lr 0.000374775 | gnorm 0.498 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28201
2023-02-11 03:24:27 | INFO | fairseq.trainer | begin training epoch 604
2023-02-11 03:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:24:51 | INFO | train_inner | epoch 604:      2 / 5 loss=5.671, ppl=50.96, wps=434649, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3000, lr=0.000375025, gnorm=0.541, loss_scale=1, train_wall=662, gb_free=5.4, wall=28225
2023-02-11 03:25:08 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2023-02-11 03:25:08 | INFO | train | epoch 604 | loss 5.65 | ppl 50.23 | wps 511102 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3003 | lr 0.0003754 | gnorm 0.489 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28242
2023-02-11 03:25:08 | INFO | fairseq.trainer | begin training epoch 605
2023-02-11 03:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:25:49 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2023-02-11 03:25:49 | INFO | train | epoch 605 | loss 5.642 | ppl 49.94 | wps 518947 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3008 | lr 0.000376025 | gnorm 0.429 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28283
2023-02-11 03:25:49 | INFO | fairseq.trainer | begin training epoch 606
2023-02-11 03:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:26:30 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2023-02-11 03:26:30 | INFO | train | epoch 606 | loss 5.638 | ppl 49.81 | wps 508706 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3013 | lr 0.00037665 | gnorm 0.47 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28324
2023-02-11 03:26:30 | INFO | fairseq.trainer | begin training epoch 607
2023-02-11 03:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:27:11 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2023-02-11 03:27:11 | INFO | train | epoch 607 | loss 5.65 | ppl 50.21 | wps 518212 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3018 | lr 0.000377275 | gnorm 0.641 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28365
2023-02-11 03:27:11 | INFO | fairseq.trainer | begin training epoch 608
2023-02-11 03:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:27:51 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2023-02-11 03:27:51 | INFO | train | epoch 608 | loss 5.648 | ppl 50.14 | wps 517800 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3023 | lr 0.000377899 | gnorm 0.636 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28405
2023-02-11 03:27:53 | INFO | fairseq.trainer | begin training epoch 609
2023-02-11 03:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:28:33 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2023-02-11 03:28:33 | INFO | train | epoch 609 | loss 5.65 | ppl 50.22 | wps 501033 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3028 | lr 0.000378524 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28447
2023-02-11 03:28:33 | INFO | fairseq.trainer | begin training epoch 610
2023-02-11 03:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:29:20 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 5.3 | ppl 39.39 | wps 0 | wpb 11230 | bsz 22 | num_updates 3033 | best_loss 5.3
2023-02-11 03:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 3033 updates
2023-02-11 03:29:20 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint610.pt
2023-02-11 03:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint610.pt
2023-02-11 03:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint610.pt (epoch 610 @ 3033 updates, score 5.3) (writing took 66.95030043099541 seconds)
2023-02-11 03:30:27 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2023-02-11 03:30:27 | INFO | train | epoch 610 | loss 5.642 | ppl 49.92 | wps 184362 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3033 | lr 0.000379149 | gnorm 0.588 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28561
2023-02-11 03:30:27 | INFO | fairseq.trainer | begin training epoch 611
2023-02-11 03:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:31:10 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2023-02-11 03:31:10 | INFO | train | epoch 611 | loss 5.642 | ppl 49.92 | wps 492705 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3038 | lr 0.000379774 | gnorm 0.577 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28604
2023-02-11 03:31:10 | INFO | fairseq.trainer | begin training epoch 612
2023-02-11 03:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:31:47 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2023-02-11 03:31:47 | INFO | train | epoch 612 | loss 5.63 | ppl 49.53 | wps 569094 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3043 | lr 0.000380399 | gnorm 0.437 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28641
2023-02-11 03:31:47 | INFO | fairseq.trainer | begin training epoch 613
2023-02-11 03:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:32:29 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2023-02-11 03:32:29 | INFO | train | epoch 613 | loss 5.624 | ppl 49.32 | wps 502586 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3048 | lr 0.000381024 | gnorm 0.417 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28683
2023-02-11 03:32:29 | INFO | fairseq.trainer | begin training epoch 614
2023-02-11 03:32:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:33:09 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2023-02-11 03:33:09 | INFO | train | epoch 614 | loss 5.623 | ppl 49.28 | wps 521105 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3053 | lr 0.000381649 | gnorm 0.475 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28723
2023-02-11 03:33:09 | INFO | fairseq.trainer | begin training epoch 615
2023-02-11 03:33:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:33:50 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2023-02-11 03:33:50 | INFO | train | epoch 615 | loss 5.626 | ppl 49.39 | wps 520015 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3058 | lr 0.000382274 | gnorm 0.557 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28764
2023-02-11 03:33:51 | INFO | fairseq.trainer | begin training epoch 616
2023-02-11 03:33:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:34:31 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2023-02-11 03:34:31 | INFO | train | epoch 616 | loss 5.623 | ppl 49.29 | wps 502205 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3063 | lr 0.000382898 | gnorm 0.502 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28806
2023-02-11 03:34:32 | INFO | fairseq.trainer | begin training epoch 617
2023-02-11 03:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:35:12 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2023-02-11 03:35:12 | INFO | train | epoch 617 | loss 5.621 | ppl 49.2 | wps 519832 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3068 | lr 0.000383523 | gnorm 0.489 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28846
2023-02-11 03:35:12 | INFO | fairseq.trainer | begin training epoch 618
2023-02-11 03:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:35:53 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2023-02-11 03:35:53 | INFO | train | epoch 618 | loss 5.618 | ppl 49.1 | wps 515397 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3073 | lr 0.000384148 | gnorm 0.515 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28887
2023-02-11 03:35:53 | INFO | fairseq.trainer | begin training epoch 619
2023-02-11 03:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:36:34 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2023-02-11 03:36:34 | INFO | train | epoch 619 | loss 5.625 | ppl 49.33 | wps 511456 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3078 | lr 0.000384773 | gnorm 0.617 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 28928
2023-02-11 03:36:34 | INFO | fairseq.trainer | begin training epoch 620
2023-02-11 03:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:37:22 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 5.305 | ppl 39.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 3083 | best_loss 5.3
2023-02-11 03:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 3083 updates
2023-02-11 03:37:22 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint620.pt
2023-02-11 03:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint620.pt
2023-02-11 03:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint620.pt (epoch 620 @ 3083 updates, score 5.305) (writing took 61.18132197498926 seconds)
2023-02-11 03:38:23 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2023-02-11 03:38:23 | INFO | train | epoch 620 | loss 5.635 | ppl 49.7 | wps 192445 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3083 | lr 0.000385398 | gnorm 0.73 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29037
2023-02-11 03:38:23 | INFO | fairseq.trainer | begin training epoch 621
2023-02-11 03:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:39:04 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2023-02-11 03:39:04 | INFO | train | epoch 621 | loss 5.63 | ppl 49.51 | wps 512424 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3088 | lr 0.000386023 | gnorm 0.623 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29078
2023-02-11 03:39:04 | INFO | fairseq.trainer | begin training epoch 622
2023-02-11 03:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:39:44 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2023-02-11 03:39:44 | INFO | train | epoch 622 | loss 5.614 | ppl 48.97 | wps 530388 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3093 | lr 0.000386648 | gnorm 0.455 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29118
2023-02-11 03:39:44 | INFO | fairseq.trainer | begin training epoch 623
2023-02-11 03:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:40:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 03:40:24 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2023-02-11 03:40:24 | INFO | train | epoch 623 | loss 5.624 | ppl 49.31 | wps 394020 | ups 0.1 | wpb 3.96794e+06 | bsz 7750 | num_updates 3097 | lr 0.000387148 | gnorm 0.64 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29158
2023-02-11 03:40:24 | INFO | fairseq.trainer | begin training epoch 624
2023-02-11 03:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:40:57 | INFO | train_inner | epoch 624:      3 / 5 loss=5.632, ppl=49.6, wps=435777, ups=0.1, wpb=4.20756e+06, bsz=8218, num_updates=3100, lr=0.000387523, gnorm=0.548, loss_scale=1, train_wall=669, gb_free=5.4, wall=29191
2023-02-11 03:41:05 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2023-02-11 03:41:05 | INFO | train | epoch 624 | loss 5.631 | ppl 49.57 | wps 510996 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3102 | lr 0.000387772 | gnorm 0.666 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29199
2023-02-11 03:41:06 | INFO | fairseq.trainer | begin training epoch 625
2023-02-11 03:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:41:47 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2023-02-11 03:41:47 | INFO | train | epoch 625 | loss 5.618 | ppl 49.12 | wps 508218 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3107 | lr 0.000388397 | gnorm 0.504 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29241
2023-02-11 03:41:47 | INFO | fairseq.trainer | begin training epoch 626
2023-02-11 03:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:42:27 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2023-02-11 03:42:27 | INFO | train | epoch 626 | loss 5.609 | ppl 48.8 | wps 519479 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3112 | lr 0.000389022 | gnorm 0.487 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29281
2023-02-11 03:42:27 | INFO | fairseq.trainer | begin training epoch 627
2023-02-11 03:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:43:07 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2023-02-11 03:43:07 | INFO | train | epoch 627 | loss 5.607 | ppl 48.74 | wps 525084 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3117 | lr 0.000389647 | gnorm 0.507 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29321
2023-02-11 03:43:08 | INFO | fairseq.trainer | begin training epoch 628
2023-02-11 03:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:43:45 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2023-02-11 03:43:45 | INFO | train | epoch 628 | loss 5.602 | ppl 48.57 | wps 551893 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3122 | lr 0.000390272 | gnorm 0.499 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29359
2023-02-11 03:43:46 | INFO | fairseq.trainer | begin training epoch 629
2023-02-11 03:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:44:25 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2023-02-11 03:44:25 | INFO | train | epoch 629 | loss 5.598 | ppl 48.43 | wps 529957 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3127 | lr 0.000390897 | gnorm 0.487 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29399
2023-02-11 03:44:25 | INFO | fairseq.trainer | begin training epoch 630
2023-02-11 03:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:45:14 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 5.275 | ppl 38.72 | wps 0 | wpb 11230 | bsz 22 | num_updates 3132 | best_loss 5.275
2023-02-11 03:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 3132 updates
2023-02-11 03:45:14 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint630.pt
2023-02-11 03:45:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint630.pt
2023-02-11 03:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint630.pt (epoch 630 @ 3132 updates, score 5.275) (writing took 73.43075805099215 seconds)
2023-02-11 03:46:27 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2023-02-11 03:46:27 | INFO | train | epoch 630 | loss 5.597 | ppl 48.41 | wps 172056 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3132 | lr 0.000391522 | gnorm 0.493 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29521
2023-02-11 03:46:28 | INFO | fairseq.trainer | begin training epoch 631
2023-02-11 03:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:47:10 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2023-02-11 03:47:10 | INFO | train | epoch 631 | loss 5.602 | ppl 48.57 | wps 491581 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3137 | lr 0.000392147 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29564
2023-02-11 03:47:10 | INFO | fairseq.trainer | begin training epoch 632
2023-02-11 03:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:47:50 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2023-02-11 03:47:50 | INFO | train | epoch 632 | loss 5.602 | ppl 48.58 | wps 522193 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3142 | lr 0.000392771 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29604
2023-02-11 03:47:51 | INFO | fairseq.trainer | begin training epoch 633
2023-02-11 03:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:48:31 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2023-02-11 03:48:31 | INFO | train | epoch 633 | loss 5.593 | ppl 48.27 | wps 522029 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3147 | lr 0.000393396 | gnorm 0.461 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29645
2023-02-11 03:48:31 | INFO | fairseq.trainer | begin training epoch 634
2023-02-11 03:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:49:12 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2023-02-11 03:49:12 | INFO | train | epoch 634 | loss 5.594 | ppl 48.31 | wps 512035 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3152 | lr 0.000394021 | gnorm 0.525 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29686
2023-02-11 03:49:12 | INFO | fairseq.trainer | begin training epoch 635
2023-02-11 03:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:49:53 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2023-02-11 03:49:53 | INFO | train | epoch 635 | loss 5.591 | ppl 48.19 | wps 506532 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3157 | lr 0.000394646 | gnorm 0.521 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29727
2023-02-11 03:49:54 | INFO | fairseq.trainer | begin training epoch 636
2023-02-11 03:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:50:33 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2023-02-11 03:50:33 | INFO | train | epoch 636 | loss 5.597 | ppl 48.39 | wps 526179 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3162 | lr 0.000395271 | gnorm 0.667 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29767
2023-02-11 03:50:34 | INFO | fairseq.trainer | begin training epoch 637
2023-02-11 03:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:51:14 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2023-02-11 03:51:14 | INFO | train | epoch 637 | loss 5.601 | ppl 48.53 | wps 516081 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3167 | lr 0.000395896 | gnorm 0.675 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29808
2023-02-11 03:51:16 | INFO | fairseq.trainer | begin training epoch 638
2023-02-11 03:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:51:56 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2023-02-11 03:51:56 | INFO | train | epoch 638 | loss 5.592 | ppl 48.25 | wps 496128 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3172 | lr 0.000396521 | gnorm 0.456 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29850
2023-02-11 03:51:57 | INFO | fairseq.trainer | begin training epoch 639
2023-02-11 03:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:52:37 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2023-02-11 03:52:37 | INFO | train | epoch 639 | loss 5.582 | ppl 47.92 | wps 523848 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3177 | lr 0.000397146 | gnorm 0.438 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29891
2023-02-11 03:52:37 | INFO | fairseq.trainer | begin training epoch 640
2023-02-11 03:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 03:53:25 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 5.277 | ppl 38.77 | wps 0 | wpb 11230 | bsz 22 | num_updates 3182 | best_loss 5.275
2023-02-11 03:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 3182 updates
2023-02-11 03:53:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint640.pt
2023-02-11 03:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint640.pt
2023-02-11 03:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint640.pt (epoch 640 @ 3182 updates, score 5.277) (writing took 57.172578377998434 seconds)
2023-02-11 03:54:22 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2023-02-11 03:54:22 | INFO | train | epoch 640 | loss 5.586 | ppl 48.02 | wps 199081 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3182 | lr 0.00039777 | gnorm 0.572 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 29996
2023-02-11 03:54:23 | INFO | fairseq.trainer | begin training epoch 641
2023-02-11 03:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:55:13 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2023-02-11 03:55:13 | INFO | train | epoch 641 | loss 5.59 | ppl 48.17 | wps 414411 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3187 | lr 0.000398395 | gnorm 0.667 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30047
2023-02-11 03:55:13 | INFO | fairseq.trainer | begin training epoch 642
2023-02-11 03:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:55:51 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2023-02-11 03:55:51 | INFO | train | epoch 642 | loss 5.593 | ppl 48.27 | wps 547151 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3192 | lr 0.00039902 | gnorm 0.627 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30085
2023-02-11 03:55:52 | INFO | fairseq.trainer | begin training epoch 643
2023-02-11 03:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:56:32 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2023-02-11 03:56:32 | INFO | train | epoch 643 | loss 5.581 | ppl 47.86 | wps 521704 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3197 | lr 0.000399645 | gnorm 0.497 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30126
2023-02-11 03:56:32 | INFO | fairseq.trainer | begin training epoch 644
2023-02-11 03:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:57:05 | INFO | train_inner | epoch 644:      3 / 5 loss=5.596, ppl=48.38, wps=434529, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3200, lr=0.00040002, gnorm=0.538, loss_scale=1, train_wall=662, gb_free=5.4, wall=30159
2023-02-11 03:57:13 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2023-02-11 03:57:13 | INFO | train | epoch 644 | loss 5.574 | ppl 47.64 | wps 504725 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3202 | lr 0.00040027 | gnorm 0.472 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30167
2023-02-11 03:57:14 | INFO | fairseq.trainer | begin training epoch 645
2023-02-11 03:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:57:54 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2023-02-11 03:57:54 | INFO | train | epoch 645 | loss 5.574 | ppl 47.65 | wps 517426 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3207 | lr 0.000400895 | gnorm 0.563 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30208
2023-02-11 03:57:54 | INFO | fairseq.trainer | begin training epoch 646
2023-02-11 03:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:58:35 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2023-02-11 03:58:35 | INFO | train | epoch 646 | loss 5.59 | ppl 48.16 | wps 518768 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3212 | lr 0.00040152 | gnorm 0.747 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30249
2023-02-11 03:58:35 | INFO | fairseq.trainer | begin training epoch 647
2023-02-11 03:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:59:16 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2023-02-11 03:59:16 | INFO | train | epoch 647 | loss 5.579 | ppl 47.8 | wps 507953 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3217 | lr 0.000402145 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30290
2023-02-11 03:59:16 | INFO | fairseq.trainer | begin training epoch 648
2023-02-11 03:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 03:59:57 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2023-02-11 03:59:57 | INFO | train | epoch 648 | loss 5.567 | ppl 47.4 | wps 516581 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3222 | lr 0.000402769 | gnorm 0.422 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30331
2023-02-11 03:59:57 | INFO | fairseq.trainer | begin training epoch 649
2023-02-11 03:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:00:38 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2023-02-11 04:00:38 | INFO | train | epoch 649 | loss 5.557 | ppl 47.09 | wps 515586 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3227 | lr 0.000403394 | gnorm 0.334 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30372
2023-02-11 04:00:38 | INFO | fairseq.trainer | begin training epoch 650
2023-02-11 04:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:01:26 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 5.247 | ppl 37.97 | wps 0 | wpb 11230 | bsz 22 | num_updates 3232 | best_loss 5.247
2023-02-11 04:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 3232 updates
2023-02-11 04:01:26 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint650.pt
2023-02-11 04:01:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint650.pt
2023-02-11 04:02:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint650.pt (epoch 650 @ 3232 updates, score 5.247) (writing took 63.582132672017906 seconds)
2023-02-11 04:02:30 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2023-02-11 04:02:30 | INFO | train | epoch 650 | loss 5.562 | ppl 47.25 | wps 187815 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3232 | lr 0.000404019 | gnorm 0.519 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30484
2023-02-11 04:02:30 | INFO | fairseq.trainer | begin training epoch 651
2023-02-11 04:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:03:52 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2023-02-11 04:03:52 | INFO | train | epoch 651 | loss 5.562 | ppl 47.25 | wps 254210 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3237 | lr 0.000404644 | gnorm 0.555 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30566
2023-02-11 04:03:53 | INFO | fairseq.trainer | begin training epoch 652
2023-02-11 04:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:04:33 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2023-02-11 04:04:33 | INFO | train | epoch 652 | loss 5.567 | ppl 47.4 | wps 519679 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3242 | lr 0.000405269 | gnorm 0.614 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30607
2023-02-11 04:04:35 | INFO | fairseq.trainer | begin training epoch 653
2023-02-11 04:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:05:15 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2023-02-11 04:05:15 | INFO | train | epoch 653 | loss 5.568 | ppl 47.45 | wps 495319 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3247 | lr 0.000405894 | gnorm 0.606 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30649
2023-02-11 04:05:16 | INFO | fairseq.trainer | begin training epoch 654
2023-02-11 04:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:05:55 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2023-02-11 04:05:55 | INFO | train | epoch 654 | loss 5.565 | ppl 47.35 | wps 531639 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3252 | lr 0.000406519 | gnorm 0.618 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30689
2023-02-11 04:05:55 | INFO | fairseq.trainer | begin training epoch 655
2023-02-11 04:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:06:36 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2023-02-11 04:06:36 | INFO | train | epoch 655 | loss 5.565 | ppl 47.35 | wps 513044 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3257 | lr 0.000407144 | gnorm 0.602 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30730
2023-02-11 04:06:36 | INFO | fairseq.trainer | begin training epoch 656
2023-02-11 04:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:07:18 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2023-02-11 04:07:18 | INFO | train | epoch 656 | loss 5.555 | ppl 47.02 | wps 501071 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3262 | lr 0.000407768 | gnorm 0.461 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30772
2023-02-11 04:07:18 | INFO | fairseq.trainer | begin training epoch 657
2023-02-11 04:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:07:58 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2023-02-11 04:07:58 | INFO | train | epoch 657 | loss 5.555 | ppl 47.01 | wps 520953 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3267 | lr 0.000408393 | gnorm 0.569 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30812
2023-02-11 04:07:58 | INFO | fairseq.trainer | begin training epoch 658
2023-02-11 04:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:08:39 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2023-02-11 04:08:39 | INFO | train | epoch 658 | loss 5.552 | ppl 46.92 | wps 517717 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3272 | lr 0.000409018 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30853
2023-02-11 04:08:39 | INFO | fairseq.trainer | begin training epoch 659
2023-02-11 04:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:09:21 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2023-02-11 04:09:21 | INFO | train | epoch 659 | loss 5.55 | ppl 46.87 | wps 501354 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3277 | lr 0.000409643 | gnorm 0.573 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 30895
2023-02-11 04:09:21 | INFO | fairseq.trainer | begin training epoch 660
2023-02-11 04:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:10:08 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 5.258 | ppl 38.26 | wps 0 | wpb 11230 | bsz 22 | num_updates 3282 | best_loss 5.247
2023-02-11 04:10:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 3282 updates
2023-02-11 04:10:08 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint660.pt
2023-02-11 04:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint660.pt
2023-02-11 04:11:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint660.pt (epoch 660 @ 3282 updates, score 5.258) (writing took 61.711602291004965 seconds)
2023-02-11 04:11:10 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2023-02-11 04:11:10 | INFO | train | epoch 660 | loss 5.562 | ppl 47.23 | wps 192942 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3282 | lr 0.000410268 | gnorm 0.645 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31004
2023-02-11 04:11:10 | INFO | fairseq.trainer | begin training epoch 661
2023-02-11 04:11:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:11:51 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2023-02-11 04:11:51 | INFO | train | epoch 661 | loss 5.551 | ppl 46.89 | wps 504577 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3287 | lr 0.000410893 | gnorm 0.51 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31046
2023-02-11 04:11:52 | INFO | fairseq.trainer | begin training epoch 662
2023-02-11 04:11:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:12:30 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2023-02-11 04:12:30 | INFO | train | epoch 662 | loss 5.546 | ppl 46.72 | wps 542890 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3292 | lr 0.000411518 | gnorm 0.498 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31084
2023-02-11 04:12:30 | INFO | fairseq.trainer | begin training epoch 663
2023-02-11 04:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:13:11 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2023-02-11 04:13:11 | INFO | train | epoch 663 | loss 5.537 | ppl 46.44 | wps 513324 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3297 | lr 0.000412143 | gnorm 0.458 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31125
2023-02-11 04:13:11 | INFO | fairseq.trainer | begin training epoch 664
2023-02-11 04:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:13:42 | INFO | train_inner | epoch 664:      3 / 5 loss=5.561, ppl=47.21, wps=421607, ups=0.1, wpb=4.20696e+06, bsz=8216.8, num_updates=3300, lr=0.000412518, gnorm=0.546, loss_scale=1, train_wall=662, gb_free=5.4, wall=31157
2023-02-11 04:13:51 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2023-02-11 04:13:51 | INFO | train | epoch 664 | loss 5.54 | ppl 46.53 | wps 525890 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3302 | lr 0.000412767 | gnorm 0.566 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31165
2023-02-11 04:13:51 | INFO | fairseq.trainer | begin training epoch 665
2023-02-11 04:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:14:33 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2023-02-11 04:14:33 | INFO | train | epoch 665 | loss 5.54 | ppl 46.52 | wps 508031 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3307 | lr 0.000413392 | gnorm 0.54 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31207
2023-02-11 04:14:33 | INFO | fairseq.trainer | begin training epoch 666
2023-02-11 04:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:15:13 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2023-02-11 04:15:13 | INFO | train | epoch 666 | loss 5.548 | ppl 46.79 | wps 516655 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3312 | lr 0.000414017 | gnorm 0.69 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31247
2023-02-11 04:15:14 | INFO | fairseq.trainer | begin training epoch 667
2023-02-11 04:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:15:54 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2023-02-11 04:15:54 | INFO | train | epoch 667 | loss 5.551 | ppl 46.87 | wps 518416 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3317 | lr 0.000414642 | gnorm 0.716 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31288
2023-02-11 04:15:54 | INFO | fairseq.trainer | begin training epoch 668
2023-02-11 04:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:16:36 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2023-02-11 04:16:36 | INFO | train | epoch 668 | loss 5.547 | ppl 46.75 | wps 503648 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3322 | lr 0.000415267 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31330
2023-02-11 04:16:36 | INFO | fairseq.trainer | begin training epoch 669
2023-02-11 04:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:17:16 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2023-02-11 04:17:16 | INFO | train | epoch 669 | loss 5.531 | ppl 46.25 | wps 514847 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3327 | lr 0.000415892 | gnorm 0.417 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31371
2023-02-11 04:17:17 | INFO | fairseq.trainer | begin training epoch 670
2023-02-11 04:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:17:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:18:05 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 5.241 | ppl 37.82 | wps 0 | wpb 11230 | bsz 22 | num_updates 3332 | best_loss 5.241
2023-02-11 04:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 3332 updates
2023-02-11 04:18:05 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint670.pt
2023-02-11 04:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint670.pt
2023-02-11 04:19:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint670.pt (epoch 670 @ 3332 updates, score 5.241) (writing took 66.18488434600295 seconds)
2023-02-11 04:19:11 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2023-02-11 04:19:11 | INFO | train | epoch 670 | loss 5.524 | ppl 46.02 | wps 183701 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3332 | lr 0.000416517 | gnorm 0.404 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31485
2023-02-11 04:19:11 | INFO | fairseq.trainer | begin training epoch 671
2023-02-11 04:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:19:57 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2023-02-11 04:19:57 | INFO | train | epoch 671 | loss 5.527 | ppl 46.1 | wps 457466 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3337 | lr 0.000417142 | gnorm 0.54 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31531
2023-02-11 04:19:57 | INFO | fairseq.trainer | begin training epoch 672
2023-02-11 04:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:20:37 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2023-02-11 04:20:37 | INFO | train | epoch 672 | loss 5.528 | ppl 46.13 | wps 527792 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3342 | lr 0.000417766 | gnorm 0.536 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31571
2023-02-11 04:20:37 | INFO | fairseq.trainer | begin training epoch 673
2023-02-11 04:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:21:17 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2023-02-11 04:21:17 | INFO | train | epoch 673 | loss 5.529 | ppl 46.18 | wps 525815 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3347 | lr 0.000418391 | gnorm 0.601 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31611
2023-02-11 04:21:17 | INFO | fairseq.trainer | begin training epoch 674
2023-02-11 04:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:21:57 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2023-02-11 04:21:57 | INFO | train | epoch 674 | loss 5.532 | ppl 46.28 | wps 518544 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3352 | lr 0.000419016 | gnorm 0.623 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 31651
2023-02-11 04:21:58 | INFO | fairseq.trainer | begin training epoch 675
2023-02-11 04:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:22:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 04:22:39 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2023-02-11 04:22:39 | INFO | train | epoch 675 | loss 5.545 | ppl 46.69 | wps 376825 | ups 0.1 | wpb 3.95284e+06 | bsz 7720.5 | num_updates 3356 | lr 0.000419516 | gnorm 0.819 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31693
2023-02-11 04:22:40 | INFO | fairseq.trainer | begin training epoch 676
2023-02-11 04:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:23:20 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2023-02-11 04:23:20 | INFO | train | epoch 676 | loss 5.536 | ppl 46.4 | wps 522039 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3361 | lr 0.000420141 | gnorm 0.543 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31734
2023-02-11 04:23:20 | INFO | fairseq.trainer | begin training epoch 677
2023-02-11 04:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:24:00 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2023-02-11 04:24:00 | INFO | train | epoch 677 | loss 5.522 | ppl 45.95 | wps 524916 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3366 | lr 0.000420766 | gnorm 0.441 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31774
2023-02-11 04:24:00 | INFO | fairseq.trainer | begin training epoch 678
2023-02-11 04:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:24:38 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2023-02-11 04:24:38 | INFO | train | epoch 678 | loss 5.519 | ppl 45.87 | wps 547543 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3371 | lr 0.000421391 | gnorm 0.497 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31812
2023-02-11 04:24:38 | INFO | fairseq.trainer | begin training epoch 679
2023-02-11 04:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:25:18 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2023-02-11 04:25:18 | INFO | train | epoch 679 | loss 5.521 | ppl 45.91 | wps 533844 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3376 | lr 0.000422016 | gnorm 0.532 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31852
2023-02-11 04:25:18 | INFO | fairseq.trainer | begin training epoch 680
2023-02-11 04:25:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:26:06 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 5.234 | ppl 37.62 | wps 0 | wpb 11230 | bsz 22 | num_updates 3381 | best_loss 5.234
2023-02-11 04:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 3381 updates
2023-02-11 04:26:06 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint680.pt
2023-02-11 04:26:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint680.pt
2023-02-11 04:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint680.pt (epoch 680 @ 3381 updates, score 5.234) (writing took 60.50456903400482 seconds)
2023-02-11 04:27:07 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2023-02-11 04:27:07 | INFO | train | epoch 680 | loss 5.512 | ppl 45.64 | wps 192582 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3381 | lr 0.00042264 | gnorm 0.483 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 31961
2023-02-11 04:27:07 | INFO | fairseq.trainer | begin training epoch 681
2023-02-11 04:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:27:57 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2023-02-11 04:27:57 | INFO | train | epoch 681 | loss 5.511 | ppl 45.61 | wps 414975 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3386 | lr 0.000423265 | gnorm 0.53 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32011
2023-02-11 04:27:58 | INFO | fairseq.trainer | begin training epoch 682
2023-02-11 04:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:28:37 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2023-02-11 04:28:37 | INFO | train | epoch 682 | loss 5.512 | ppl 45.62 | wps 526175 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3391 | lr 0.00042389 | gnorm 0.605 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32051
2023-02-11 04:28:38 | INFO | fairseq.trainer | begin training epoch 683
2023-02-11 04:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:29:18 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2023-02-11 04:29:18 | INFO | train | epoch 683 | loss 5.516 | ppl 45.76 | wps 520071 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3396 | lr 0.000424515 | gnorm 0.679 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32092
2023-02-11 04:29:18 | INFO | fairseq.trainer | begin training epoch 684
2023-02-11 04:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:29:58 | INFO | train_inner | epoch 684:      4 / 5 loss=5.528, ppl=46.14, wps=431030, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3400, lr=0.000425015, gnorm=0.563, loss_scale=1, train_wall=668, gb_free=5.4, wall=32132
2023-02-11 04:29:59 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2023-02-11 04:29:59 | INFO | train | epoch 684 | loss 5.509 | ppl 45.55 | wps 511584 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3401 | lr 0.00042514 | gnorm 0.477 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32133
2023-02-11 04:29:59 | INFO | fairseq.trainer | begin training epoch 685
2023-02-11 04:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:30:40 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2023-02-11 04:30:40 | INFO | train | epoch 685 | loss 5.513 | ppl 45.66 | wps 513113 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3406 | lr 0.000425765 | gnorm 0.605 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32174
2023-02-11 04:30:40 | INFO | fairseq.trainer | begin training epoch 686
2023-02-11 04:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:31:21 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2023-02-11 04:31:21 | INFO | train | epoch 686 | loss 5.513 | ppl 45.68 | wps 517169 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3411 | lr 0.00042639 | gnorm 0.596 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32215
2023-02-11 04:31:21 | INFO | fairseq.trainer | begin training epoch 687
2023-02-11 04:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:32:02 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2023-02-11 04:32:03 | INFO | train | epoch 687 | loss 5.504 | ppl 45.39 | wps 502703 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3416 | lr 0.000427015 | gnorm 0.492 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32257
2023-02-11 04:32:03 | INFO | fairseq.trainer | begin training epoch 688
2023-02-11 04:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:32:43 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2023-02-11 04:32:43 | INFO | train | epoch 688 | loss 5.499 | ppl 45.21 | wps 518814 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3421 | lr 0.000427639 | gnorm 0.495 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32297
2023-02-11 04:32:44 | INFO | fairseq.trainer | begin training epoch 689
2023-02-11 04:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:33:24 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2023-02-11 04:33:24 | INFO | train | epoch 689 | loss 5.502 | ppl 45.32 | wps 517686 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3426 | lr 0.000428264 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32338
2023-02-11 04:33:24 | INFO | fairseq.trainer | begin training epoch 690
2023-02-11 04:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:34:12 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 5.224 | ppl 37.37 | wps 0 | wpb 11230 | bsz 22 | num_updates 3431 | best_loss 5.224
2023-02-11 04:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 3431 updates
2023-02-11 04:34:12 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint690.pt
2023-02-11 04:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint690.pt
2023-02-11 04:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint690.pt (epoch 690 @ 3431 updates, score 5.224) (writing took 58.07679173198994 seconds)
2023-02-11 04:35:10 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2023-02-11 04:35:10 | INFO | train | epoch 690 | loss 5.504 | ppl 45.37 | wps 197598 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3431 | lr 0.000428889 | gnorm 0.563 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32444
2023-02-11 04:35:10 | INFO | fairseq.trainer | begin training epoch 691
2023-02-11 04:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:36:01 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2023-02-11 04:36:01 | INFO | train | epoch 691 | loss 5.496 | ppl 45.12 | wps 412382 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3436 | lr 0.000429514 | gnorm 0.496 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32495
2023-02-11 04:36:01 | INFO | fairseq.trainer | begin training epoch 692
2023-02-11 04:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:36:39 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2023-02-11 04:36:39 | INFO | train | epoch 692 | loss 5.497 | ppl 45.15 | wps 551292 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3441 | lr 0.000430139 | gnorm 0.586 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32533
2023-02-11 04:36:40 | INFO | fairseq.trainer | begin training epoch 693
2023-02-11 04:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:37:19 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2023-02-11 04:37:19 | INFO | train | epoch 693 | loss 5.509 | ppl 45.53 | wps 525268 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3446 | lr 0.000430764 | gnorm 0.692 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32573
2023-02-11 04:37:20 | INFO | fairseq.trainer | begin training epoch 694
2023-02-11 04:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:38:01 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2023-02-11 04:38:01 | INFO | train | epoch 694 | loss 5.495 | ppl 45.11 | wps 500248 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3451 | lr 0.000431389 | gnorm 0.509 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32615
2023-02-11 04:38:02 | INFO | fairseq.trainer | begin training epoch 695
2023-02-11 04:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:38:42 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2023-02-11 04:38:42 | INFO | train | epoch 695 | loss 5.497 | ppl 45.18 | wps 523334 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3456 | lr 0.000432014 | gnorm 0.613 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32656
2023-02-11 04:38:42 | INFO | fairseq.trainer | begin training epoch 696
2023-02-11 04:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:39:22 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2023-02-11 04:39:22 | INFO | train | epoch 696 | loss 5.492 | ppl 45.01 | wps 518734 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3461 | lr 0.000432638 | gnorm 0.504 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32696
2023-02-11 04:39:22 | INFO | fairseq.trainer | begin training epoch 697
2023-02-11 04:39:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:40:04 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2023-02-11 04:40:04 | INFO | train | epoch 697 | loss 5.487 | ppl 44.84 | wps 497711 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3466 | lr 0.000433263 | gnorm 0.52 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32738
2023-02-11 04:40:05 | INFO | fairseq.trainer | begin training epoch 698
2023-02-11 04:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:40:45 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2023-02-11 04:40:45 | INFO | train | epoch 698 | loss 5.497 | ppl 45.18 | wps 523818 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3471 | lr 0.000433888 | gnorm 0.638 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32779
2023-02-11 04:40:45 | INFO | fairseq.trainer | begin training epoch 699
2023-02-11 04:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:41:25 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2023-02-11 04:41:25 | INFO | train | epoch 699 | loss 5.487 | ppl 44.84 | wps 516933 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3476 | lr 0.000434513 | gnorm 0.524 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32819
2023-02-11 04:41:26 | INFO | fairseq.trainer | begin training epoch 700
2023-02-11 04:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:42:14 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 5.222 | ppl 37.32 | wps 0 | wpb 11230 | bsz 22 | num_updates 3481 | best_loss 5.222
2023-02-11 04:42:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 3481 updates
2023-02-11 04:42:14 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint700.pt
2023-02-11 04:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint700.pt
2023-02-11 04:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint700.pt (epoch 700 @ 3481 updates, score 5.222) (writing took 69.7159196199791 seconds)
2023-02-11 04:43:23 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2023-02-11 04:43:23 | INFO | train | epoch 700 | loss 5.487 | ppl 44.86 | wps 178116 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3481 | lr 0.000435138 | gnorm 0.651 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32937
2023-02-11 04:43:24 | INFO | fairseq.trainer | begin training epoch 701
2023-02-11 04:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:44:13 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2023-02-11 04:44:13 | INFO | train | epoch 701 | loss 5.484 | ppl 44.75 | wps 421187 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3486 | lr 0.000435763 | gnorm 0.554 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 32987
2023-02-11 04:44:14 | INFO | fairseq.trainer | begin training epoch 702
2023-02-11 04:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:44:52 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2023-02-11 04:44:52 | INFO | train | epoch 702 | loss 5.481 | ppl 44.67 | wps 548414 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3491 | lr 0.000436388 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33026
2023-02-11 04:44:52 | INFO | fairseq.trainer | begin training epoch 703
2023-02-11 04:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:45:32 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2023-02-11 04:45:32 | INFO | train | epoch 703 | loss 5.488 | ppl 44.89 | wps 526459 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3496 | lr 0.000437013 | gnorm 0.677 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33066
2023-02-11 04:45:32 | INFO | fairseq.trainer | begin training epoch 704
2023-02-11 04:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:46:12 | INFO | train_inner | epoch 704:      4 / 5 loss=5.496, ppl=45.14, wps=431965, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3500, lr=0.000437513, gnorm=0.577, loss_scale=1, train_wall=662, gb_free=5.4, wall=33106
2023-02-11 04:46:13 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2023-02-11 04:46:13 | INFO | train | epoch 704 | loss 5.496 | ppl 45.11 | wps 509545 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3501 | lr 0.000437637 | gnorm 0.673 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33107
2023-02-11 04:46:13 | INFO | fairseq.trainer | begin training epoch 705
2023-02-11 04:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:46:53 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2023-02-11 04:46:53 | INFO | train | epoch 705 | loss 5.486 | ppl 44.81 | wps 524142 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3506 | lr 0.000438262 | gnorm 0.56 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33147
2023-02-11 04:46:53 | INFO | fairseq.trainer | begin training epoch 706
2023-02-11 04:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:47:34 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2023-02-11 04:47:34 | INFO | train | epoch 706 | loss 5.472 | ppl 44.37 | wps 514184 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3511 | lr 0.000438887 | gnorm 0.43 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33188
2023-02-11 04:47:34 | INFO | fairseq.trainer | begin training epoch 707
2023-02-11 04:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:48:16 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2023-02-11 04:48:16 | INFO | train | epoch 707 | loss 5.463 | ppl 44.11 | wps 501162 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3516 | lr 0.000439512 | gnorm 0.384 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33230
2023-02-11 04:48:16 | INFO | fairseq.trainer | begin training epoch 708
2023-02-11 04:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:48:56 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2023-02-11 04:48:56 | INFO | train | epoch 708 | loss 5.461 | ppl 44.06 | wps 522827 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3521 | lr 0.000440137 | gnorm 0.442 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33270
2023-02-11 04:48:56 | INFO | fairseq.trainer | begin training epoch 709
2023-02-11 04:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:49:37 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2023-02-11 04:49:37 | INFO | train | epoch 709 | loss 5.472 | ppl 44.38 | wps 514439 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3526 | lr 0.000440762 | gnorm 0.64 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33311
2023-02-11 04:49:37 | INFO | fairseq.trainer | begin training epoch 710
2023-02-11 04:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:50:25 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 5.246 | ppl 37.95 | wps 0 | wpb 11230 | bsz 22 | num_updates 3531 | best_loss 5.222
2023-02-11 04:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 3531 updates
2023-02-11 04:50:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint710.pt
2023-02-11 04:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint710.pt
2023-02-11 04:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint710.pt (epoch 710 @ 3531 updates, score 5.246) (writing took 68.10291331700864 seconds)
2023-02-11 04:51:33 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2023-02-11 04:51:33 | INFO | train | epoch 710 | loss 5.483 | ppl 44.71 | wps 180889 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3531 | lr 0.000441387 | gnorm 0.683 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33427
2023-02-11 04:51:34 | INFO | fairseq.trainer | begin training epoch 711
2023-02-11 04:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:52:24 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2023-02-11 04:52:24 | INFO | train | epoch 711 | loss 5.484 | ppl 44.77 | wps 413729 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3536 | lr 0.000442012 | gnorm 0.668 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33478
2023-02-11 04:52:24 | INFO | fairseq.trainer | begin training epoch 712
2023-02-11 04:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:53:02 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2023-02-11 04:53:02 | INFO | train | epoch 712 | loss 5.473 | ppl 44.41 | wps 551067 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3541 | lr 0.000442636 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33516
2023-02-11 04:53:02 | INFO | fairseq.trainer | begin training epoch 713
2023-02-11 04:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:53:42 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2023-02-11 04:53:42 | INFO | train | epoch 713 | loss 5.47 | ppl 44.32 | wps 524620 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3546 | lr 0.000443261 | gnorm 0.562 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33556
2023-02-11 04:53:43 | INFO | fairseq.trainer | begin training epoch 714
2023-02-11 04:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:54:25 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2023-02-11 04:54:25 | INFO | train | epoch 714 | loss 5.462 | ppl 44.09 | wps 498259 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3551 | lr 0.000443886 | gnorm 0.537 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33599
2023-02-11 04:54:25 | INFO | fairseq.trainer | begin training epoch 715
2023-02-11 04:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:55:04 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2023-02-11 04:55:04 | INFO | train | epoch 715 | loss 5.463 | ppl 44.11 | wps 527801 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3556 | lr 0.000444511 | gnorm 0.577 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33638
2023-02-11 04:55:05 | INFO | fairseq.trainer | begin training epoch 716
2023-02-11 04:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:55:45 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2023-02-11 04:55:45 | INFO | train | epoch 716 | loss 5.457 | ppl 43.93 | wps 520117 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3561 | lr 0.000445136 | gnorm 0.517 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33679
2023-02-11 04:55:45 | INFO | fairseq.trainer | begin training epoch 717
2023-02-11 04:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:56:23 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2023-02-11 04:56:23 | INFO | train | epoch 717 | loss 5.45 | ppl 43.71 | wps 549860 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3566 | lr 0.000445761 | gnorm 0.453 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33717
2023-02-11 04:56:23 | INFO | fairseq.trainer | begin training epoch 718
2023-02-11 04:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:57:03 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2023-02-11 04:57:03 | INFO | train | epoch 718 | loss 5.45 | ppl 43.7 | wps 532594 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3571 | lr 0.000446386 | gnorm 0.537 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33757
2023-02-11 04:57:03 | INFO | fairseq.trainer | begin training epoch 719
2023-02-11 04:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:57:44 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2023-02-11 04:57:44 | INFO | train | epoch 719 | loss 5.455 | ppl 43.86 | wps 512142 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3576 | lr 0.000447011 | gnorm 0.637 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33798
2023-02-11 04:57:44 | INFO | fairseq.trainer | begin training epoch 720
2023-02-11 04:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 04:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 04:58:31 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 5.231 | ppl 37.54 | wps 0 | wpb 11230 | bsz 22 | num_updates 3581 | best_loss 5.222
2023-02-11 04:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 3581 updates
2023-02-11 04:58:31 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint720.pt
2023-02-11 04:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint720.pt
2023-02-11 04:59:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint720.pt (epoch 720 @ 3581 updates, score 5.231) (writing took 60.24202544399304 seconds)
2023-02-11 04:59:32 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2023-02-11 04:59:32 | INFO | train | epoch 720 | loss 5.465 | ppl 44.16 | wps 194813 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3581 | lr 0.000447635 | gnorm 0.636 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33906
2023-02-11 04:59:32 | INFO | fairseq.trainer | begin training epoch 721
2023-02-11 04:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:00:16 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2023-02-11 05:00:16 | INFO | train | epoch 721 | loss 5.459 | ppl 43.97 | wps 471725 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3586 | lr 0.00044826 | gnorm 0.582 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33950
2023-02-11 05:00:17 | INFO | fairseq.trainer | begin training epoch 722
2023-02-11 05:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:00:53 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2023-02-11 05:00:53 | INFO | train | epoch 722 | loss 5.459 | ppl 43.99 | wps 569238 | ups 0.14 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3591 | lr 0.000448885 | gnorm 0.661 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 33987
2023-02-11 05:00:53 | INFO | fairseq.trainer | begin training epoch 723
2023-02-11 05:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:01:35 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2023-02-11 05:01:35 | INFO | train | epoch 723 | loss 5.456 | ppl 43.89 | wps 509034 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3596 | lr 0.00044951 | gnorm 0.589 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34029
2023-02-11 05:01:35 | INFO | fairseq.trainer | begin training epoch 724
2023-02-11 05:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:02:15 | INFO | train_inner | epoch 724:      4 / 5 loss=5.464, ppl=44.15, wps=437087, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3600, lr=0.00045001, gnorm=0.561, loss_scale=1, train_wall=662, gb_free=5.4, wall=34069
2023-02-11 05:02:15 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2023-02-11 05:02:15 | INFO | train | epoch 724 | loss 5.45 | ppl 43.71 | wps 516031 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3601 | lr 0.000450135 | gnorm 0.565 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34069
2023-02-11 05:02:16 | INFO | fairseq.trainer | begin training epoch 725
2023-02-11 05:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:02:56 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2023-02-11 05:02:56 | INFO | train | epoch 725 | loss 5.449 | ppl 43.68 | wps 521163 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3606 | lr 0.00045076 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34110
2023-02-11 05:02:56 | INFO | fairseq.trainer | begin training epoch 726
2023-02-11 05:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:03:37 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2023-02-11 05:03:37 | INFO | train | epoch 726 | loss 5.44 | ppl 43.4 | wps 503981 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3611 | lr 0.000451385 | gnorm 0.46 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 34151
2023-02-11 05:03:38 | INFO | fairseq.trainer | begin training epoch 727
2023-02-11 05:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:04:18 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2023-02-11 05:04:18 | INFO | train | epoch 727 | loss 5.433 | ppl 43.21 | wps 523327 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3616 | lr 0.00045201 | gnorm 0.403 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 34192
2023-02-11 05:04:18 | INFO | fairseq.trainer | begin training epoch 728
2023-02-11 05:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:04:58 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2023-02-11 05:04:58 | INFO | train | epoch 728 | loss 5.436 | ppl 43.28 | wps 516326 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3621 | lr 0.000452634 | gnorm 0.533 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 34232
2023-02-11 05:04:59 | INFO | fairseq.trainer | begin training epoch 729
2023-02-11 05:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:05:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 05:05:40 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2023-02-11 05:05:40 | INFO | train | epoch 729 | loss 5.451 | ppl 43.74 | wps 375942 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 3625 | lr 0.000453134 | gnorm 0.642 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34274
2023-02-11 05:05:41 | INFO | fairseq.trainer | begin training epoch 730
2023-02-11 05:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:06:27 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 5.244 | ppl 37.9 | wps 0 | wpb 11230 | bsz 22 | num_updates 3630 | best_loss 5.222
2023-02-11 05:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 3630 updates
2023-02-11 05:06:27 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint730.pt
2023-02-11 05:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint730.pt
2023-02-11 05:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint730.pt (epoch 730 @ 3630 updates, score 5.244) (writing took 59.71830051500001 seconds)
2023-02-11 05:07:27 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2023-02-11 05:07:27 | INFO | train | epoch 730 | loss 5.444 | ppl 43.52 | wps 197060 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3630 | lr 0.000453759 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34381
2023-02-11 05:07:27 | INFO | fairseq.trainer | begin training epoch 731
2023-02-11 05:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:08:09 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2023-02-11 05:08:09 | INFO | train | epoch 731 | loss 5.466 | ppl 44.19 | wps 496750 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3635 | lr 0.000454384 | gnorm 0.839 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34423
2023-02-11 05:08:10 | INFO | fairseq.trainer | begin training epoch 732
2023-02-11 05:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:08:49 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2023-02-11 05:08:49 | INFO | train | epoch 732 | loss 5.446 | ppl 43.6 | wps 525824 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3640 | lr 0.000455009 | gnorm 0.516 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34463
2023-02-11 05:08:50 | INFO | fairseq.trainer | begin training epoch 733
2023-02-11 05:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:09:30 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2023-02-11 05:09:30 | INFO | train | epoch 733 | loss 5.45 | ppl 43.72 | wps 516742 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3645 | lr 0.000455634 | gnorm 0.685 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34504
2023-02-11 05:09:30 | INFO | fairseq.trainer | begin training epoch 734
2023-02-11 05:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:10:11 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2023-02-11 05:10:11 | INFO | train | epoch 734 | loss 5.453 | ppl 43.81 | wps 518198 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3650 | lr 0.000456259 | gnorm 0.706 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34545
2023-02-11 05:10:11 | INFO | fairseq.trainer | begin training epoch 735
2023-02-11 05:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:10:52 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2023-02-11 05:10:52 | INFO | train | epoch 735 | loss 5.449 | ppl 43.68 | wps 505148 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3655 | lr 0.000456884 | gnorm 0.651 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34586
2023-02-11 05:10:53 | INFO | fairseq.trainer | begin training epoch 736
2023-02-11 05:10:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:11:32 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2023-02-11 05:11:32 | INFO | train | epoch 736 | loss 5.435 | ppl 43.25 | wps 526663 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3660 | lr 0.000457509 | gnorm 0.512 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34626
2023-02-11 05:11:34 | INFO | fairseq.trainer | begin training epoch 737
2023-02-11 05:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:12:14 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2023-02-11 05:12:14 | INFO | train | epoch 737 | loss 5.428 | ppl 43.06 | wps 508583 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3665 | lr 0.000458133 | gnorm 0.494 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34668
2023-02-11 05:12:14 | INFO | fairseq.trainer | begin training epoch 738
2023-02-11 05:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:12:56 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2023-02-11 05:12:56 | INFO | train | epoch 738 | loss 5.425 | ppl 42.97 | wps 502267 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3670 | lr 0.000458758 | gnorm 0.515 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34710
2023-02-11 05:12:56 | INFO | fairseq.trainer | begin training epoch 739
2023-02-11 05:12:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:13:35 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2023-02-11 05:13:35 | INFO | train | epoch 739 | loss 5.421 | ppl 42.83 | wps 528902 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3675 | lr 0.000459383 | gnorm 0.483 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34749
2023-02-11 05:13:36 | INFO | fairseq.trainer | begin training epoch 740
2023-02-11 05:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:14:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:14:25 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 5.193 | ppl 36.59 | wps 0 | wpb 11230 | bsz 22 | num_updates 3680 | best_loss 5.193
2023-02-11 05:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 3680 updates
2023-02-11 05:14:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint740.pt
2023-02-11 05:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint740.pt
2023-02-11 05:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint740.pt (epoch 740 @ 3680 updates, score 5.193) (writing took 66.54936156299664 seconds)
2023-02-11 05:15:31 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2023-02-11 05:15:31 | INFO | train | epoch 740 | loss 5.417 | ppl 42.71 | wps 181511 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3680 | lr 0.000460008 | gnorm 0.486 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34865
2023-02-11 05:15:31 | INFO | fairseq.trainer | begin training epoch 741
2023-02-11 05:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:16:50 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2023-02-11 05:16:50 | INFO | train | epoch 741 | loss 5.412 | ppl 42.59 | wps 268517 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3685 | lr 0.000460633 | gnorm 0.445 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34944
2023-02-11 05:16:50 | INFO | fairseq.trainer | begin training epoch 742
2023-02-11 05:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:17:27 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2023-02-11 05:17:27 | INFO | train | epoch 742 | loss 5.424 | ppl 42.93 | wps 564331 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3690 | lr 0.000461258 | gnorm 0.65 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 34981
2023-02-11 05:17:27 | INFO | fairseq.trainer | begin training epoch 743
2023-02-11 05:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:18:08 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2023-02-11 05:18:08 | INFO | train | epoch 743 | loss 5.424 | ppl 42.93 | wps 514698 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3695 | lr 0.000461883 | gnorm 0.589 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35022
2023-02-11 05:18:08 | INFO | fairseq.trainer | begin training epoch 744
2023-02-11 05:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:18:48 | INFO | train_inner | epoch 744:      5 / 5 loss=5.436, ppl=43.29, wps=418225, ups=0.1, wpb=4.15596e+06, bsz=8117.2, num_updates=3700, lr=0.000462508, gnorm=0.569, loss_scale=1, train_wall=661, gb_free=5.6, wall=35063
2023-02-11 05:18:48 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2023-02-11 05:18:48 | INFO | train | epoch 744 | loss 5.421 | ppl 42.85 | wps 515541 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3700 | lr 0.000462508 | gnorm 0.613 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35063
2023-02-11 05:18:49 | INFO | fairseq.trainer | begin training epoch 745
2023-02-11 05:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:19:29 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2023-02-11 05:19:29 | INFO | train | epoch 745 | loss 5.416 | ppl 42.71 | wps 521625 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3705 | lr 0.000463132 | gnorm 0.525 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35103
2023-02-11 05:19:29 | INFO | fairseq.trainer | begin training epoch 746
2023-02-11 05:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:20:10 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2023-02-11 05:20:10 | INFO | train | epoch 746 | loss 5.415 | ppl 42.66 | wps 506296 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3710 | lr 0.000463757 | gnorm 0.555 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35144
2023-02-11 05:20:11 | INFO | fairseq.trainer | begin training epoch 747
2023-02-11 05:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:20:51 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2023-02-11 05:20:51 | INFO | train | epoch 747 | loss 5.413 | ppl 42.59 | wps 513323 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3715 | lr 0.000464382 | gnorm 0.529 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35185
2023-02-11 05:20:52 | INFO | fairseq.trainer | begin training epoch 748
2023-02-11 05:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:21:32 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2023-02-11 05:21:32 | INFO | train | epoch 748 | loss 5.406 | ppl 42.4 | wps 519618 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3720 | lr 0.000465007 | gnorm 0.481 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35226
2023-02-11 05:21:32 | INFO | fairseq.trainer | begin training epoch 749
2023-02-11 05:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:22:13 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2023-02-11 05:22:13 | INFO | train | epoch 749 | loss 5.418 | ppl 42.76 | wps 509696 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3725 | lr 0.000465632 | gnorm 0.733 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35267
2023-02-11 05:22:13 | INFO | fairseq.trainer | begin training epoch 750
2023-02-11 05:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:23:01 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 5.215 | ppl 37.14 | wps 0 | wpb 11230 | bsz 22 | num_updates 3730 | best_loss 5.193
2023-02-11 05:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 3730 updates
2023-02-11 05:23:01 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint750.pt
2023-02-11 05:23:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint750.pt
2023-02-11 05:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint750.pt (epoch 750 @ 3730 updates, score 5.215) (writing took 68.03137729200535 seconds)
2023-02-11 05:24:09 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2023-02-11 05:24:09 | INFO | train | epoch 750 | loss 5.448 | ppl 43.64 | wps 181600 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3730 | lr 0.000466257 | gnorm 0.896 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35383
2023-02-11 05:24:09 | INFO | fairseq.trainer | begin training epoch 751
2023-02-11 05:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:24:52 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2023-02-11 05:24:52 | INFO | train | epoch 751 | loss 5.443 | ppl 43.51 | wps 483401 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3735 | lr 0.000466882 | gnorm 0.767 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35426
2023-02-11 05:24:53 | INFO | fairseq.trainer | begin training epoch 752
2023-02-11 05:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:25:33 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2023-02-11 05:25:33 | INFO | train | epoch 752 | loss 5.438 | ppl 43.36 | wps 524244 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3740 | lr 0.000467507 | gnorm 0.73 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35467
2023-02-11 05:25:33 | INFO | fairseq.trainer | begin training epoch 753
2023-02-11 05:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:26:14 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2023-02-11 05:26:14 | INFO | train | epoch 753 | loss 5.419 | ppl 42.77 | wps 505068 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3745 | lr 0.000468131 | gnorm 0.516 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35508
2023-02-11 05:26:14 | INFO | fairseq.trainer | begin training epoch 754
2023-02-11 05:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:26:55 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2023-02-11 05:26:55 | INFO | train | epoch 754 | loss 5.403 | ppl 42.32 | wps 518672 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3750 | lr 0.000468756 | gnorm 0.39 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35549
2023-02-11 05:26:55 | INFO | fairseq.trainer | begin training epoch 755
2023-02-11 05:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:27:35 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2023-02-11 05:27:35 | INFO | train | epoch 755 | loss 5.4 | ppl 42.23 | wps 520077 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3755 | lr 0.000469381 | gnorm 0.472 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35589
2023-02-11 05:27:35 | INFO | fairseq.trainer | begin training epoch 756
2023-02-11 05:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:28:17 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2023-02-11 05:28:17 | INFO | train | epoch 756 | loss 5.394 | ppl 42.06 | wps 503750 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3760 | lr 0.000470006 | gnorm 0.436 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35631
2023-02-11 05:28:17 | INFO | fairseq.trainer | begin training epoch 757
2023-02-11 05:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:28:58 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2023-02-11 05:28:58 | INFO | train | epoch 757 | loss 5.395 | ppl 42.07 | wps 518272 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3765 | lr 0.000470631 | gnorm 0.54 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35672
2023-02-11 05:28:58 | INFO | fairseq.trainer | begin training epoch 758
2023-02-11 05:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:29:38 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2023-02-11 05:29:38 | INFO | train | epoch 758 | loss 5.393 | ppl 42.01 | wps 519064 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3770 | lr 0.000471256 | gnorm 0.528 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35712
2023-02-11 05:29:38 | INFO | fairseq.trainer | begin training epoch 759
2023-02-11 05:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:30:20 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2023-02-11 05:30:20 | INFO | train | epoch 759 | loss 5.4 | ppl 42.24 | wps 500752 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3775 | lr 0.000471881 | gnorm 0.654 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35754
2023-02-11 05:30:20 | INFO | fairseq.trainer | begin training epoch 760
2023-02-11 05:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:31:07 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 5.21 | ppl 37.01 | wps 0 | wpb 11230 | bsz 22 | num_updates 3780 | best_loss 5.193
2023-02-11 05:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 3780 updates
2023-02-11 05:31:07 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint760.pt
2023-02-11 05:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint760.pt
2023-02-11 05:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint760.pt (epoch 760 @ 3780 updates, score 5.21) (writing took 62.48090783398948 seconds)
2023-02-11 05:32:10 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2023-02-11 05:32:10 | INFO | train | epoch 760 | loss 5.41 | ppl 42.52 | wps 191814 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3780 | lr 0.000472506 | gnorm 0.707 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35864
2023-02-11 05:32:10 | INFO | fairseq.trainer | begin training epoch 761
2023-02-11 05:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:32:54 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2023-02-11 05:32:54 | INFO | train | epoch 761 | loss 5.403 | ppl 42.32 | wps 474031 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3785 | lr 0.00047313 | gnorm 0.63 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35908
2023-02-11 05:32:54 | INFO | fairseq.trainer | begin training epoch 762
2023-02-11 05:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:33:34 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2023-02-11 05:33:34 | INFO | train | epoch 762 | loss 5.395 | ppl 42.08 | wps 531668 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3790 | lr 0.000473755 | gnorm 0.559 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35948
2023-02-11 05:33:34 | INFO | fairseq.trainer | begin training epoch 763
2023-02-11 05:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:34:16 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2023-02-11 05:34:16 | INFO | train | epoch 763 | loss 5.394 | ppl 42.04 | wps 502245 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3795 | lr 0.00047438 | gnorm 0.57 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 35990
2023-02-11 05:34:16 | INFO | fairseq.trainer | begin training epoch 764
2023-02-11 05:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:34:56 | INFO | train_inner | epoch 764:      5 / 5 loss=5.41, ppl=42.51, wps=434908, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=3800, lr=0.000475005, gnorm=0.591, loss_scale=1, train_wall=662, gb_free=5.6, wall=36030
2023-02-11 05:34:56 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2023-02-11 05:34:56 | INFO | train | epoch 764 | loss 5.393 | ppl 42.03 | wps 522982 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3800 | lr 0.000475005 | gnorm 0.599 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36030
2023-02-11 05:34:56 | INFO | fairseq.trainer | begin training epoch 765
2023-02-11 05:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:35:37 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2023-02-11 05:35:37 | INFO | train | epoch 765 | loss 5.392 | ppl 42 | wps 511938 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3805 | lr 0.00047563 | gnorm 0.577 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36071
2023-02-11 05:35:37 | INFO | fairseq.trainer | begin training epoch 766
2023-02-11 05:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:36:18 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2023-02-11 05:36:18 | INFO | train | epoch 766 | loss 5.384 | ppl 41.76 | wps 506751 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3810 | lr 0.000476255 | gnorm 0.461 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36112
2023-02-11 05:36:19 | INFO | fairseq.trainer | begin training epoch 767
2023-02-11 05:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:36:59 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2023-02-11 05:36:59 | INFO | train | epoch 767 | loss 5.376 | ppl 41.53 | wps 522024 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3815 | lr 0.00047688 | gnorm 0.409 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36153
2023-02-11 05:36:59 | INFO | fairseq.trainer | begin training epoch 768
2023-02-11 05:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:37:40 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2023-02-11 05:37:40 | INFO | train | epoch 768 | loss 5.389 | ppl 41.92 | wps 511216 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3820 | lr 0.000477505 | gnorm 0.674 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36194
2023-02-11 05:37:40 | INFO | fairseq.trainer | begin training epoch 769
2023-02-11 05:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:38:21 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2023-02-11 05:38:21 | INFO | train | epoch 769 | loss 5.396 | ppl 42.11 | wps 506128 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3825 | lr 0.000478129 | gnorm 0.777 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36235
2023-02-11 05:38:22 | INFO | fairseq.trainer | begin training epoch 770
2023-02-11 05:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:39:09 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 5.171 | ppl 36.03 | wps 0 | wpb 11230 | bsz 22 | num_updates 3830 | best_loss 5.171
2023-02-11 05:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 3830 updates
2023-02-11 05:39:09 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint770.pt
2023-02-11 05:39:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint770.pt
2023-02-11 05:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint770.pt (epoch 770 @ 3830 updates, score 5.171) (writing took 63.84673192197806 seconds)
2023-02-11 05:40:13 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2023-02-11 05:40:13 | INFO | train | epoch 770 | loss 5.399 | ppl 42.18 | wps 188589 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3830 | lr 0.000478754 | gnorm 0.719 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36347
2023-02-11 05:40:13 | INFO | fairseq.trainer | begin training epoch 771
2023-02-11 05:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:40:55 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2023-02-11 05:40:55 | INFO | train | epoch 771 | loss 5.393 | ppl 42.02 | wps 496051 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3835 | lr 0.000479379 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36389
2023-02-11 05:40:56 | INFO | fairseq.trainer | begin training epoch 772
2023-02-11 05:40:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:41:36 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2023-02-11 05:41:36 | INFO | train | epoch 772 | loss 5.384 | ppl 41.76 | wps 517990 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3840 | lr 0.000480004 | gnorm 0.534 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36430
2023-02-11 05:41:36 | INFO | fairseq.trainer | begin training epoch 773
2023-02-11 05:41:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:42:16 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2023-02-11 05:42:16 | INFO | train | epoch 773 | loss 5.377 | ppl 41.57 | wps 522732 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3845 | lr 0.000480629 | gnorm 0.509 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36470
2023-02-11 05:42:16 | INFO | fairseq.trainer | begin training epoch 774
2023-02-11 05:42:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:42:57 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2023-02-11 05:42:57 | INFO | train | epoch 774 | loss 5.378 | ppl 41.59 | wps 517841 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3850 | lr 0.000481254 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36511
2023-02-11 05:42:57 | INFO | fairseq.trainer | begin training epoch 775
2023-02-11 05:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:43:39 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2023-02-11 05:43:39 | INFO | train | epoch 775 | loss 5.371 | ppl 41.38 | wps 501476 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3855 | lr 0.000481879 | gnorm 0.482 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36553
2023-02-11 05:43:39 | INFO | fairseq.trainer | begin training epoch 776
2023-02-11 05:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:44:19 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2023-02-11 05:44:19 | INFO | train | epoch 776 | loss 5.369 | ppl 41.32 | wps 519895 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3860 | lr 0.000482504 | gnorm 0.543 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36593
2023-02-11 05:44:19 | INFO | fairseq.trainer | begin training epoch 777
2023-02-11 05:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:45:00 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2023-02-11 05:45:00 | INFO | train | epoch 777 | loss 5.378 | ppl 41.59 | wps 517256 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3865 | lr 0.000483128 | gnorm 0.655 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36634
2023-02-11 05:45:00 | INFO | fairseq.trainer | begin training epoch 778
2023-02-11 05:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:45:42 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2023-02-11 05:45:42 | INFO | train | epoch 778 | loss 5.371 | ppl 41.38 | wps 503036 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3870 | lr 0.000483753 | gnorm 0.524 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36676
2023-02-11 05:45:42 | INFO | fairseq.trainer | begin training epoch 779
2023-02-11 05:45:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:46:22 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2023-02-11 05:46:22 | INFO | train | epoch 779 | loss 5.374 | ppl 41.46 | wps 521114 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3875 | lr 0.000484378 | gnorm 0.648 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36716
2023-02-11 05:46:22 | INFO | fairseq.trainer | begin training epoch 780
2023-02-11 05:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:47:11 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 5.192 | ppl 36.56 | wps 0 | wpb 11230 | bsz 22 | num_updates 3880 | best_loss 5.171
2023-02-11 05:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 3880 updates
2023-02-11 05:47:11 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint780.pt
2023-02-11 05:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint780.pt
2023-02-11 05:48:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint780.pt (epoch 780 @ 3880 updates, score 5.192) (writing took 64.28273866901873 seconds)
2023-02-11 05:48:15 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2023-02-11 05:48:15 | INFO | train | epoch 780 | loss 5.371 | ppl 41.4 | wps 186133 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3880 | lr 0.000485003 | gnorm 0.538 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 36829
2023-02-11 05:48:15 | INFO | fairseq.trainer | begin training epoch 781
2023-02-11 05:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:49:01 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2023-02-11 05:49:01 | INFO | train | epoch 781 | loss 5.363 | ppl 41.16 | wps 453726 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3885 | lr 0.000485628 | gnorm 0.463 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 36875
2023-02-11 05:49:02 | INFO | fairseq.trainer | begin training epoch 782
2023-02-11 05:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:49:43 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2023-02-11 05:49:43 | INFO | train | epoch 782 | loss 5.358 | ppl 41.01 | wps 508637 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3890 | lr 0.000486253 | gnorm 0.447 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 36917
2023-02-11 05:49:43 | INFO | fairseq.trainer | begin training epoch 783
2023-02-11 05:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 05:50:23 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2023-02-11 05:50:23 | INFO | train | epoch 783 | loss 5.362 | ppl 41.12 | wps 391858 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 3894 | lr 0.000486753 | gnorm 0.593 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36957
2023-02-11 05:50:23 | INFO | fairseq.trainer | begin training epoch 784
2023-02-11 05:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:51:04 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2023-02-11 05:51:04 | INFO | train | epoch 784 | loss 5.381 | ppl 41.66 | wps 518176 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3899 | lr 0.000487378 | gnorm 0.849 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 36998
2023-02-11 05:51:04 | INFO | fairseq.trainer | begin training epoch 785
2023-02-11 05:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:51:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 05:51:29 | INFO | train_inner | epoch 785:      2 / 5 loss=5.379, ppl=41.62, wps=423629, ups=0.1, wpb=4.20574e+06, bsz=8214.4, num_updates=3900, lr=0.000487503, gnorm=0.586, loss_scale=0.5, train_wall=678, gb_free=5.4, wall=37023
2023-02-11 05:51:46 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2023-02-11 05:51:46 | INFO | train | epoch 785 | loss 5.431 | ppl 43.14 | wps 375640 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 3903 | lr 0.000487877 | gnorm 1.038 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37040
2023-02-11 05:51:46 | INFO | fairseq.trainer | begin training epoch 786
2023-02-11 05:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:52:26 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2023-02-11 05:52:26 | INFO | train | epoch 786 | loss 5.419 | ppl 42.8 | wps 526171 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3908 | lr 0.000488502 | gnorm 0.793 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37080
2023-02-11 05:52:26 | INFO | fairseq.trainer | begin training epoch 787
2023-02-11 05:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:53:06 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2023-02-11 05:53:06 | INFO | train | epoch 787 | loss 5.395 | ppl 42.08 | wps 517129 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3913 | lr 0.000489127 | gnorm 0.644 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37120
2023-02-11 05:53:07 | INFO | fairseq.trainer | begin training epoch 788
2023-02-11 05:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:53:49 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2023-02-11 05:53:49 | INFO | train | epoch 788 | loss 5.383 | ppl 41.72 | wps 498368 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3918 | lr 0.000489752 | gnorm 0.605 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37163
2023-02-11 05:53:49 | INFO | fairseq.trainer | begin training epoch 789
2023-02-11 05:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:54:29 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2023-02-11 05:54:29 | INFO | train | epoch 789 | loss 5.368 | ppl 41.3 | wps 521404 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3923 | lr 0.000490377 | gnorm 0.481 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37203
2023-02-11 05:54:29 | INFO | fairseq.trainer | begin training epoch 790
2023-02-11 05:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 05:55:17 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 5.187 | ppl 36.43 | wps 0 | wpb 11230 | bsz 22 | num_updates 3928 | best_loss 5.171
2023-02-11 05:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 3928 updates
2023-02-11 05:55:17 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint790.pt
2023-02-11 05:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint790.pt
2023-02-11 05:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint790.pt (epoch 790 @ 3928 updates, score 5.187) (writing took 59.486986519012135 seconds)
2023-02-11 05:56:17 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2023-02-11 05:56:17 | INFO | train | epoch 790 | loss 5.357 | ppl 40.97 | wps 194570 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3928 | lr 0.000491002 | gnorm 0.43 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37311
2023-02-11 05:56:17 | INFO | fairseq.trainer | begin training epoch 791
2023-02-11 05:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:57:08 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2023-02-11 05:57:08 | INFO | train | epoch 791 | loss 5.359 | ppl 41.03 | wps 408481 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3933 | lr 0.000491627 | gnorm 0.532 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37363
2023-02-11 05:57:09 | INFO | fairseq.trainer | begin training epoch 792
2023-02-11 05:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:57:49 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2023-02-11 05:57:49 | INFO | train | epoch 792 | loss 5.35 | ppl 40.78 | wps 516949 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3938 | lr 0.000492252 | gnorm 0.477 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37403
2023-02-11 05:57:49 | INFO | fairseq.trainer | begin training epoch 793
2023-02-11 05:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:58:29 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2023-02-11 05:58:29 | INFO | train | epoch 793 | loss 5.352 | ppl 40.84 | wps 524397 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3943 | lr 0.000492876 | gnorm 0.511 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37443
2023-02-11 05:58:30 | INFO | fairseq.trainer | begin training epoch 794
2023-02-11 05:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:59:10 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2023-02-11 05:59:10 | INFO | train | epoch 794 | loss 5.348 | ppl 40.74 | wps 511801 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3948 | lr 0.000493501 | gnorm 0.553 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37484
2023-02-11 05:59:11 | INFO | fairseq.trainer | begin training epoch 795
2023-02-11 05:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 05:59:52 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2023-02-11 05:59:52 | INFO | train | epoch 795 | loss 5.35 | ppl 40.79 | wps 504564 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3953 | lr 0.000494126 | gnorm 0.566 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37526
2023-02-11 05:59:52 | INFO | fairseq.trainer | begin training epoch 796
2023-02-11 05:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:00:32 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2023-02-11 06:00:32 | INFO | train | epoch 796 | loss 5.355 | ppl 40.92 | wps 522492 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3958 | lr 0.000494751 | gnorm 0.64 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37566
2023-02-11 06:00:33 | INFO | fairseq.trainer | begin training epoch 797
2023-02-11 06:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:01:13 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2023-02-11 06:01:13 | INFO | train | epoch 797 | loss 5.361 | ppl 41.09 | wps 513171 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3963 | lr 0.000495376 | gnorm 0.741 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37607
2023-02-11 06:01:14 | INFO | fairseq.trainer | begin training epoch 798
2023-02-11 06:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:01:55 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2023-02-11 06:01:55 | INFO | train | epoch 798 | loss 5.352 | ppl 40.83 | wps 508149 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3968 | lr 0.000496001 | gnorm 0.572 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37649
2023-02-11 06:01:55 | INFO | fairseq.trainer | begin training epoch 799
2023-02-11 06:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:02:35 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2023-02-11 06:02:35 | INFO | train | epoch 799 | loss 5.354 | ppl 40.89 | wps 521162 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3973 | lr 0.000496626 | gnorm 0.651 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37689
2023-02-11 06:02:35 | INFO | fairseq.trainer | begin training epoch 800
2023-02-11 06:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:03:24 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 5.18 | ppl 36.26 | wps 0 | wpb 11230 | bsz 22 | num_updates 3978 | best_loss 5.171
2023-02-11 06:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 3978 updates
2023-02-11 06:03:24 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint800.pt
2023-02-11 06:03:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint800.pt
2023-02-11 06:04:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint800.pt (epoch 800 @ 3978 updates, score 5.18) (writing took 66.23429847098305 seconds)
2023-02-11 06:04:30 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2023-02-11 06:04:30 | INFO | train | epoch 800 | loss 5.351 | ppl 40.81 | wps 182696 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3978 | lr 0.000497251 | gnorm 0.575 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37804
2023-02-11 06:04:30 | INFO | fairseq.trainer | begin training epoch 801
2023-02-11 06:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:05:20 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2023-02-11 06:05:20 | INFO | train | epoch 801 | loss 5.341 | ppl 40.52 | wps 424474 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3983 | lr 0.000497875 | gnorm 0.513 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37854
2023-02-11 06:05:20 | INFO | fairseq.trainer | begin training epoch 802
2023-02-11 06:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:06:01 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2023-02-11 06:06:01 | INFO | train | epoch 802 | loss 5.341 | ppl 40.52 | wps 512403 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3988 | lr 0.0004985 | gnorm 0.59 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37895
2023-02-11 06:06:01 | INFO | fairseq.trainer | begin training epoch 803
2023-02-11 06:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:06:41 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2023-02-11 06:06:41 | INFO | train | epoch 803 | loss 5.359 | ppl 41.04 | wps 518354 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3993 | lr 0.000499125 | gnorm 0.797 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37935
2023-02-11 06:06:42 | INFO | fairseq.trainer | begin training epoch 804
2023-02-11 06:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:07:22 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2023-02-11 06:07:22 | INFO | train | epoch 804 | loss 5.368 | ppl 41.29 | wps 516097 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 3998 | lr 0.00049975 | gnorm 0.708 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 37976
2023-02-11 06:07:22 | INFO | fairseq.trainer | begin training epoch 805
2023-02-11 06:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:07:46 | INFO | train_inner | epoch 805:      2 / 5 loss=5.363, ppl=41.14, wps=430368, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=4000, lr=0.0005, gnorm=0.61, loss_scale=0.5, train_wall=661, gb_free=5.4, wall=38000
2023-02-11 06:08:03 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2023-02-11 06:08:03 | INFO | train | epoch 805 | loss 5.347 | ppl 40.71 | wps 512922 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4003 | lr 0.000499813 | gnorm 0.54 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38017
2023-02-11 06:08:03 | INFO | fairseq.trainer | begin training epoch 806
2023-02-11 06:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:08:44 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2023-02-11 06:08:44 | INFO | train | epoch 806 | loss 5.343 | ppl 40.58 | wps 512863 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4008 | lr 0.000499501 | gnorm 0.563 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38058
2023-02-11 06:08:44 | INFO | fairseq.trainer | begin training epoch 807
2023-02-11 06:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:09:25 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2023-02-11 06:09:25 | INFO | train | epoch 807 | loss 5.337 | ppl 40.41 | wps 513919 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4013 | lr 0.000499189 | gnorm 0.529 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38099
2023-02-11 06:09:25 | INFO | fairseq.trainer | begin training epoch 808
2023-02-11 06:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:10:06 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2023-02-11 06:10:06 | INFO | train | epoch 808 | loss 5.331 | ppl 40.25 | wps 509398 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4018 | lr 0.000498879 | gnorm 0.486 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38140
2023-02-11 06:10:07 | INFO | fairseq.trainer | begin training epoch 809
2023-02-11 06:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:10:47 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2023-02-11 06:10:47 | INFO | train | epoch 809 | loss 5.329 | ppl 40.19 | wps 522300 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4023 | lr 0.000498569 | gnorm 0.542 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38181
2023-02-11 06:10:47 | INFO | fairseq.trainer | begin training epoch 810
2023-02-11 06:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:11:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:11:36 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 5.182 | ppl 36.31 | wps 0 | wpb 11230 | bsz 22 | num_updates 4028 | best_loss 5.171
2023-02-11 06:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 4028 updates
2023-02-11 06:11:36 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint810.pt
2023-02-11 06:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint810.pt
2023-02-11 06:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint810.pt (epoch 810 @ 4028 updates, score 5.182) (writing took 73.22761583401007 seconds)
2023-02-11 06:12:49 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2023-02-11 06:12:49 | INFO | train | epoch 810 | loss 5.329 | ppl 40.21 | wps 171708 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4028 | lr 0.000498259 | gnorm 0.571 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38303
2023-02-11 06:12:49 | INFO | fairseq.trainer | begin training epoch 811
2023-02-11 06:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:13:34 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2023-02-11 06:13:34 | INFO | train | epoch 811 | loss 5.333 | ppl 40.31 | wps 473812 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4033 | lr 0.00049795 | gnorm 0.668 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38348
2023-02-11 06:13:34 | INFO | fairseq.trainer | begin training epoch 812
2023-02-11 06:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:14:13 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2023-02-11 06:14:13 | INFO | train | epoch 812 | loss 5.335 | ppl 40.36 | wps 535585 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4038 | lr 0.000497642 | gnorm 0.668 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38387
2023-02-11 06:14:13 | INFO | fairseq.trainer | begin training epoch 813
2023-02-11 06:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:14:53 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2023-02-11 06:14:53 | INFO | train | epoch 813 | loss 5.386 | ppl 41.82 | wps 527397 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4043 | lr 0.000497334 | gnorm 1.067 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38427
2023-02-11 06:14:53 | INFO | fairseq.trainer | begin training epoch 814
2023-02-11 06:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:15:34 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2023-02-11 06:15:34 | INFO | train | epoch 814 | loss 5.372 | ppl 41.41 | wps 508087 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4048 | lr 0.000497027 | gnorm 0.656 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38468
2023-02-11 06:15:34 | INFO | fairseq.trainer | begin training epoch 815
2023-02-11 06:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:16:15 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2023-02-11 06:16:15 | INFO | train | epoch 815 | loss 5.344 | ppl 40.63 | wps 512262 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4053 | lr 0.00049672 | gnorm 0.463 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38509
2023-02-11 06:16:15 | INFO | fairseq.trainer | begin training epoch 816
2023-02-11 06:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:16:55 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2023-02-11 06:16:55 | INFO | train | epoch 816 | loss 5.336 | ppl 40.39 | wps 525936 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4058 | lr 0.000496414 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38549
2023-02-11 06:16:55 | INFO | fairseq.trainer | begin training epoch 817
2023-02-11 06:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:17:37 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2023-02-11 06:17:37 | INFO | train | epoch 817 | loss 5.326 | ppl 40.11 | wps 507865 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4063 | lr 0.000496108 | gnorm 0.485 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38591
2023-02-11 06:17:37 | INFO | fairseq.trainer | begin training epoch 818
2023-02-11 06:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:18:18 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2023-02-11 06:18:18 | INFO | train | epoch 818 | loss 5.315 | ppl 39.82 | wps 503205 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4068 | lr 0.000495803 | gnorm 0.393 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38632
2023-02-11 06:18:19 | INFO | fairseq.trainer | begin training epoch 819
2023-02-11 06:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:18:58 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2023-02-11 06:18:58 | INFO | train | epoch 819 | loss 5.309 | ppl 39.65 | wps 531330 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4073 | lr 0.000495499 | gnorm 0.382 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38672
2023-02-11 06:18:58 | INFO | fairseq.trainer | begin training epoch 820
2023-02-11 06:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:19:47 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 5.164 | ppl 35.84 | wps 0 | wpb 11230 | bsz 22 | num_updates 4078 | best_loss 5.164
2023-02-11 06:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 4078 updates
2023-02-11 06:19:47 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint820.pt
2023-02-11 06:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint820.pt
2023-02-11 06:20:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint820.pt (epoch 820 @ 4078 updates, score 5.164) (writing took 70.30725681598415 seconds)
2023-02-11 06:20:57 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2023-02-11 06:20:57 | INFO | train | epoch 820 | loss 5.313 | ppl 39.74 | wps 176206 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4078 | lr 0.000495195 | gnorm 0.515 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38791
2023-02-11 06:20:58 | INFO | fairseq.trainer | begin training epoch 821
2023-02-11 06:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:21:49 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2023-02-11 06:21:49 | INFO | train | epoch 821 | loss 5.31 | ppl 39.66 | wps 404541 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4083 | lr 0.000494892 | gnorm 0.521 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38843
2023-02-11 06:21:50 | INFO | fairseq.trainer | begin training epoch 822
2023-02-11 06:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:22:29 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2023-02-11 06:22:29 | INFO | train | epoch 822 | loss 5.314 | ppl 39.77 | wps 533839 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4088 | lr 0.000494589 | gnorm 0.593 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38883
2023-02-11 06:22:29 | INFO | fairseq.trainer | begin training epoch 823
2023-02-11 06:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:23:09 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2023-02-11 06:23:09 | INFO | train | epoch 823 | loss 5.316 | ppl 39.84 | wps 523147 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4093 | lr 0.000494287 | gnorm 0.633 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38923
2023-02-11 06:23:09 | INFO | fairseq.trainer | begin training epoch 824
2023-02-11 06:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:23:50 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2023-02-11 06:23:50 | INFO | train | epoch 824 | loss 5.312 | ppl 39.73 | wps 515882 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4098 | lr 0.000493985 | gnorm 0.583 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 38964
2023-02-11 06:23:50 | INFO | fairseq.trainer | begin training epoch 825
2023-02-11 06:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:24:15 | INFO | train_inner | epoch 825:      2 / 5 loss=5.331, ppl=40.25, wps=425617, ups=0.1, wpb=4.20776e+06, bsz=8218.4, num_updates=4100, lr=0.000493865, gnorm=0.571, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=38989
2023-02-11 06:24:32 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2023-02-11 06:24:32 | INFO | train | epoch 825 | loss 5.311 | ppl 39.69 | wps 501856 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4103 | lr 0.000493684 | gnorm 0.623 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39006
2023-02-11 06:24:32 | INFO | fairseq.trainer | begin training epoch 826
2023-02-11 06:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:25:12 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2023-02-11 06:25:12 | INFO | train | epoch 826 | loss 5.324 | ppl 40.07 | wps 521598 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4108 | lr 0.000493384 | gnorm 0.78 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39046
2023-02-11 06:25:12 | INFO | fairseq.trainer | begin training epoch 827
2023-02-11 06:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:25:52 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2023-02-11 06:25:52 | INFO | train | epoch 827 | loss 5.319 | ppl 39.91 | wps 519062 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4113 | lr 0.000493084 | gnorm 0.654 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39087
2023-02-11 06:25:53 | INFO | fairseq.trainer | begin training epoch 828
2023-02-11 06:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:26:35 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2023-02-11 06:26:35 | INFO | train | epoch 828 | loss 5.307 | ppl 39.6 | wps 499842 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4118 | lr 0.000492784 | gnorm 0.478 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39129
2023-02-11 06:26:35 | INFO | fairseq.trainer | begin training epoch 829
2023-02-11 06:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:27:15 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2023-02-11 06:27:15 | INFO | train | epoch 829 | loss 5.3 | ppl 39.4 | wps 520635 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4123 | lr 0.000492485 | gnorm 0.426 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39169
2023-02-11 06:27:15 | INFO | fairseq.trainer | begin training epoch 830
2023-02-11 06:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:28:04 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 5.137 | ppl 35.2 | wps 0 | wpb 11230 | bsz 22 | num_updates 4128 | best_loss 5.137
2023-02-11 06:28:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 4128 updates
2023-02-11 06:28:04 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint830.pt
2023-02-11 06:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint830.pt
2023-02-11 06:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint830.pt (epoch 830 @ 4128 updates, score 5.137) (writing took 65.71104453000589 seconds)
2023-02-11 06:29:09 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2023-02-11 06:29:09 | INFO | train | epoch 830 | loss 5.295 | ppl 39.25 | wps 183809 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4128 | lr 0.000492187 | gnorm 0.432 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39283
2023-02-11 06:29:10 | INFO | fairseq.trainer | begin training epoch 831
2023-02-11 06:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:29:58 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2023-02-11 06:29:58 | INFO | train | epoch 831 | loss 5.296 | ppl 39.29 | wps 431950 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4133 | lr 0.000491889 | gnorm 0.551 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39332
2023-02-11 06:29:58 | INFO | fairseq.trainer | begin training epoch 832
2023-02-11 06:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:30:41 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2023-02-11 06:30:41 | INFO | train | epoch 832 | loss 5.301 | ppl 39.42 | wps 495855 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4138 | lr 0.000491592 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39375
2023-02-11 06:30:41 | INFO | fairseq.trainer | begin training epoch 833
2023-02-11 06:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:31:21 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2023-02-11 06:31:21 | INFO | train | epoch 833 | loss 5.306 | ppl 39.55 | wps 520447 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4143 | lr 0.000491295 | gnorm 0.66 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39415
2023-02-11 06:31:21 | INFO | fairseq.trainer | begin training epoch 834
2023-02-11 06:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:32:02 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2023-02-11 06:32:02 | INFO | train | epoch 834 | loss 5.306 | ppl 39.56 | wps 514702 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4148 | lr 0.000490999 | gnorm 0.683 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39456
2023-02-11 06:32:02 | INFO | fairseq.trainer | begin training epoch 835
2023-02-11 06:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:32:43 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2023-02-11 06:32:43 | INFO | train | epoch 835 | loss 5.308 | ppl 39.61 | wps 506052 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4153 | lr 0.000490703 | gnorm 0.707 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 39497
2023-02-11 06:32:44 | INFO | fairseq.trainer | begin training epoch 836
2023-02-11 06:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:33:24 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2023-02-11 06:33:24 | INFO | train | epoch 836 | loss 5.3 | ppl 39.4 | wps 519533 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4158 | lr 0.000490408 | gnorm 0.559 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39538
2023-02-11 06:33:24 | INFO | fairseq.trainer | begin training epoch 837
2023-02-11 06:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:34:05 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2023-02-11 06:34:05 | INFO | train | epoch 837 | loss 5.297 | ppl 39.31 | wps 513068 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4163 | lr 0.000490114 | gnorm 0.566 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39579
2023-02-11 06:34:05 | INFO | fairseq.trainer | begin training epoch 838
2023-02-11 06:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:34:46 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2023-02-11 06:34:46 | INFO | train | epoch 838 | loss 5.297 | ppl 39.32 | wps 513842 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4168 | lr 0.00048982 | gnorm 0.603 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39620
2023-02-11 06:34:46 | INFO | fairseq.trainer | begin training epoch 839
2023-02-11 06:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:35:27 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2023-02-11 06:35:27 | INFO | train | epoch 839 | loss 5.294 | ppl 39.22 | wps 516250 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4173 | lr 0.000489526 | gnorm 0.558 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39661
2023-02-11 06:35:27 | INFO | fairseq.trainer | begin training epoch 840
2023-02-11 06:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:36:16 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 5.146 | ppl 35.4 | wps 0 | wpb 11230 | bsz 22 | num_updates 4178 | best_loss 5.137
2023-02-11 06:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 4178 updates
2023-02-11 06:36:16 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint840.pt
2023-02-11 06:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint840.pt
2023-02-11 06:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint840.pt (epoch 840 @ 4178 updates, score 5.146) (writing took 68.85824648899143 seconds)
2023-02-11 06:37:25 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2023-02-11 06:37:25 | INFO | train | epoch 840 | loss 5.285 | ppl 39 | wps 178172 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4178 | lr 0.000489233 | gnorm 0.482 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39779
2023-02-11 06:37:25 | INFO | fairseq.trainer | begin training epoch 841
2023-02-11 06:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:38:08 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2023-02-11 06:38:08 | INFO | train | epoch 841 | loss 5.28 | ppl 38.86 | wps 484436 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4183 | lr 0.000488941 | gnorm 0.437 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39822
2023-02-11 06:38:08 | INFO | fairseq.trainer | begin training epoch 842
2023-02-11 06:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:38:47 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2023-02-11 06:38:47 | INFO | train | epoch 842 | loss 5.277 | ppl 38.77 | wps 532999 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4188 | lr 0.000488649 | gnorm 0.46 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39862
2023-02-11 06:38:48 | INFO | fairseq.trainer | begin training epoch 843
2023-02-11 06:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:39:27 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2023-02-11 06:39:27 | INFO | train | epoch 843 | loss 5.281 | ppl 38.87 | wps 527443 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4193 | lr 0.000488357 | gnorm 0.562 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39901
2023-02-11 06:39:28 | INFO | fairseq.trainer | begin training epoch 844
2023-02-11 06:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:40:08 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2023-02-11 06:40:08 | INFO | train | epoch 844 | loss 5.294 | ppl 39.22 | wps 511920 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4198 | lr 0.000488066 | gnorm 0.738 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39942
2023-02-11 06:40:09 | INFO | fairseq.trainer | begin training epoch 845
2023-02-11 06:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:40:33 | INFO | train_inner | epoch 845:      2 / 5 loss=5.299, ppl=39.36, wps=430020, ups=0.1, wpb=4.20655e+06, bsz=8216, num_updates=4200, lr=0.00048795, gnorm=0.58, loss_scale=1, train_wall=662, gb_free=5.4, wall=39967
2023-02-11 06:40:50 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2023-02-11 06:40:50 | INFO | train | epoch 845 | loss 5.294 | ppl 39.23 | wps 506971 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4203 | lr 0.000487776 | gnorm 0.644 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 39984
2023-02-11 06:40:50 | INFO | fairseq.trainer | begin training epoch 846
2023-02-11 06:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:41:30 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2023-02-11 06:41:30 | INFO | train | epoch 846 | loss 5.29 | ppl 39.12 | wps 526058 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4208 | lr 0.000487486 | gnorm 0.643 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40024
2023-02-11 06:41:30 | INFO | fairseq.trainer | begin training epoch 847
2023-02-11 06:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:42:11 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2023-02-11 06:42:11 | INFO | train | epoch 847 | loss 5.288 | ppl 39.07 | wps 513850 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4213 | lr 0.000487197 | gnorm 0.669 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40065
2023-02-11 06:42:11 | INFO | fairseq.trainer | begin training epoch 848
2023-02-11 06:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:42:53 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2023-02-11 06:42:53 | INFO | train | epoch 848 | loss 5.284 | ppl 38.95 | wps 499404 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4218 | lr 0.000486908 | gnorm 0.545 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40107
2023-02-11 06:42:53 | INFO | fairseq.trainer | begin training epoch 849
2023-02-11 06:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:43:33 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2023-02-11 06:43:33 | INFO | train | epoch 849 | loss 5.277 | ppl 38.77 | wps 526210 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4223 | lr 0.000486619 | gnorm 0.508 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40147
2023-02-11 06:43:33 | INFO | fairseq.trainer | begin training epoch 850
2023-02-11 06:43:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:44:22 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 5.166 | ppl 35.89 | wps 0 | wpb 11230 | bsz 22 | num_updates 4228 | best_loss 5.137
2023-02-11 06:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 4228 updates
2023-02-11 06:44:22 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint850.pt
2023-02-11 06:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint850.pt
2023-02-11 06:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint850.pt (epoch 850 @ 4228 updates, score 5.166) (writing took 67.82255877699936 seconds)
2023-02-11 06:45:30 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2023-02-11 06:45:30 | INFO | train | epoch 850 | loss 5.276 | ppl 38.74 | wps 179697 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4228 | lr 0.000486332 | gnorm 0.559 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40264
2023-02-11 06:45:30 | INFO | fairseq.trainer | begin training epoch 851
2023-02-11 06:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:46:21 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2023-02-11 06:46:21 | INFO | train | epoch 851 | loss 5.275 | ppl 38.73 | wps 412994 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4233 | lr 0.000486044 | gnorm 0.6 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40315
2023-02-11 06:46:21 | INFO | fairseq.trainer | begin training epoch 852
2023-02-11 06:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:46:59 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2023-02-11 06:46:59 | INFO | train | epoch 852 | loss 5.269 | ppl 38.55 | wps 549682 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4238 | lr 0.000485758 | gnorm 0.487 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40353
2023-02-11 06:46:59 | INFO | fairseq.trainer | begin training epoch 853
2023-02-11 06:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:47:39 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2023-02-11 06:47:39 | INFO | train | epoch 853 | loss 5.268 | ppl 38.54 | wps 527463 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4243 | lr 0.000485471 | gnorm 0.522 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40393
2023-02-11 06:47:39 | INFO | fairseq.trainer | begin training epoch 854
2023-02-11 06:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:48:20 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2023-02-11 06:48:20 | INFO | train | epoch 854 | loss 5.267 | ppl 38.51 | wps 511273 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4248 | lr 0.000485185 | gnorm 0.605 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40434
2023-02-11 06:48:20 | INFO | fairseq.trainer | begin training epoch 855
2023-02-11 06:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:49:02 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2023-02-11 06:49:02 | INFO | train | epoch 855 | loss 5.283 | ppl 38.94 | wps 505383 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4253 | lr 0.0004849 | gnorm 0.756 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40476
2023-02-11 06:49:02 | INFO | fairseq.trainer | begin training epoch 856
2023-02-11 06:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:49:42 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2023-02-11 06:49:42 | INFO | train | epoch 856 | loss 5.275 | ppl 38.72 | wps 528356 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4258 | lr 0.000484615 | gnorm 0.559 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40516
2023-02-11 06:49:42 | INFO | fairseq.trainer | begin training epoch 857
2023-02-11 06:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:50:22 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2023-02-11 06:50:22 | INFO | train | epoch 857 | loss 5.274 | ppl 38.7 | wps 516136 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4263 | lr 0.000484331 | gnorm 0.641 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40556
2023-02-11 06:50:23 | INFO | fairseq.trainer | begin training epoch 858
2023-02-11 06:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:51:05 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2023-02-11 06:51:05 | INFO | train | epoch 858 | loss 5.266 | ppl 38.49 | wps 497035 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4268 | lr 0.000484047 | gnorm 0.523 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40599
2023-02-11 06:51:05 | INFO | fairseq.trainer | begin training epoch 859
2023-02-11 06:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:51:45 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2023-02-11 06:51:45 | INFO | train | epoch 859 | loss 5.264 | ppl 38.42 | wps 526652 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4273 | lr 0.000483764 | gnorm 0.572 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40639
2023-02-11 06:51:45 | INFO | fairseq.trainer | begin training epoch 860
2023-02-11 06:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 06:52:34 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 5.148 | ppl 35.47 | wps 0 | wpb 11230 | bsz 22 | num_updates 4278 | best_loss 5.137
2023-02-11 06:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 4278 updates
2023-02-11 06:52:34 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint860.pt
2023-02-11 06:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint860.pt
2023-02-11 06:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint860.pt (epoch 860 @ 4278 updates, score 5.148) (writing took 59.59741936298087 seconds)
2023-02-11 06:53:33 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2023-02-11 06:53:33 | INFO | train | epoch 860 | loss 5.26 | ppl 38.31 | wps 193510 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4278 | lr 0.000483481 | gnorm 0.526 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40747
2023-02-11 06:53:34 | INFO | fairseq.trainer | begin training epoch 861
2023-02-11 06:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:54:26 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2023-02-11 06:54:26 | INFO | train | epoch 861 | loss 5.258 | ppl 38.27 | wps 402704 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4283 | lr 0.000483199 | gnorm 0.529 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40800
2023-02-11 06:54:26 | INFO | fairseq.trainer | begin training epoch 862
2023-02-11 06:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:55:05 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2023-02-11 06:55:05 | INFO | train | epoch 862 | loss 5.255 | ppl 38.18 | wps 530439 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4288 | lr 0.000482917 | gnorm 0.563 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40839
2023-02-11 06:55:05 | INFO | fairseq.trainer | begin training epoch 863
2023-02-11 06:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:55:45 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2023-02-11 06:55:45 | INFO | train | epoch 863 | loss 5.266 | ppl 38.47 | wps 525232 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4293 | lr 0.000482636 | gnorm 0.689 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40879
2023-02-11 06:55:46 | INFO | fairseq.trainer | begin training epoch 864
2023-02-11 06:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:56:27 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2023-02-11 06:56:27 | INFO | train | epoch 864 | loss 5.259 | ppl 38.28 | wps 507812 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4298 | lr 0.000482355 | gnorm 0.586 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40921
2023-02-11 06:56:27 | INFO | fairseq.trainer | begin training epoch 865
2023-02-11 06:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:56:51 | INFO | train_inner | epoch 865:      2 / 5 loss=5.271, ppl=38.62, wps=430212, ups=0.1, wpb=4.20595e+06, bsz=8214.8, num_updates=4300, lr=0.000482243, gnorm=0.585, loss_scale=1, train_wall=662, gb_free=5.4, wall=40945
2023-02-11 06:57:08 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2023-02-11 06:57:08 | INFO | train | epoch 865 | loss 5.259 | ppl 38.28 | wps 513544 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4303 | lr 0.000482075 | gnorm 0.607 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 40962
2023-02-11 06:57:08 | INFO | fairseq.trainer | begin training epoch 866
2023-02-11 06:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:57:48 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2023-02-11 06:57:48 | INFO | train | epoch 866 | loss 5.253 | ppl 38.14 | wps 519574 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4308 | lr 0.000481795 | gnorm 0.532 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41002
2023-02-11 06:57:48 | INFO | fairseq.trainer | begin training epoch 867
2023-02-11 06:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:58:30 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2023-02-11 06:58:30 | INFO | train | epoch 867 | loss 5.248 | ppl 38.01 | wps 506273 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4313 | lr 0.000481515 | gnorm 0.49 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41044
2023-02-11 06:58:30 | INFO | fairseq.trainer | begin training epoch 868
2023-02-11 06:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:59:10 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2023-02-11 06:59:10 | INFO | train | epoch 868 | loss 5.243 | ppl 37.87 | wps 518674 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4318 | lr 0.000481237 | gnorm 0.451 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41084
2023-02-11 06:59:11 | INFO | fairseq.trainer | begin training epoch 869
2023-02-11 06:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 06:59:51 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2023-02-11 06:59:51 | INFO | train | epoch 869 | loss 5.242 | ppl 37.85 | wps 518145 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4323 | lr 0.000480958 | gnorm 0.498 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41125
2023-02-11 06:59:51 | INFO | fairseq.trainer | begin training epoch 870
2023-02-11 06:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:00:39 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 5.162 | ppl 35.81 | wps 0 | wpb 11230 | bsz 22 | num_updates 4328 | best_loss 5.137
2023-02-11 07:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 4328 updates
2023-02-11 07:00:39 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint870.pt
2023-02-11 07:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint870.pt
2023-02-11 07:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint870.pt (epoch 870 @ 4328 updates, score 5.162) (writing took 61.1091326510068 seconds)
2023-02-11 07:01:40 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2023-02-11 07:01:40 | INFO | train | epoch 870 | loss 5.255 | ppl 38.19 | wps 191939 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4328 | lr 0.00048068 | gnorm 0.697 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41234
2023-02-11 07:01:41 | INFO | fairseq.trainer | begin training epoch 871
2023-02-11 07:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:02:35 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2023-02-11 07:02:35 | INFO | train | epoch 871 | loss 5.256 | ppl 38.2 | wps 386831 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4333 | lr 0.000480403 | gnorm 0.665 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41289
2023-02-11 07:02:35 | INFO | fairseq.trainer | begin training epoch 872
2023-02-11 07:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:03:16 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2023-02-11 07:03:16 | INFO | train | epoch 872 | loss 5.257 | ppl 38.24 | wps 513425 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4338 | lr 0.000480126 | gnorm 0.68 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41330
2023-02-11 07:03:16 | INFO | fairseq.trainer | begin training epoch 873
2023-02-11 07:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:03:57 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2023-02-11 07:03:57 | INFO | train | epoch 873 | loss 5.253 | ppl 38.14 | wps 516222 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4343 | lr 0.00047985 | gnorm 0.641 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41371
2023-02-11 07:03:57 | INFO | fairseq.trainer | begin training epoch 874
2023-02-11 07:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:04:38 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2023-02-11 07:04:38 | INFO | train | epoch 874 | loss 5.243 | ppl 37.87 | wps 504578 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4348 | lr 0.000479574 | gnorm 0.501 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41412
2023-02-11 07:04:39 | INFO | fairseq.trainer | begin training epoch 875
2023-02-11 07:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:05:19 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2023-02-11 07:05:19 | INFO | train | epoch 875 | loss 5.235 | ppl 37.67 | wps 515868 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4353 | lr 0.000479298 | gnorm 0.431 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41453
2023-02-11 07:05:19 | INFO | fairseq.trainer | begin training epoch 876
2023-02-11 07:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:05:59 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2023-02-11 07:05:59 | INFO | train | epoch 876 | loss 5.237 | ppl 37.7 | wps 520924 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4358 | lr 0.000479023 | gnorm 0.548 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41493
2023-02-11 07:06:00 | INFO | fairseq.trainer | begin training epoch 877
2023-02-11 07:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:06:41 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2023-02-11 07:06:41 | INFO | train | epoch 877 | loss 5.234 | ppl 37.64 | wps 506608 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4363 | lr 0.000478748 | gnorm 0.521 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41535
2023-02-11 07:06:41 | INFO | fairseq.trainer | begin training epoch 878
2023-02-11 07:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:07:22 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2023-02-11 07:07:22 | INFO | train | epoch 878 | loss 5.234 | ppl 37.62 | wps 513965 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4368 | lr 0.000478474 | gnorm 0.536 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41576
2023-02-11 07:07:22 | INFO | fairseq.trainer | begin training epoch 879
2023-02-11 07:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:08:02 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2023-02-11 07:08:02 | INFO | train | epoch 879 | loss 5.238 | ppl 37.73 | wps 519212 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4373 | lr 0.000478201 | gnorm 0.607 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41616
2023-02-11 07:08:03 | INFO | fairseq.trainer | begin training epoch 880
2023-02-11 07:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:08:51 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 5.118 | ppl 34.74 | wps 0 | wpb 11230 | bsz 22 | num_updates 4378 | best_loss 5.118
2023-02-11 07:08:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 4378 updates
2023-02-11 07:08:51 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint880.pt
2023-02-11 07:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint880.pt
2023-02-11 07:10:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint880.pt (epoch 880 @ 4378 updates, score 5.118) (writing took 77.89797495299717 seconds)
2023-02-11 07:10:09 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2023-02-11 07:10:09 | INFO | train | epoch 880 | loss 5.234 | ppl 37.65 | wps 166233 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4378 | lr 0.000477928 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41743
2023-02-11 07:10:09 | INFO | fairseq.trainer | begin training epoch 881
2023-02-11 07:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:11:23 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2023-02-11 07:11:23 | INFO | train | epoch 881 | loss 5.236 | ppl 37.69 | wps 285388 | ups 0.07 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4383 | lr 0.000477655 | gnorm 0.591 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41817
2023-02-11 07:11:23 | INFO | fairseq.trainer | begin training epoch 882
2023-02-11 07:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:12:03 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2023-02-11 07:12:03 | INFO | train | epoch 882 | loss 5.232 | ppl 37.58 | wps 518612 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4388 | lr 0.000477383 | gnorm 0.546 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41857
2023-02-11 07:12:03 | INFO | fairseq.trainer | begin training epoch 883
2023-02-11 07:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:12:45 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2023-02-11 07:12:45 | INFO | train | epoch 883 | loss 5.234 | ppl 37.64 | wps 501503 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4393 | lr 0.000477111 | gnorm 0.636 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41899
2023-02-11 07:12:45 | INFO | fairseq.trainer | begin training epoch 884
2023-02-11 07:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:13:26 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2023-02-11 07:13:26 | INFO | train | epoch 884 | loss 5.236 | ppl 37.69 | wps 519641 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4398 | lr 0.00047684 | gnorm 0.652 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41940
2023-02-11 07:13:26 | INFO | fairseq.trainer | begin training epoch 885
2023-02-11 07:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:13:49 | INFO | train_inner | epoch 885:      2 / 5 loss=5.242, ppl=37.85, wps=413277, ups=0.1, wpb=4.20776e+06, bsz=8218.4, num_updates=4400, lr=0.000476731, gnorm=0.568, loss_scale=1, train_wall=662, gb_free=5.4, wall=41963
2023-02-11 07:14:06 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2023-02-11 07:14:06 | INFO | train | epoch 885 | loss 5.229 | ppl 37.51 | wps 524067 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4403 | lr 0.000476569 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 41980
2023-02-11 07:14:06 | INFO | fairseq.trainer | begin training epoch 886
2023-02-11 07:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:14:48 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2023-02-11 07:14:48 | INFO | train | epoch 886 | loss 5.229 | ppl 37.49 | wps 503032 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4408 | lr 0.000476298 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42022
2023-02-11 07:14:48 | INFO | fairseq.trainer | begin training epoch 887
2023-02-11 07:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:15:28 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2023-02-11 07:15:28 | INFO | train | epoch 887 | loss 5.222 | ppl 37.33 | wps 513567 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4413 | lr 0.000476029 | gnorm 0.46 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 42063
2023-02-11 07:15:29 | INFO | fairseq.trainer | begin training epoch 888
2023-02-11 07:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:16:08 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2023-02-11 07:16:08 | INFO | train | epoch 888 | loss 5.22 | ppl 37.27 | wps 528031 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4418 | lr 0.000475759 | gnorm 0.5 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 42102
2023-02-11 07:16:09 | INFO | fairseq.trainer | begin training epoch 889
2023-02-11 07:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:16:50 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2023-02-11 07:16:50 | INFO | train | epoch 889 | loss 5.222 | ppl 37.31 | wps 501408 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4423 | lr 0.00047549 | gnorm 0.567 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 42144
2023-02-11 07:16:51 | INFO | fairseq.trainer | begin training epoch 890
2023-02-11 07:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:17:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 07:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:17:38 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 5.143 | ppl 35.33 | wps 0 | wpb 11230 | bsz 22 | num_updates 4427 | best_loss 5.118
2023-02-11 07:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 4427 updates
2023-02-11 07:17:38 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint890.pt
2023-02-11 07:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint890.pt
2023-02-11 07:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint890.pt (epoch 890 @ 4427 updates, score 5.143) (writing took 65.07493966200855 seconds)
2023-02-11 07:18:43 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2023-02-11 07:18:43 | INFO | train | epoch 890 | loss 5.225 | ppl 37.41 | wps 140117 | ups 0.04 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 4427 | lr 0.000475275 | gnorm 0.581 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42257
2023-02-11 07:18:43 | INFO | fairseq.trainer | begin training epoch 891
2023-02-11 07:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:19:28 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2023-02-11 07:19:28 | INFO | train | epoch 891 | loss 5.233 | ppl 37.62 | wps 466315 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4432 | lr 0.000475007 | gnorm 0.713 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42302
2023-02-11 07:19:28 | INFO | fairseq.trainer | begin training epoch 892
2023-02-11 07:19:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:20:09 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2023-02-11 07:20:09 | INFO | train | epoch 892 | loss 5.235 | ppl 37.66 | wps 512102 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4437 | lr 0.000474739 | gnorm 0.729 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42343
2023-02-11 07:20:09 | INFO | fairseq.trainer | begin training epoch 893
2023-02-11 07:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:20:51 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2023-02-11 07:20:51 | INFO | train | epoch 893 | loss 5.231 | ppl 37.57 | wps 497848 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4442 | lr 0.000474472 | gnorm 0.652 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42385
2023-02-11 07:20:52 | INFO | fairseq.trainer | begin training epoch 894
2023-02-11 07:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:21:32 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2023-02-11 07:21:32 | INFO | train | epoch 894 | loss 5.221 | ppl 37.29 | wps 518615 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4447 | lr 0.000474205 | gnorm 0.509 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42426
2023-02-11 07:21:32 | INFO | fairseq.trainer | begin training epoch 895
2023-02-11 07:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:22:13 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2023-02-11 07:22:13 | INFO | train | epoch 895 | loss 5.213 | ppl 37.08 | wps 516751 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4452 | lr 0.000473939 | gnorm 0.451 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42467
2023-02-11 07:22:13 | INFO | fairseq.trainer | begin training epoch 896
2023-02-11 07:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:22:54 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2023-02-11 07:22:54 | INFO | train | epoch 896 | loss 5.21 | ppl 37.02 | wps 508358 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4457 | lr 0.000473673 | gnorm 0.455 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42508
2023-02-11 07:22:54 | INFO | fairseq.trainer | begin training epoch 897
2023-02-11 07:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:23:35 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2023-02-11 07:23:35 | INFO | train | epoch 897 | loss 5.207 | ppl 36.94 | wps 518621 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4462 | lr 0.000473408 | gnorm 0.485 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42549
2023-02-11 07:23:35 | INFO | fairseq.trainer | begin training epoch 898
2023-02-11 07:23:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:24:15 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2023-02-11 07:24:15 | INFO | train | epoch 898 | loss 5.216 | ppl 37.17 | wps 522340 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4467 | lr 0.000473143 | gnorm 0.693 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42589
2023-02-11 07:24:15 | INFO | fairseq.trainer | begin training epoch 899
2023-02-11 07:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:24:57 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2023-02-11 07:24:57 | INFO | train | epoch 899 | loss 5.229 | ppl 37.51 | wps 497224 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4472 | lr 0.000472878 | gnorm 0.778 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42631
2023-02-11 07:24:57 | INFO | fairseq.trainer | begin training epoch 900
2023-02-11 07:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:25:44 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 5.124 | ppl 34.87 | wps 0 | wpb 11230 | bsz 22 | num_updates 4477 | best_loss 5.118
2023-02-11 07:25:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 4477 updates
2023-02-11 07:25:44 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint900.pt
2023-02-11 07:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint900.pt
2023-02-11 07:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint900.pt (epoch 900 @ 4477 updates, score 5.124) (writing took 59.4629338470113 seconds)
2023-02-11 07:26:43 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2023-02-11 07:26:43 | INFO | train | epoch 900 | loss 5.221 | ppl 37.28 | wps 198033 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4477 | lr 0.000472614 | gnorm 0.622 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42737
2023-02-11 07:26:44 | INFO | fairseq.trainer | begin training epoch 901
2023-02-11 07:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:27:28 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2023-02-11 07:27:28 | INFO | train | epoch 901 | loss 5.208 | ppl 36.96 | wps 473420 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4482 | lr 0.00047235 | gnorm 0.454 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42782
2023-02-11 07:27:28 | INFO | fairseq.trainer | begin training epoch 902
2023-02-11 07:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:28:07 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2023-02-11 07:28:07 | INFO | train | epoch 902 | loss 5.204 | ppl 36.86 | wps 537266 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4487 | lr 0.000472087 | gnorm 0.466 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42821
2023-02-11 07:28:07 | INFO | fairseq.trainer | begin training epoch 903
2023-02-11 07:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:28:47 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2023-02-11 07:28:47 | INFO | train | epoch 903 | loss 5.201 | ppl 36.78 | wps 522073 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4492 | lr 0.000471824 | gnorm 0.481 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42861
2023-02-11 07:28:48 | INFO | fairseq.trainer | begin training epoch 904
2023-02-11 07:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:29:27 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2023-02-11 07:29:27 | INFO | train | epoch 904 | loss 5.203 | ppl 36.85 | wps 523152 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4497 | lr 0.000471562 | gnorm 0.577 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42901
2023-02-11 07:29:28 | INFO | fairseq.trainer | begin training epoch 905
2023-02-11 07:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:30:00 | INFO | train_inner | epoch 905:      3 / 5 loss=5.218, ppl=37.23, wps=432860, ups=0.1, wpb=4.20594e+06, bsz=8214.8, num_updates=4500, lr=0.000471405, gnorm=0.568, loss_scale=1, train_wall=669, gb_free=5.4, wall=42934
2023-02-11 07:30:09 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2023-02-11 07:30:09 | INFO | train | epoch 905 | loss 5.207 | ppl 36.94 | wps 504499 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4502 | lr 0.0004713 | gnorm 0.648 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42943
2023-02-11 07:30:09 | INFO | fairseq.trainer | begin training epoch 906
2023-02-11 07:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:30:50 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2023-02-11 07:30:50 | INFO | train | epoch 906 | loss 5.207 | ppl 36.94 | wps 513328 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4507 | lr 0.000471038 | gnorm 0.629 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 42984
2023-02-11 07:30:50 | INFO | fairseq.trainer | begin training epoch 907
2023-02-11 07:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:31:30 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2023-02-11 07:31:30 | INFO | train | epoch 907 | loss 5.203 | ppl 36.83 | wps 522838 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4512 | lr 0.000470777 | gnorm 0.591 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43024
2023-02-11 07:31:31 | INFO | fairseq.trainer | begin training epoch 908
2023-02-11 07:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:32:12 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2023-02-11 07:32:12 | INFO | train | epoch 908 | loss 5.203 | ppl 36.84 | wps 504310 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4517 | lr 0.000470517 | gnorm 0.581 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43066
2023-02-11 07:32:12 | INFO | fairseq.trainer | begin training epoch 909
2023-02-11 07:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:32:53 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2023-02-11 07:32:53 | INFO | train | epoch 909 | loss 5.197 | ppl 36.69 | wps 514878 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4522 | lr 0.000470256 | gnorm 0.523 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43107
2023-02-11 07:32:53 | INFO | fairseq.trainer | begin training epoch 910
2023-02-11 07:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:33:41 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 5.155 | ppl 35.63 | wps 0 | wpb 11230 | bsz 22 | num_updates 4527 | best_loss 5.118
2023-02-11 07:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 4527 updates
2023-02-11 07:33:41 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint910.pt
2023-02-11 07:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint910.pt
2023-02-11 07:34:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint910.pt (epoch 910 @ 4527 updates, score 5.155) (writing took 70.22214414700284 seconds)
2023-02-11 07:34:52 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2023-02-11 07:34:52 | INFO | train | epoch 910 | loss 5.194 | ppl 36.62 | wps 177303 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4527 | lr 0.000469997 | gnorm 0.532 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43226
2023-02-11 07:34:52 | INFO | fairseq.trainer | begin training epoch 911
2023-02-11 07:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:35:36 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2023-02-11 07:35:36 | INFO | train | epoch 911 | loss 5.19 | ppl 36.5 | wps 477049 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4532 | lr 0.000469737 | gnorm 0.454 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43270
2023-02-11 07:35:36 | INFO | fairseq.trainer | begin training epoch 912
2023-02-11 07:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:36:17 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2023-02-11 07:36:17 | INFO | train | epoch 912 | loss 5.191 | ppl 36.52 | wps 504000 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4537 | lr 0.000469478 | gnorm 0.562 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43311
2023-02-11 07:36:18 | INFO | fairseq.trainer | begin training epoch 913
2023-02-11 07:36:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:36:59 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2023-02-11 07:36:59 | INFO | train | epoch 913 | loss 5.193 | ppl 36.57 | wps 511149 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4542 | lr 0.00046922 | gnorm 0.573 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43353
2023-02-11 07:36:59 | INFO | fairseq.trainer | begin training epoch 914
2023-02-11 07:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:37:39 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2023-02-11 07:37:39 | INFO | train | epoch 914 | loss 5.198 | ppl 36.71 | wps 519846 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4547 | lr 0.000468962 | gnorm 0.649 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43393
2023-02-11 07:37:39 | INFO | fairseq.trainer | begin training epoch 915
2023-02-11 07:37:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:38:21 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2023-02-11 07:38:21 | INFO | train | epoch 915 | loss 5.192 | ppl 36.56 | wps 503886 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4552 | lr 0.000468704 | gnorm 0.575 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43435
2023-02-11 07:38:21 | INFO | fairseq.trainer | begin training epoch 916
2023-02-11 07:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:39:01 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2023-02-11 07:39:01 | INFO | train | epoch 916 | loss 5.195 | ppl 36.63 | wps 523996 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4557 | lr 0.000468447 | gnorm 0.634 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43475
2023-02-11 07:39:01 | INFO | fairseq.trainer | begin training epoch 917
2023-02-11 07:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:39:42 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2023-02-11 07:39:42 | INFO | train | epoch 917 | loss 5.194 | ppl 36.61 | wps 511039 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4562 | lr 0.00046819 | gnorm 0.642 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43516
2023-02-11 07:39:42 | INFO | fairseq.trainer | begin training epoch 918
2023-02-11 07:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:40:24 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2023-02-11 07:40:24 | INFO | train | epoch 918 | loss 5.188 | ppl 36.47 | wps 505077 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4567 | lr 0.000467934 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43558
2023-02-11 07:40:24 | INFO | fairseq.trainer | begin training epoch 919
2023-02-11 07:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:41:04 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2023-02-11 07:41:04 | INFO | train | epoch 919 | loss 5.183 | ppl 36.32 | wps 519492 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4572 | lr 0.000467678 | gnorm 0.486 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43598
2023-02-11 07:41:05 | INFO | fairseq.trainer | begin training epoch 920
2023-02-11 07:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:41:53 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 5.14 | ppl 35.26 | wps 0 | wpb 11230 | bsz 22 | num_updates 4577 | best_loss 5.118
2023-02-11 07:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 4577 updates
2023-02-11 07:41:53 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint920.pt
2023-02-11 07:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint920.pt
2023-02-11 07:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint920.pt (epoch 920 @ 4577 updates, score 5.14) (writing took 67.62963620299706 seconds)
2023-02-11 07:43:01 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2023-02-11 07:43:01 | INFO | train | epoch 920 | loss 5.181 | ppl 36.28 | wps 180807 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4577 | lr 0.000467422 | gnorm 0.504 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43715
2023-02-11 07:43:01 | INFO | fairseq.trainer | begin training epoch 921
2023-02-11 07:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:43:44 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2023-02-11 07:43:44 | INFO | train | epoch 921 | loss 5.181 | ppl 36.27 | wps 478243 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4582 | lr 0.000467167 | gnorm 0.528 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43759
2023-02-11 07:43:45 | INFO | fairseq.trainer | begin training epoch 922
2023-02-11 07:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:44:25 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2023-02-11 07:44:25 | INFO | train | epoch 922 | loss 5.18 | ppl 36.24 | wps 523455 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4587 | lr 0.000466913 | gnorm 0.529 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43799
2023-02-11 07:44:25 | INFO | fairseq.trainer | begin training epoch 923
2023-02-11 07:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:45:05 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2023-02-11 07:45:05 | INFO | train | epoch 923 | loss 5.177 | ppl 36.18 | wps 515765 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4592 | lr 0.000466658 | gnorm 0.534 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43840
2023-02-11 07:45:06 | INFO | fairseq.trainer | begin training epoch 924
2023-02-11 07:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:45:46 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2023-02-11 07:45:46 | INFO | train | epoch 924 | loss 5.184 | ppl 36.35 | wps 521158 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4597 | lr 0.000466405 | gnorm 0.688 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43880
2023-02-11 07:45:46 | INFO | fairseq.trainer | begin training epoch 925
2023-02-11 07:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:46:18 | INFO | train_inner | epoch 925:      3 / 5 loss=5.192, ppl=36.54, wps=430052, ups=0.1, wpb=4.20655e+06, bsz=8216, num_updates=4600, lr=0.000466252, gnorm=0.575, loss_scale=1, train_wall=662, gb_free=5.4, wall=43913
2023-02-11 07:46:27 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2023-02-11 07:46:27 | INFO | train | epoch 925 | loss 5.196 | ppl 36.66 | wps 506965 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4602 | lr 0.000466151 | gnorm 0.771 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43921
2023-02-11 07:46:28 | INFO | fairseq.trainer | begin training epoch 926
2023-02-11 07:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:47:08 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2023-02-11 07:47:08 | INFO | train | epoch 926 | loss 5.184 | ppl 36.36 | wps 515297 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4607 | lr 0.000465898 | gnorm 0.55 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 43962
2023-02-11 07:47:08 | INFO | fairseq.trainer | begin training epoch 927
2023-02-11 07:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:47:48 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2023-02-11 07:47:48 | INFO | train | epoch 927 | loss 5.179 | ppl 36.23 | wps 524479 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4612 | lr 0.000465645 | gnorm 0.512 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44002
2023-02-11 07:47:49 | INFO | fairseq.trainer | begin training epoch 928
2023-02-11 07:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:48:30 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2023-02-11 07:48:30 | INFO | train | epoch 928 | loss 5.173 | ppl 36.07 | wps 499810 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4617 | lr 0.000465393 | gnorm 0.445 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44044
2023-02-11 07:48:31 | INFO | fairseq.trainer | begin training epoch 929
2023-02-11 07:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:49:11 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2023-02-11 07:49:11 | INFO | train | epoch 929 | loss 5.171 | ppl 36.03 | wps 519159 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4622 | lr 0.000465141 | gnorm 0.493 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44085
2023-02-11 07:49:11 | INFO | fairseq.trainer | begin training epoch 930
2023-02-11 07:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:49:59 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 5.158 | ppl 35.7 | wps 0 | wpb 11230 | bsz 22 | num_updates 4627 | best_loss 5.118
2023-02-11 07:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 4627 updates
2023-02-11 07:49:59 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint930.pt
2023-02-11 07:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint930.pt
2023-02-11 07:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint930.pt (epoch 930 @ 4627 updates, score 5.158) (writing took 66.5157856119913 seconds)
2023-02-11 07:51:06 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2023-02-11 07:51:06 | INFO | train | epoch 930 | loss 5.171 | ppl 36.04 | wps 182891 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4627 | lr 0.00046489 | gnorm 0.564 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44200
2023-02-11 07:51:06 | INFO | fairseq.trainer | begin training epoch 931
2023-02-11 07:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:51:52 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2023-02-11 07:51:52 | INFO | train | epoch 931 | loss 5.172 | ppl 36.05 | wps 451438 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4632 | lr 0.000464639 | gnorm 0.588 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44246
2023-02-11 07:51:53 | INFO | fairseq.trainer | begin training epoch 932
2023-02-11 07:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:52:32 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2023-02-11 07:52:32 | INFO | train | epoch 932 | loss 5.174 | ppl 36.09 | wps 535898 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4637 | lr 0.000464388 | gnorm 0.603 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44286
2023-02-11 07:52:32 | INFO | fairseq.trainer | begin training epoch 933
2023-02-11 07:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:53:12 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2023-02-11 07:53:12 | INFO | train | epoch 933 | loss 5.17 | ppl 36.01 | wps 526052 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4642 | lr 0.000464138 | gnorm 0.562 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44326
2023-02-11 07:53:12 | INFO | fairseq.trainer | begin training epoch 934
2023-02-11 07:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:53:52 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2023-02-11 07:53:52 | INFO | train | epoch 934 | loss 5.172 | ppl 36.05 | wps 518086 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4647 | lr 0.000463889 | gnorm 0.622 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44366
2023-02-11 07:53:53 | INFO | fairseq.trainer | begin training epoch 935
2023-02-11 07:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:54:34 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2023-02-11 07:54:34 | INFO | train | epoch 935 | loss 5.167 | ppl 35.92 | wps 503995 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4652 | lr 0.000463639 | gnorm 0.52 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44408
2023-02-11 07:54:34 | INFO | fairseq.trainer | begin training epoch 936
2023-02-11 07:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:55:14 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2023-02-11 07:55:14 | INFO | train | epoch 936 | loss 5.176 | ppl 36.15 | wps 522499 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4657 | lr 0.00046339 | gnorm 0.728 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44448
2023-02-11 07:55:15 | INFO | fairseq.trainer | begin training epoch 937
2023-02-11 07:55:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:55:55 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2023-02-11 07:55:55 | INFO | train | epoch 937 | loss 5.168 | ppl 35.95 | wps 510451 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4662 | lr 0.000463142 | gnorm 0.559 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44490
2023-02-11 07:55:56 | INFO | fairseq.trainer | begin training epoch 938
2023-02-11 07:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:56:37 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2023-02-11 07:56:37 | INFO | train | epoch 938 | loss 5.162 | ppl 35.81 | wps 507575 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4667 | lr 0.000462894 | gnorm 0.487 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44531
2023-02-11 07:56:37 | INFO | fairseq.trainer | begin training epoch 939
2023-02-11 07:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:57:17 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2023-02-11 07:57:17 | INFO | train | epoch 939 | loss 5.161 | ppl 35.77 | wps 525933 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4672 | lr 0.000462646 | gnorm 0.513 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44571
2023-02-11 07:57:17 | INFO | fairseq.trainer | begin training epoch 940
2023-02-11 07:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 07:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 07:58:06 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 5.142 | ppl 35.32 | wps 0 | wpb 11230 | bsz 22 | num_updates 4677 | best_loss 5.118
2023-02-11 07:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 4677 updates
2023-02-11 07:58:06 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint940.pt
2023-02-11 07:58:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint940.pt
2023-02-11 07:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint940.pt (epoch 940 @ 4677 updates, score 5.142) (writing took 71.08011053499649 seconds)
2023-02-11 07:59:17 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2023-02-11 07:59:17 | INFO | train | epoch 940 | loss 5.176 | ppl 36.15 | wps 174938 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4677 | lr 0.000462398 | gnorm 0.78 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44691
2023-02-11 07:59:17 | INFO | fairseq.trainer | begin training epoch 941
2023-02-11 07:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:00:04 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2023-02-11 08:00:04 | INFO | train | epoch 941 | loss 5.168 | ppl 35.96 | wps 452370 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4682 | lr 0.000462151 | gnorm 0.596 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 44738
2023-02-11 08:00:04 | INFO | fairseq.trainer | begin training epoch 942
2023-02-11 08:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:00:43 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2023-02-11 08:00:43 | INFO | train | epoch 942 | loss 5.159 | ppl 35.73 | wps 531100 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4687 | lr 0.000461905 | gnorm 0.455 | loss_scale 2 | train_wall 33 | gb_free 5.6 | wall 44777
2023-02-11 08:00:44 | INFO | fairseq.trainer | begin training epoch 943
2023-02-11 08:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:01:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 08:01:23 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2023-02-11 08:01:23 | INFO | train | epoch 943 | loss 5.154 | ppl 35.61 | wps 397735 | ups 0.1 | wpb 3.95284e+06 | bsz 7720.5 | num_updates 4691 | lr 0.000461708 | gnorm 0.452 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44817
2023-02-11 08:01:23 | INFO | fairseq.trainer | begin training epoch 944
2023-02-11 08:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:02:04 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2023-02-11 08:02:04 | INFO | train | epoch 944 | loss 5.153 | ppl 35.58 | wps 510119 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4696 | lr 0.000461462 | gnorm 0.44 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44858
2023-02-11 08:02:05 | INFO | fairseq.trainer | begin training epoch 945
2023-02-11 08:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:02:45 | INFO | train_inner | epoch 945:      4 / 5 loss=5.169, ppl=35.98, wps=426644, ups=0.1, wpb=4.20696e+06, bsz=8216.8, num_updates=4700, lr=0.000461266, gnorm=0.558, loss_scale=1, train_wall=670, gb_free=5.4, wall=44899
2023-02-11 08:02:45 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2023-02-11 08:02:45 | INFO | train | epoch 945 | loss 5.161 | ppl 35.77 | wps 514916 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4701 | lr 0.000461217 | gnorm 0.63 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44899
2023-02-11 08:02:45 | INFO | fairseq.trainer | begin training epoch 946
2023-02-11 08:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:03:25 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2023-02-11 08:03:25 | INFO | train | epoch 946 | loss 5.159 | ppl 35.73 | wps 520706 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4706 | lr 0.000460971 | gnorm 0.601 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44940
2023-02-11 08:03:26 | INFO | fairseq.trainer | begin training epoch 947
2023-02-11 08:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:04:06 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2023-02-11 08:04:06 | INFO | train | epoch 947 | loss 5.158 | ppl 35.71 | wps 516495 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4711 | lr 0.000460727 | gnorm 0.63 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 44980
2023-02-11 08:04:07 | INFO | fairseq.trainer | begin training epoch 948
2023-02-11 08:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:04:48 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2023-02-11 08:04:48 | INFO | train | epoch 948 | loss 5.158 | ppl 35.71 | wps 501785 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4716 | lr 0.000460482 | gnorm 0.614 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45022
2023-02-11 08:04:48 | INFO | fairseq.trainer | begin training epoch 949
2023-02-11 08:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:05:28 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2023-02-11 08:05:28 | INFO | train | epoch 949 | loss 5.158 | ppl 35.71 | wps 522777 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4721 | lr 0.000460239 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45062
2023-02-11 08:05:29 | INFO | fairseq.trainer | begin training epoch 950
2023-02-11 08:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:06:17 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 5.134 | ppl 35.11 | wps 0 | wpb 11230 | bsz 22 | num_updates 4726 | best_loss 5.118
2023-02-11 08:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 4726 updates
2023-02-11 08:06:17 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint950.pt
2023-02-11 08:06:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint950.pt
2023-02-11 08:07:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint950.pt (epoch 950 @ 4726 updates, score 5.134) (writing took 58.02319070199155 seconds)
2023-02-11 08:07:15 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2023-02-11 08:07:15 | INFO | train | epoch 950 | loss 5.149 | ppl 35.47 | wps 196367 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4726 | lr 0.000459995 | gnorm 0.474 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45170
2023-02-11 08:07:16 | INFO | fairseq.trainer | begin training epoch 951
2023-02-11 08:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:08:07 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2023-02-11 08:08:07 | INFO | train | epoch 951 | loss 5.144 | ppl 35.35 | wps 406386 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4731 | lr 0.000459752 | gnorm 0.453 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45221
2023-02-11 08:08:08 | INFO | fairseq.trainer | begin training epoch 952
2023-02-11 08:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:08:48 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2023-02-11 08:08:48 | INFO | train | epoch 952 | loss 5.143 | ppl 35.32 | wps 512978 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4736 | lr 0.000459509 | gnorm 0.462 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45262
2023-02-11 08:08:49 | INFO | fairseq.trainer | begin training epoch 953
2023-02-11 08:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:09:29 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2023-02-11 08:09:29 | INFO | train | epoch 953 | loss 5.151 | ppl 35.53 | wps 517651 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4741 | lr 0.000459267 | gnorm 0.677 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 45303
2023-02-11 08:09:29 | INFO | fairseq.trainer | begin training epoch 954
2023-02-11 08:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:09:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 08:10:11 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2023-02-11 08:10:11 | INFO | train | epoch 954 | loss 5.16 | ppl 35.76 | wps 379018 | ups 0.1 | wpb 3.94778e+06 | bsz 7710.5 | num_updates 4745 | lr 0.000459073 | gnorm 0.793 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45345
2023-02-11 08:10:11 | INFO | fairseq.trainer | begin training epoch 955
2023-02-11 08:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:10:51 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2023-02-11 08:10:51 | INFO | train | epoch 955 | loss 5.166 | ppl 35.89 | wps 515864 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4750 | lr 0.000458831 | gnorm 0.775 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45385
2023-02-11 08:10:52 | INFO | fairseq.trainer | begin training epoch 956
2023-02-11 08:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:11:32 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2023-02-11 08:11:32 | INFO | train | epoch 956 | loss 5.157 | ppl 35.68 | wps 517726 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4755 | lr 0.00045859 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45426
2023-02-11 08:11:32 | INFO | fairseq.trainer | begin training epoch 957
2023-02-11 08:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:12:13 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2023-02-11 08:12:13 | INFO | train | epoch 957 | loss 5.146 | ppl 35.41 | wps 510806 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4760 | lr 0.000458349 | gnorm 0.441 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45467
2023-02-11 08:12:13 | INFO | fairseq.trainer | begin training epoch 958
2023-02-11 08:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:12:54 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2023-02-11 08:12:54 | INFO | train | epoch 958 | loss 5.142 | ppl 35.32 | wps 513867 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4765 | lr 0.000458109 | gnorm 0.484 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45508
2023-02-11 08:12:54 | INFO | fairseq.trainer | begin training epoch 959
2023-02-11 08:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:13:35 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2023-02-11 08:13:35 | INFO | train | epoch 959 | loss 5.147 | ppl 35.43 | wps 514836 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4770 | lr 0.000457869 | gnorm 0.567 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45549
2023-02-11 08:13:35 | INFO | fairseq.trainer | begin training epoch 960
2023-02-11 08:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:14:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:14:24 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 5.151 | ppl 35.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 4775 | best_loss 5.118
2023-02-11 08:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 4775 updates
2023-02-11 08:14:24 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint960.pt
2023-02-11 08:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint960.pt
2023-02-11 08:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint960.pt (epoch 960 @ 4775 updates, score 5.151) (writing took 54.02950496098492 seconds)
2023-02-11 08:15:18 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2023-02-11 08:15:18 | INFO | train | epoch 960 | loss 5.14 | ppl 35.26 | wps 203846 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4775 | lr 0.000457629 | gnorm 0.532 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45652
2023-02-11 08:15:18 | INFO | fairseq.trainer | begin training epoch 961
2023-02-11 08:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:16:29 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2023-02-11 08:16:29 | INFO | train | epoch 961 | loss 5.14 | ppl 35.27 | wps 298275 | ups 0.07 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4780 | lr 0.000457389 | gnorm 0.577 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45723
2023-02-11 08:16:29 | INFO | fairseq.trainer | begin training epoch 962
2023-02-11 08:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:17:11 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2023-02-11 08:17:11 | INFO | train | epoch 962 | loss 5.139 | ppl 35.23 | wps 500507 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4785 | lr 0.00045715 | gnorm 0.538 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45765
2023-02-11 08:17:11 | INFO | fairseq.trainer | begin training epoch 963
2023-02-11 08:17:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:17:51 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2023-02-11 08:17:51 | INFO | train | epoch 963 | loss 5.141 | ppl 35.28 | wps 520099 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4790 | lr 0.000456912 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45805
2023-02-11 08:17:51 | INFO | fairseq.trainer | begin training epoch 964
2023-02-11 08:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:18:32 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2023-02-11 08:18:32 | INFO | train | epoch 964 | loss 5.139 | ppl 35.25 | wps 516334 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4795 | lr 0.000456673 | gnorm 0.611 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45846
2023-02-11 08:18:32 | INFO | fairseq.trainer | begin training epoch 965
2023-02-11 08:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:19:14 | INFO | train_inner | epoch 965:      5 / 5 loss=5.148, ppl=35.47, wps=420125, ups=0.1, wpb=4.15596e+06, bsz=8117.2, num_updates=4800, lr=0.000456435, gnorm=0.575, loss_scale=0.5, train_wall=662, gb_free=5.6, wall=45888
2023-02-11 08:19:14 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2023-02-11 08:19:14 | INFO | train | epoch 965 | loss 5.132 | ppl 35.07 | wps 501637 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4800 | lr 0.000456435 | gnorm 0.501 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45888
2023-02-11 08:19:14 | INFO | fairseq.trainer | begin training epoch 966
2023-02-11 08:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:19:54 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2023-02-11 08:19:54 | INFO | train | epoch 966 | loss 5.139 | ppl 35.23 | wps 523606 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4805 | lr 0.000456198 | gnorm 0.655 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45928
2023-02-11 08:19:54 | INFO | fairseq.trainer | begin training epoch 967
2023-02-11 08:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:20:34 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2023-02-11 08:20:34 | INFO | train | epoch 967 | loss 5.133 | ppl 35.1 | wps 524269 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4810 | lr 0.000455961 | gnorm 0.53 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 45968
2023-02-11 08:20:34 | INFO | fairseq.trainer | begin training epoch 968
2023-02-11 08:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:21:17 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2023-02-11 08:21:17 | INFO | train | epoch 968 | loss 5.13 | ppl 35.01 | wps 492459 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4815 | lr 0.000455724 | gnorm 0.533 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46011
2023-02-11 08:21:17 | INFO | fairseq.trainer | begin training epoch 969
2023-02-11 08:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:21:57 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2023-02-11 08:21:57 | INFO | train | epoch 969 | loss 5.13 | ppl 35.02 | wps 518677 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4820 | lr 0.000455488 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46051
2023-02-11 08:21:58 | INFO | fairseq.trainer | begin training epoch 970
2023-02-11 08:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:22:45 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 5.144 | ppl 35.36 | wps 0 | wpb 11230 | bsz 22 | num_updates 4825 | best_loss 5.118
2023-02-11 08:22:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 4825 updates
2023-02-11 08:22:45 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint970.pt
2023-02-11 08:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint970.pt
2023-02-11 08:23:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint970.pt (epoch 970 @ 4825 updates, score 5.144) (writing took 65.96517084600055 seconds)
2023-02-11 08:23:51 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2023-02-11 08:23:51 | INFO | train | epoch 970 | loss 5.126 | ppl 34.91 | wps 184452 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4825 | lr 0.000455251 | gnorm 0.509 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46165
2023-02-11 08:23:52 | INFO | fairseq.trainer | begin training epoch 971
2023-02-11 08:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:24:35 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2023-02-11 08:24:35 | INFO | train | epoch 971 | loss 5.135 | ppl 35.13 | wps 478382 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4830 | lr 0.000455016 | gnorm 0.696 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46209
2023-02-11 08:24:36 | INFO | fairseq.trainer | begin training epoch 972
2023-02-11 08:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:25:17 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2023-02-11 08:25:17 | INFO | train | epoch 972 | loss 5.143 | ppl 35.34 | wps 500636 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4835 | lr 0.00045478 | gnorm 0.771 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46251
2023-02-11 08:25:18 | INFO | fairseq.trainer | begin training epoch 973
2023-02-11 08:25:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:25:58 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2023-02-11 08:25:58 | INFO | train | epoch 973 | loss 5.138 | ppl 35.21 | wps 523829 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4840 | lr 0.000454545 | gnorm 0.66 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46292
2023-02-11 08:25:58 | INFO | fairseq.trainer | begin training epoch 974
2023-02-11 08:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:26:39 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2023-02-11 08:26:39 | INFO | train | epoch 974 | loss 5.129 | ppl 34.99 | wps 512937 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4845 | lr 0.000454311 | gnorm 0.518 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46333
2023-02-11 08:26:39 | INFO | fairseq.trainer | begin training epoch 975
2023-02-11 08:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:27:20 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2023-02-11 08:27:20 | INFO | train | epoch 975 | loss 5.134 | ppl 35.11 | wps 503175 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4850 | lr 0.000454077 | gnorm 0.648 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46374
2023-02-11 08:27:21 | INFO | fairseq.trainer | begin training epoch 976
2023-02-11 08:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:28:00 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2023-02-11 08:28:00 | INFO | train | epoch 976 | loss 5.126 | ppl 34.93 | wps 525241 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4855 | lr 0.000453843 | gnorm 0.548 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46414
2023-02-11 08:28:01 | INFO | fairseq.trainer | begin training epoch 977
2023-02-11 08:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:28:41 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2023-02-11 08:28:41 | INFO | train | epoch 977 | loss 5.119 | ppl 34.74 | wps 517310 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4860 | lr 0.000453609 | gnorm 0.454 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46455
2023-02-11 08:28:41 | INFO | fairseq.trainer | begin training epoch 978
2023-02-11 08:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:29:23 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2023-02-11 08:29:23 | INFO | train | epoch 978 | loss 5.115 | ppl 34.66 | wps 502233 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4865 | lr 0.000453376 | gnorm 0.458 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46497
2023-02-11 08:29:23 | INFO | fairseq.trainer | begin training epoch 979
2023-02-11 08:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:30:03 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2023-02-11 08:30:03 | INFO | train | epoch 979 | loss 5.119 | ppl 34.74 | wps 522983 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4870 | lr 0.000453143 | gnorm 0.572 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46537
2023-02-11 08:30:03 | INFO | fairseq.trainer | begin training epoch 980
2023-02-11 08:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:30:52 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 5.13 | ppl 35.02 | wps 0 | wpb 11230 | bsz 22 | num_updates 4875 | best_loss 5.118
2023-02-11 08:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 4875 updates
2023-02-11 08:30:52 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint980.pt
2023-02-11 08:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint980.pt
2023-02-11 08:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint980.pt (epoch 980 @ 4875 updates, score 5.13) (writing took 62.69743969599949 seconds)
2023-02-11 08:31:55 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2023-02-11 08:31:55 | INFO | train | epoch 980 | loss 5.116 | ppl 34.69 | wps 188065 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4875 | lr 0.000452911 | gnorm 0.551 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46649
2023-02-11 08:31:55 | INFO | fairseq.trainer | begin training epoch 981
2023-02-11 08:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:32:48 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2023-02-11 08:32:48 | INFO | train | epoch 981 | loss 5.114 | ppl 34.62 | wps 398705 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4880 | lr 0.000452679 | gnorm 0.5 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46702
2023-02-11 08:32:48 | INFO | fairseq.trainer | begin training epoch 982
2023-02-11 08:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:33:29 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2023-02-11 08:33:29 | INFO | train | epoch 982 | loss 5.111 | ppl 34.57 | wps 509195 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4885 | lr 0.000452447 | gnorm 0.505 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46743
2023-02-11 08:33:29 | INFO | fairseq.trainer | begin training epoch 983
2023-02-11 08:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:34:09 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2023-02-11 08:34:09 | INFO | train | epoch 983 | loss 5.117 | ppl 34.71 | wps 523595 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4890 | lr 0.000452216 | gnorm 0.658 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46783
2023-02-11 08:34:10 | INFO | fairseq.trainer | begin training epoch 984
2023-02-11 08:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:34:50 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2023-02-11 08:34:50 | INFO | train | epoch 984 | loss 5.122 | ppl 34.81 | wps 517190 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4895 | lr 0.000451985 | gnorm 0.654 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46824
2023-02-11 08:34:50 | INFO | fairseq.trainer | begin training epoch 985
2023-02-11 08:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:35:32 | INFO | train_inner | epoch 985:      5 / 5 loss=5.126, ppl=34.91, wps=430197, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=4900, lr=0.000451754, gnorm=0.577, loss_scale=0.5, train_wall=661, gb_free=5.6, wall=46866
2023-02-11 08:35:32 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2023-02-11 08:35:32 | INFO | train | epoch 985 | loss 5.117 | ppl 34.7 | wps 503782 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4900 | lr 0.000451754 | gnorm 0.578 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46866
2023-02-11 08:35:32 | INFO | fairseq.trainer | begin training epoch 986
2023-02-11 08:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:36:12 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2023-02-11 08:36:12 | INFO | train | epoch 986 | loss 5.114 | ppl 34.63 | wps 522405 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4905 | lr 0.000451524 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46906
2023-02-11 08:36:12 | INFO | fairseq.trainer | begin training epoch 987
2023-02-11 08:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:36:53 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2023-02-11 08:36:53 | INFO | train | epoch 987 | loss 5.114 | ppl 34.63 | wps 509131 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4910 | lr 0.000451294 | gnorm 0.609 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46947
2023-02-11 08:36:54 | INFO | fairseq.trainer | begin training epoch 988
2023-02-11 08:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:37:35 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2023-02-11 08:37:35 | INFO | train | epoch 988 | loss 5.112 | ppl 34.59 | wps 505592 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4915 | lr 0.000451064 | gnorm 0.589 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 46989
2023-02-11 08:37:35 | INFO | fairseq.trainer | begin training epoch 989
2023-02-11 08:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:38:15 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2023-02-11 08:38:15 | INFO | train | epoch 989 | loss 5.109 | ppl 34.52 | wps 527063 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4920 | lr 0.000450835 | gnorm 0.589 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47029
2023-02-11 08:38:15 | INFO | fairseq.trainer | begin training epoch 990
2023-02-11 08:38:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:39:04 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 5.141 | ppl 35.29 | wps 0 | wpb 11230 | bsz 22 | num_updates 4925 | best_loss 5.118
2023-02-11 08:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 4925 updates
2023-02-11 08:39:04 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint990.pt
2023-02-11 08:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint990.pt
2023-02-11 08:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint990.pt (epoch 990 @ 4925 updates, score 5.141) (writing took 74.91181786102243 seconds)
2023-02-11 08:40:19 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2023-02-11 08:40:19 | INFO | train | epoch 990 | loss 5.109 | ppl 34.52 | wps 169252 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4925 | lr 0.000450606 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47153
2023-02-11 08:40:19 | INFO | fairseq.trainer | begin training epoch 991
2023-02-11 08:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:41:04 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2023-02-11 08:41:04 | INFO | train | epoch 991 | loss 5.104 | ppl 34.4 | wps 468853 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4930 | lr 0.000450377 | gnorm 0.505 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47198
2023-02-11 08:41:04 | INFO | fairseq.trainer | begin training epoch 992
2023-02-11 08:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:41:45 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2023-02-11 08:41:45 | INFO | train | epoch 992 | loss 5.102 | ppl 34.33 | wps 506875 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4935 | lr 0.000450149 | gnorm 0.49 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47239
2023-02-11 08:41:46 | INFO | fairseq.trainer | begin training epoch 993
2023-02-11 08:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:42:26 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2023-02-11 08:42:26 | INFO | train | epoch 993 | loss 5.104 | ppl 34.39 | wps 517461 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4940 | lr 0.000449921 | gnorm 0.567 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47280
2023-02-11 08:42:26 | INFO | fairseq.trainer | begin training epoch 994
2023-02-11 08:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:43:07 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2023-02-11 08:43:07 | INFO | train | epoch 994 | loss 5.103 | ppl 34.38 | wps 515438 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4945 | lr 0.000449694 | gnorm 0.583 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47321
2023-02-11 08:43:07 | INFO | fairseq.trainer | begin training epoch 995
2023-02-11 08:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:43:48 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2023-02-11 08:43:48 | INFO | train | epoch 995 | loss 5.099 | ppl 34.27 | wps 505814 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4950 | lr 0.000449467 | gnorm 0.468 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47362
2023-02-11 08:43:49 | INFO | fairseq.trainer | begin training epoch 996
2023-02-11 08:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:44:29 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2023-02-11 08:44:29 | INFO | train | epoch 996 | loss 5.101 | ppl 34.31 | wps 520135 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4955 | lr 0.00044924 | gnorm 0.556 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47403
2023-02-11 08:44:29 | INFO | fairseq.trainer | begin training epoch 997
2023-02-11 08:44:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:45:09 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2023-02-11 08:45:09 | INFO | train | epoch 997 | loss 5.1 | ppl 34.3 | wps 522380 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4960 | lr 0.000449013 | gnorm 0.589 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47443
2023-02-11 08:45:09 | INFO | fairseq.trainer | begin training epoch 998
2023-02-11 08:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:45:51 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2023-02-11 08:45:51 | INFO | train | epoch 998 | loss 5.104 | ppl 34.38 | wps 498527 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4965 | lr 0.000448787 | gnorm 0.617 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47485
2023-02-11 08:45:52 | INFO | fairseq.trainer | begin training epoch 999
2023-02-11 08:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:46:31 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2023-02-11 08:46:31 | INFO | train | epoch 999 | loss 5.099 | ppl 34.27 | wps 525717 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4970 | lr 0.000448561 | gnorm 0.582 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47525
2023-02-11 08:46:32 | INFO | fairseq.trainer | begin training epoch 1000
2023-02-11 08:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:47:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:47:20 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 5.161 | ppl 35.77 | wps 0 | wpb 11230 | bsz 22 | num_updates 4975 | best_loss 5.118
2023-02-11 08:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 4975 updates
2023-02-11 08:47:20 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1000.pt
2023-02-11 08:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1000.pt
2023-02-11 08:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1000.pt (epoch 1000 @ 4975 updates, score 5.161) (writing took 59.838822184014134 seconds)
2023-02-11 08:48:20 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2023-02-11 08:48:20 | INFO | train | epoch 1000 | loss 5.112 | ppl 34.59 | wps 193422 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4975 | lr 0.000448336 | gnorm 0.781 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47634
2023-02-11 08:48:20 | INFO | fairseq.trainer | begin training epoch 1001
2023-02-11 08:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:49:13 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2023-02-11 08:49:13 | INFO | train | epoch 1001 | loss 5.11 | ppl 34.54 | wps 395636 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4980 | lr 0.000448111 | gnorm 0.683 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47687
2023-02-11 08:49:14 | INFO | fairseq.trainer | begin training epoch 1002
2023-02-11 08:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:49:53 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2023-02-11 08:49:53 | INFO | train | epoch 1002 | loss 5.099 | ppl 34.28 | wps 533616 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4985 | lr 0.000447886 | gnorm 0.508 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47727
2023-02-11 08:49:53 | INFO | fairseq.trainer | begin training epoch 1003
2023-02-11 08:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:50:32 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2023-02-11 08:50:32 | INFO | train | epoch 1003 | loss 5.093 | ppl 34.12 | wps 529044 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4990 | lr 0.000447661 | gnorm 0.461 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47766
2023-02-11 08:50:33 | INFO | fairseq.trainer | begin training epoch 1004
2023-02-11 08:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:51:13 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2023-02-11 08:51:13 | INFO | train | epoch 1004 | loss 5.092 | ppl 34.11 | wps 516706 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 4995 | lr 0.000447437 | gnorm 0.51 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 47807
2023-02-11 08:51:13 | INFO | fairseq.trainer | begin training epoch 1005
2023-02-11 08:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:51:55 | INFO | train_inner | epoch 1005:      5 / 5 loss=5.104, ppl=34.38, wps=427852, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=5000, lr=0.000447214, gnorm=0.571, loss_scale=1, train_wall=662, gb_free=5.6, wall=47849
2023-02-11 08:51:55 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2023-02-11 08:51:55 | INFO | train | epoch 1005 | loss 5.093 | ppl 34.13 | wps 503919 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5000 | lr 0.000447214 | gnorm 0.568 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 47849
2023-02-11 08:51:55 | INFO | fairseq.trainer | begin training epoch 1006
2023-02-11 08:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:52:35 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2023-02-11 08:52:35 | INFO | train | epoch 1006 | loss 5.089 | ppl 34.03 | wps 523019 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5005 | lr 0.00044699 | gnorm 0.514 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 47889
2023-02-11 08:52:35 | INFO | fairseq.trainer | begin training epoch 1007
2023-02-11 08:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:53:16 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2023-02-11 08:53:16 | INFO | train | epoch 1007 | loss 5.09 | ppl 34.05 | wps 512390 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5010 | lr 0.000446767 | gnorm 0.588 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 47930
2023-02-11 08:53:16 | INFO | fairseq.trainer | begin training epoch 1008
2023-02-11 08:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:53:58 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2023-02-11 08:53:58 | INFO | train | epoch 1008 | loss 5.092 | ppl 34.1 | wps 503960 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5015 | lr 0.000446544 | gnorm 0.624 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 47972
2023-02-11 08:53:58 | INFO | fairseq.trainer | begin training epoch 1009
2023-02-11 08:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:54:37 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2023-02-11 08:54:37 | INFO | train | epoch 1009 | loss 5.097 | ppl 34.23 | wps 531461 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5020 | lr 0.000446322 | gnorm 0.693 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48011
2023-02-11 08:54:38 | INFO | fairseq.trainer | begin training epoch 1010
2023-02-11 08:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 08:55:27 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 5.119 | ppl 34.74 | wps 0 | wpb 11230 | bsz 22 | num_updates 5025 | best_loss 5.118
2023-02-11 08:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 5025 updates
2023-02-11 08:55:27 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1010.pt
2023-02-11 08:55:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1010.pt
2023-02-11 08:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1010.pt (epoch 1010 @ 5025 updates, score 5.119) (writing took 57.64082940999651 seconds)
2023-02-11 08:56:24 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2023-02-11 08:56:24 | INFO | train | epoch 1010 | loss 5.089 | ppl 34.03 | wps 196581 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5025 | lr 0.0004461 | gnorm 0.539 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48118
2023-02-11 08:56:25 | INFO | fairseq.trainer | begin training epoch 1011
2023-02-11 08:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:57:21 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2023-02-11 08:57:21 | INFO | train | epoch 1011 | loss 5.091 | ppl 34.08 | wps 370739 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5030 | lr 0.000445878 | gnorm 0.613 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48175
2023-02-11 08:57:21 | INFO | fairseq.trainer | begin training epoch 1012
2023-02-11 08:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:58:03 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2023-02-11 08:58:03 | INFO | train | epoch 1012 | loss 5.088 | ppl 34.01 | wps 502984 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5035 | lr 0.000445657 | gnorm 0.591 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48217
2023-02-11 08:58:03 | INFO | fairseq.trainer | begin training epoch 1013
2023-02-11 08:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:58:44 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2023-02-11 08:58:44 | INFO | train | epoch 1013 | loss 5.094 | ppl 34.15 | wps 514771 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5040 | lr 0.000445435 | gnorm 0.67 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48258
2023-02-11 08:58:44 | INFO | fairseq.trainer | begin training epoch 1014
2023-02-11 08:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 08:59:24 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2023-02-11 08:59:24 | INFO | train | epoch 1014 | loss 5.087 | ppl 33.98 | wps 523883 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5045 | lr 0.000445215 | gnorm 0.567 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48298
2023-02-11 08:59:24 | INFO | fairseq.trainer | begin training epoch 1015
2023-02-11 08:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:00:07 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2023-02-11 09:00:07 | INFO | train | epoch 1015 | loss 5.084 | ppl 33.92 | wps 493733 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5050 | lr 0.000444994 | gnorm 0.564 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48341
2023-02-11 09:00:07 | INFO | fairseq.trainer | begin training epoch 1016
2023-02-11 09:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:00:47 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2023-02-11 09:00:47 | INFO | train | epoch 1016 | loss 5.096 | ppl 34.21 | wps 524750 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5055 | lr 0.000444774 | gnorm 0.668 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48381
2023-02-11 09:00:47 | INFO | fairseq.trainer | begin training epoch 1017
2023-02-11 09:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:01:28 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2023-02-11 09:01:28 | INFO | train | epoch 1017 | loss 5.097 | ppl 34.22 | wps 514581 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5060 | lr 0.000444554 | gnorm 0.6 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48422
2023-02-11 09:01:28 | INFO | fairseq.trainer | begin training epoch 1018
2023-02-11 09:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:02:09 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2023-02-11 09:02:09 | INFO | train | epoch 1018 | loss 5.091 | ppl 34.08 | wps 502036 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5065 | lr 0.000444335 | gnorm 0.522 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48464
2023-02-11 09:02:10 | INFO | fairseq.trainer | begin training epoch 1019
2023-02-11 09:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:02:50 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2023-02-11 09:02:50 | INFO | train | epoch 1019 | loss 5.087 | ppl 33.99 | wps 523807 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5070 | lr 0.000444116 | gnorm 0.528 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48504
2023-02-11 09:02:50 | INFO | fairseq.trainer | begin training epoch 1020
2023-02-11 09:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:03:39 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 5.122 | ppl 34.82 | wps 0 | wpb 11230 | bsz 22 | num_updates 5075 | best_loss 5.118
2023-02-11 09:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 5075 updates
2023-02-11 09:03:39 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1020.pt
2023-02-11 09:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1020.pt
2023-02-11 09:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1020.pt (epoch 1020 @ 5075 updates, score 5.122) (writing took 61.186555914988276 seconds)
2023-02-11 09:04:40 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2023-02-11 09:04:40 | INFO | train | epoch 1020 | loss 5.083 | ppl 33.9 | wps 190856 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5075 | lr 0.000443897 | gnorm 0.532 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48614
2023-02-11 09:04:40 | INFO | fairseq.trainer | begin training epoch 1021
2023-02-11 09:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:05:35 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2023-02-11 09:05:35 | INFO | train | epoch 1021 | loss 5.079 | ppl 33.79 | wps 382603 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5080 | lr 0.000443678 | gnorm 0.473 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48669
2023-02-11 09:05:35 | INFO | fairseq.trainer | begin training epoch 1022
2023-02-11 09:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:06:15 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2023-02-11 09:06:15 | INFO | train | epoch 1022 | loss 5.078 | ppl 33.78 | wps 518896 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5085 | lr 0.00044346 | gnorm 0.548 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48709
2023-02-11 09:06:16 | INFO | fairseq.trainer | begin training epoch 1023
2023-02-11 09:06:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:06:55 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2023-02-11 09:06:55 | INFO | train | epoch 1023 | loss 5.08 | ppl 33.83 | wps 525159 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5090 | lr 0.000443242 | gnorm 0.656 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48749
2023-02-11 09:06:56 | INFO | fairseq.trainer | begin training epoch 1024
2023-02-11 09:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:07:37 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2023-02-11 09:07:37 | INFO | train | epoch 1024 | loss 5.083 | ppl 33.89 | wps 510862 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5095 | lr 0.000443025 | gnorm 0.67 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48791
2023-02-11 09:07:37 | INFO | fairseq.trainer | begin training epoch 1025
2023-02-11 09:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:08:18 | INFO | train_inner | epoch 1025:      5 / 5 loss=5.088, ppl=34, wps=427874, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=5100, lr=0.000442807, gnorm=0.589, loss_scale=1, train_wall=661, gb_free=5.6, wall=48832
2023-02-11 09:08:18 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2023-02-11 09:08:18 | INFO | train | epoch 1025 | loss 5.079 | ppl 33.79 | wps 507449 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5100 | lr 0.000442807 | gnorm 0.616 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48832
2023-02-11 09:08:18 | INFO | fairseq.trainer | begin training epoch 1026
2023-02-11 09:08:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:08:58 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2023-02-11 09:08:58 | INFO | train | epoch 1026 | loss 5.08 | ppl 33.82 | wps 526802 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5105 | lr 0.000442591 | gnorm 0.629 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48872
2023-02-11 09:08:58 | INFO | fairseq.trainer | begin training epoch 1027
2023-02-11 09:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:09:39 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2023-02-11 09:09:39 | INFO | train | epoch 1027 | loss 5.08 | ppl 33.83 | wps 509470 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5110 | lr 0.000442374 | gnorm 0.655 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48913
2023-02-11 09:09:40 | INFO | fairseq.trainer | begin training epoch 1028
2023-02-11 09:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:10:21 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2023-02-11 09:10:21 | INFO | train | epoch 1028 | loss 5.073 | ppl 33.65 | wps 499416 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5115 | lr 0.000442158 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48955
2023-02-11 09:10:22 | INFO | fairseq.trainer | begin training epoch 1029
2023-02-11 09:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:11:01 | INFO | fairseq_cli.train | end of epoch 1029 (average epoch stats below)
2023-02-11 09:11:01 | INFO | train | epoch 1029 | loss 5.069 | ppl 33.57 | wps 530859 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5120 | lr 0.000441942 | gnorm 0.527 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 48995
2023-02-11 09:11:01 | INFO | fairseq.trainer | begin training epoch 1030
2023-02-11 09:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:11:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:11:50 | INFO | valid | epoch 1030 | valid on 'valid' subset | loss 5.134 | ppl 35.1 | wps 0 | wpb 11230 | bsz 22 | num_updates 5125 | best_loss 5.118
2023-02-11 09:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1030 @ 5125 updates
2023-02-11 09:11:50 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1030.pt
2023-02-11 09:11:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1030.pt
2023-02-11 09:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1030.pt (epoch 1030 @ 5125 updates, score 5.134) (writing took 68.52128999799606 seconds)
2023-02-11 09:12:59 | INFO | fairseq_cli.train | end of epoch 1030 (average epoch stats below)
2023-02-11 09:12:59 | INFO | train | epoch 1030 | loss 5.069 | ppl 33.57 | wps 178623 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5125 | lr 0.000441726 | gnorm 0.549 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49113
2023-02-11 09:12:59 | INFO | fairseq.trainer | begin training epoch 1031
2023-02-11 09:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:13:51 | INFO | fairseq_cli.train | end of epoch 1031 (average epoch stats below)
2023-02-11 09:13:51 | INFO | train | epoch 1031 | loss 5.064 | ppl 33.45 | wps 405917 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5130 | lr 0.000441511 | gnorm 0.466 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49165
2023-02-11 09:13:51 | INFO | fairseq.trainer | begin training epoch 1032
2023-02-11 09:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:14:32 | INFO | fairseq_cli.train | end of epoch 1032 (average epoch stats below)
2023-02-11 09:14:32 | INFO | train | epoch 1032 | loss 5.067 | ppl 33.53 | wps 513152 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5135 | lr 0.000441296 | gnorm 0.585 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49206
2023-02-11 09:14:32 | INFO | fairseq.trainer | begin training epoch 1033
2023-02-11 09:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:15:12 | INFO | fairseq_cli.train | end of epoch 1033 (average epoch stats below)
2023-02-11 09:15:12 | INFO | train | epoch 1033 | loss 5.071 | ppl 33.61 | wps 519560 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5140 | lr 0.000441081 | gnorm 0.634 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49246
2023-02-11 09:15:12 | INFO | fairseq.trainer | begin training epoch 1034
2023-02-11 09:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:15:53 | INFO | fairseq_cli.train | end of epoch 1034 (average epoch stats below)
2023-02-11 09:15:53 | INFO | train | epoch 1034 | loss 5.068 | ppl 33.54 | wps 511396 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5145 | lr 0.000440867 | gnorm 0.631 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49287
2023-02-11 09:15:54 | INFO | fairseq.trainer | begin training epoch 1035
2023-02-11 09:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:16:35 | INFO | fairseq_cli.train | end of epoch 1035 (average epoch stats below)
2023-02-11 09:16:35 | INFO | train | epoch 1035 | loss 5.072 | ppl 33.63 | wps 507800 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5150 | lr 0.000440653 | gnorm 0.727 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49329
2023-02-11 09:16:35 | INFO | fairseq.trainer | begin training epoch 1036
2023-02-11 09:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:17:15 | INFO | fairseq_cli.train | end of epoch 1036 (average epoch stats below)
2023-02-11 09:17:15 | INFO | train | epoch 1036 | loss 5.072 | ppl 33.63 | wps 521754 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5155 | lr 0.000440439 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49369
2023-02-11 09:17:15 | INFO | fairseq.trainer | begin training epoch 1037
2023-02-11 09:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:17:55 | INFO | fairseq_cli.train | end of epoch 1037 (average epoch stats below)
2023-02-11 09:17:55 | INFO | train | epoch 1037 | loss 5.064 | ppl 33.44 | wps 521227 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5160 | lr 0.000440225 | gnorm 0.498 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49409
2023-02-11 09:17:56 | INFO | fairseq.trainer | begin training epoch 1038
2023-02-11 09:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:18:38 | INFO | fairseq_cli.train | end of epoch 1038 (average epoch stats below)
2023-02-11 09:18:38 | INFO | train | epoch 1038 | loss 5.064 | ppl 33.46 | wps 497331 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5165 | lr 0.000440012 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49452
2023-02-11 09:18:38 | INFO | fairseq.trainer | begin training epoch 1039
2023-02-11 09:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:19:18 | INFO | fairseq_cli.train | end of epoch 1039 (average epoch stats below)
2023-02-11 09:19:18 | INFO | train | epoch 1039 | loss 5.063 | ppl 33.42 | wps 524550 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5170 | lr 0.000439799 | gnorm 0.557 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49492
2023-02-11 09:19:18 | INFO | fairseq.trainer | begin training epoch 1040
2023-02-11 09:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:20:07 | INFO | valid | epoch 1040 | valid on 'valid' subset | loss 5.16 | ppl 35.76 | wps 0 | wpb 11230 | bsz 22 | num_updates 5175 | best_loss 5.118
2023-02-11 09:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1040 @ 5175 updates
2023-02-11 09:20:07 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1040.pt
2023-02-11 09:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1040.pt
2023-02-11 09:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1040.pt (epoch 1040 @ 5175 updates, score 5.16) (writing took 70.05137658698368 seconds)
2023-02-11 09:21:17 | INFO | fairseq_cli.train | end of epoch 1040 (average epoch stats below)
2023-02-11 09:21:17 | INFO | train | epoch 1040 | loss 5.058 | ppl 33.3 | wps 176515 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5175 | lr 0.000439587 | gnorm 0.485 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49611
2023-02-11 09:21:17 | INFO | fairseq.trainer | begin training epoch 1041
2023-02-11 09:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:22:44 | INFO | fairseq_cli.train | end of epoch 1041 (average epoch stats below)
2023-02-11 09:22:44 | INFO | train | epoch 1041 | loss 5.058 | ppl 33.32 | wps 240076 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5180 | lr 0.000439375 | gnorm 0.541 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49698
2023-02-11 09:22:45 | INFO | fairseq.trainer | begin training epoch 1042
2023-02-11 09:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:23:24 | INFO | fairseq_cli.train | end of epoch 1042 (average epoch stats below)
2023-02-11 09:23:24 | INFO | train | epoch 1042 | loss 5.056 | ppl 33.27 | wps 531165 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5185 | lr 0.000439163 | gnorm 0.555 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49738
2023-02-11 09:23:24 | INFO | fairseq.trainer | begin training epoch 1043
2023-02-11 09:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:24:04 | INFO | fairseq_cli.train | end of epoch 1043 (average epoch stats below)
2023-02-11 09:24:04 | INFO | train | epoch 1043 | loss 5.062 | ppl 33.41 | wps 522873 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5190 | lr 0.000438951 | gnorm 0.665 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49778
2023-02-11 09:24:05 | INFO | fairseq.trainer | begin training epoch 1044
2023-02-11 09:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:24:46 | INFO | fairseq_cli.train | end of epoch 1044 (average epoch stats below)
2023-02-11 09:24:46 | INFO | train | epoch 1044 | loss 5.058 | ppl 33.31 | wps 499643 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5195 | lr 0.00043874 | gnorm 0.564 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49820
2023-02-11 09:24:47 | INFO | fairseq.trainer | begin training epoch 1045
2023-02-11 09:24:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:25:26 | INFO | train_inner | epoch 1045:      5 / 5 loss=5.066, ppl=33.5, wps=409256, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=5200, lr=0.000438529, gnorm=0.58, loss_scale=1, train_wall=662, gb_free=5.6, wall=49860
2023-02-11 09:25:26 | INFO | fairseq_cli.train | end of epoch 1045 (average epoch stats below)
2023-02-11 09:25:26 | INFO | train | epoch 1045 | loss 5.056 | ppl 33.26 | wps 531600 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5200 | lr 0.000438529 | gnorm 0.586 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49860
2023-02-11 09:25:26 | INFO | fairseq.trainer | begin training epoch 1046
2023-02-11 09:25:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:26:07 | INFO | fairseq_cli.train | end of epoch 1046 (average epoch stats below)
2023-02-11 09:26:07 | INFO | train | epoch 1046 | loss 5.061 | ppl 33.38 | wps 513124 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5205 | lr 0.000438318 | gnorm 0.699 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49901
2023-02-11 09:26:07 | INFO | fairseq.trainer | begin training epoch 1047
2023-02-11 09:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:26:49 | INFO | fairseq_cli.train | end of epoch 1047 (average epoch stats below)
2023-02-11 09:26:49 | INFO | train | epoch 1047 | loss 5.058 | ppl 33.31 | wps 499665 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5210 | lr 0.000438108 | gnorm 0.583 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49943
2023-02-11 09:26:49 | INFO | fairseq.trainer | begin training epoch 1048
2023-02-11 09:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:27:29 | INFO | fairseq_cli.train | end of epoch 1048 (average epoch stats below)
2023-02-11 09:27:29 | INFO | train | epoch 1048 | loss 5.049 | ppl 33.11 | wps 520685 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5215 | lr 0.000437898 | gnorm 0.479 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 49983
2023-02-11 09:27:30 | INFO | fairseq.trainer | begin training epoch 1049
2023-02-11 09:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:28:10 | INFO | fairseq_cli.train | end of epoch 1049 (average epoch stats below)
2023-02-11 09:28:10 | INFO | train | epoch 1049 | loss 5.053 | ppl 33.19 | wps 512601 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5220 | lr 0.000437688 | gnorm 0.593 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 50025
2023-02-11 09:28:11 | INFO | fairseq.trainer | begin training epoch 1050
2023-02-11 09:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:28:58 | INFO | valid | epoch 1050 | valid on 'valid' subset | loss 5.129 | ppl 34.98 | wps 0 | wpb 11230 | bsz 22 | num_updates 5225 | best_loss 5.118
2023-02-11 09:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1050 @ 5225 updates
2023-02-11 09:28:58 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1050.pt
2023-02-11 09:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1050.pt
2023-02-11 09:30:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1050.pt (epoch 1050 @ 5225 updates, score 5.129) (writing took 62.34542144200532 seconds)
2023-02-11 09:30:01 | INFO | fairseq_cli.train | end of epoch 1050 (average epoch stats below)
2023-02-11 09:30:01 | INFO | train | epoch 1050 | loss 5.048 | ppl 33.07 | wps 190953 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5225 | lr 0.000437479 | gnorm 0.48 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 50135
2023-02-11 09:30:01 | INFO | fairseq.trainer | begin training epoch 1051
2023-02-11 09:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 09:30:55 | INFO | fairseq_cli.train | end of epoch 1051 (average epoch stats below)
2023-02-11 09:30:55 | INFO | train | epoch 1051 | loss 5.044 | ppl 32.99 | wps 292646 | ups 0.07 | wpb 3.97306e+06 | bsz 7760 | num_updates 5229 | lr 0.000437311 | gnorm 0.593 | loss_scale 0.5 | train_wall 33 | gb_free 5.4 | wall 50189
2023-02-11 09:30:55 | INFO | fairseq.trainer | begin training epoch 1052
2023-02-11 09:30:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:31:35 | INFO | fairseq_cli.train | end of epoch 1052 (average epoch stats below)
2023-02-11 09:31:35 | INFO | train | epoch 1052 | loss 5.059 | ppl 33.33 | wps 524301 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5234 | lr 0.000437102 | gnorm 0.732 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50229
2023-02-11 09:31:35 | INFO | fairseq.trainer | begin training epoch 1053
2023-02-11 09:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:32:16 | INFO | fairseq_cli.train | end of epoch 1053 (average epoch stats below)
2023-02-11 09:32:16 | INFO | train | epoch 1053 | loss 5.057 | ppl 33.28 | wps 517450 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5239 | lr 0.000436894 | gnorm 0.661 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50270
2023-02-11 09:32:16 | INFO | fairseq.trainer | begin training epoch 1054
2023-02-11 09:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:32:58 | INFO | fairseq_cli.train | end of epoch 1054 (average epoch stats below)
2023-02-11 09:32:58 | INFO | train | epoch 1054 | loss 5.055 | ppl 33.25 | wps 501692 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5244 | lr 0.000436685 | gnorm 0.693 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50312
2023-02-11 09:32:58 | INFO | fairseq.trainer | begin training epoch 1055
2023-02-11 09:32:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:33:38 | INFO | fairseq_cli.train | end of epoch 1055 (average epoch stats below)
2023-02-11 09:33:38 | INFO | train | epoch 1055 | loss 5.047 | ppl 33.07 | wps 521775 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5249 | lr 0.000436477 | gnorm 0.532 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50352
2023-02-11 09:33:38 | INFO | fairseq.trainer | begin training epoch 1056
2023-02-11 09:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:34:19 | INFO | fairseq_cli.train | end of epoch 1056 (average epoch stats below)
2023-02-11 09:34:19 | INFO | train | epoch 1056 | loss 5.042 | ppl 32.94 | wps 518405 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5254 | lr 0.00043627 | gnorm 0.451 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50393
2023-02-11 09:34:19 | INFO | fairseq.trainer | begin training epoch 1057
2023-02-11 09:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:35:00 | INFO | fairseq_cli.train | end of epoch 1057 (average epoch stats below)
2023-02-11 09:35:00 | INFO | train | epoch 1057 | loss 5.044 | ppl 32.99 | wps 503549 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5259 | lr 0.000436062 | gnorm 0.575 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50434
2023-02-11 09:35:01 | INFO | fairseq.trainer | begin training epoch 1058
2023-02-11 09:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:35:41 | INFO | fairseq_cli.train | end of epoch 1058 (average epoch stats below)
2023-02-11 09:35:41 | INFO | train | epoch 1058 | loss 5.042 | ppl 32.94 | wps 517984 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5264 | lr 0.000435855 | gnorm 0.562 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50475
2023-02-11 09:35:41 | INFO | fairseq.trainer | begin training epoch 1059
2023-02-11 09:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:36:21 | INFO | fairseq_cli.train | end of epoch 1059 (average epoch stats below)
2023-02-11 09:36:21 | INFO | train | epoch 1059 | loss 5.037 | ppl 32.84 | wps 518321 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5269 | lr 0.000435648 | gnorm 0.486 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50516
2023-02-11 09:36:22 | INFO | fairseq.trainer | begin training epoch 1060
2023-02-11 09:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:37:10 | INFO | valid | epoch 1060 | valid on 'valid' subset | loss 5.153 | ppl 35.57 | wps 0 | wpb 11230 | bsz 22 | num_updates 5274 | best_loss 5.118
2023-02-11 09:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1060 @ 5274 updates
2023-02-11 09:37:10 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1060.pt
2023-02-11 09:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1060.pt
2023-02-11 09:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1060.pt (epoch 1060 @ 5274 updates, score 5.153) (writing took 63.81829751498299 seconds)
2023-02-11 09:38:14 | INFO | fairseq_cli.train | end of epoch 1060 (average epoch stats below)
2023-02-11 09:38:14 | INFO | train | epoch 1060 | loss 5.04 | ppl 32.9 | wps 187511 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5274 | lr 0.000435442 | gnorm 0.57 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50628
2023-02-11 09:38:14 | INFO | fairseq.trainer | begin training epoch 1061
2023-02-11 09:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:39:09 | INFO | fairseq_cli.train | end of epoch 1061 (average epoch stats below)
2023-02-11 09:39:09 | INFO | train | epoch 1061 | loss 5.038 | ppl 32.85 | wps 381635 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5279 | lr 0.000435235 | gnorm 0.558 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50683
2023-02-11 09:39:09 | INFO | fairseq.trainer | begin training epoch 1062
2023-02-11 09:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:39:47 | INFO | fairseq_cli.train | end of epoch 1062 (average epoch stats below)
2023-02-11 09:39:47 | INFO | train | epoch 1062 | loss 5.041 | ppl 32.92 | wps 548402 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5284 | lr 0.000435029 | gnorm 0.656 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50721
2023-02-11 09:39:47 | INFO | fairseq.trainer | begin training epoch 1063
2023-02-11 09:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:40:27 | INFO | fairseq_cli.train | end of epoch 1063 (average epoch stats below)
2023-02-11 09:40:27 | INFO | train | epoch 1063 | loss 5.043 | ppl 32.96 | wps 529964 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5289 | lr 0.000434824 | gnorm 0.651 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50761
2023-02-11 09:40:27 | INFO | fairseq.trainer | begin training epoch 1064
2023-02-11 09:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:41:09 | INFO | fairseq_cli.train | end of epoch 1064 (average epoch stats below)
2023-02-11 09:41:09 | INFO | train | epoch 1064 | loss 5.043 | ppl 32.98 | wps 493660 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5294 | lr 0.000434618 | gnorm 0.716 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50803
2023-02-11 09:41:10 | INFO | fairseq.trainer | begin training epoch 1065
2023-02-11 09:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:41:50 | INFO | fairseq_cli.train | end of epoch 1065 (average epoch stats below)
2023-02-11 09:41:50 | INFO | train | epoch 1065 | loss 5.042 | ppl 32.95 | wps 524373 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5299 | lr 0.000434413 | gnorm 0.623 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50844
2023-02-11 09:41:50 | INFO | fairseq.trainer | begin training epoch 1066
2023-02-11 09:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:42:04 | INFO | train_inner | epoch 1066:      1 / 5 loss=5.047, ppl=33.06, wps=421413, ups=0.1, wpb=4.20777e+06, bsz=8218.4, num_updates=5300, lr=0.000434372, gnorm=0.596, loss_scale=0.5, train_wall=670, gb_free=5.4, wall=50858
2023-02-11 09:42:30 | INFO | fairseq_cli.train | end of epoch 1066 (average epoch stats below)
2023-02-11 09:42:30 | INFO | train | epoch 1066 | loss 5.04 | ppl 32.91 | wps 521958 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5304 | lr 0.000434208 | gnorm 0.622 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50884
2023-02-11 09:42:30 | INFO | fairseq.trainer | begin training epoch 1067
2023-02-11 09:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:43:12 | INFO | fairseq_cli.train | end of epoch 1067 (average epoch stats below)
2023-02-11 09:43:12 | INFO | train | epoch 1067 | loss 5.035 | ppl 32.78 | wps 496240 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5309 | lr 0.000434004 | gnorm 0.507 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50926
2023-02-11 09:43:12 | INFO | fairseq.trainer | begin training epoch 1068
2023-02-11 09:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:43:52 | INFO | fairseq_cli.train | end of epoch 1068 (average epoch stats below)
2023-02-11 09:43:52 | INFO | train | epoch 1068 | loss 5.032 | ppl 32.73 | wps 522897 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5314 | lr 0.0004338 | gnorm 0.502 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 50967
2023-02-11 09:43:53 | INFO | fairseq.trainer | begin training epoch 1069
2023-02-11 09:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:44:33 | INFO | fairseq_cli.train | end of epoch 1069 (average epoch stats below)
2023-02-11 09:44:33 | INFO | train | epoch 1069 | loss 5.032 | ppl 32.72 | wps 517456 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5319 | lr 0.000433596 | gnorm 0.561 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51007
2023-02-11 09:44:33 | INFO | fairseq.trainer | begin training epoch 1070
2023-02-11 09:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:45:22 | INFO | valid | epoch 1070 | valid on 'valid' subset | loss 5.136 | ppl 35.15 | wps 0 | wpb 11230 | bsz 22 | num_updates 5324 | best_loss 5.118
2023-02-11 09:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1070 @ 5324 updates
2023-02-11 09:45:22 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1070.pt
2023-02-11 09:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1070.pt
2023-02-11 09:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1070.pt (epoch 1070 @ 5324 updates, score 5.136) (writing took 59.77675022999756 seconds)
2023-02-11 09:46:21 | INFO | fairseq_cli.train | end of epoch 1070 (average epoch stats below)
2023-02-11 09:46:21 | INFO | train | epoch 1070 | loss 5.033 | ppl 32.74 | wps 194323 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5324 | lr 0.000433392 | gnorm 0.586 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51115
2023-02-11 09:46:22 | INFO | fairseq.trainer | begin training epoch 1071
2023-02-11 09:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:47:13 | INFO | fairseq_cli.train | end of epoch 1071 (average epoch stats below)
2023-02-11 09:47:13 | INFO | train | epoch 1071 | loss 5.026 | ppl 32.57 | wps 407083 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5329 | lr 0.000433189 | gnorm 0.485 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51167
2023-02-11 09:47:13 | INFO | fairseq.trainer | begin training epoch 1072
2023-02-11 09:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:47:53 | INFO | fairseq_cli.train | end of epoch 1072 (average epoch stats below)
2023-02-11 09:47:53 | INFO | train | epoch 1072 | loss 5.025 | ppl 32.55 | wps 520200 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5334 | lr 0.000432986 | gnorm 0.474 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51208
2023-02-11 09:47:54 | INFO | fairseq.trainer | begin training epoch 1073
2023-02-11 09:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:48:34 | INFO | fairseq_cli.train | end of epoch 1073 (average epoch stats below)
2023-02-11 09:48:34 | INFO | train | epoch 1073 | loss 5.026 | ppl 32.58 | wps 518696 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5339 | lr 0.000432783 | gnorm 0.601 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51248
2023-02-11 09:48:34 | INFO | fairseq.trainer | begin training epoch 1074
2023-02-11 09:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:49:16 | INFO | fairseq_cli.train | end of epoch 1074 (average epoch stats below)
2023-02-11 09:49:16 | INFO | train | epoch 1074 | loss 5.044 | ppl 32.98 | wps 504181 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5344 | lr 0.00043258 | gnorm 0.848 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51290
2023-02-11 09:49:16 | INFO | fairseq.trainer | begin training epoch 1075
2023-02-11 09:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:49:56 | INFO | fairseq_cli.train | end of epoch 1075 (average epoch stats below)
2023-02-11 09:49:56 | INFO | train | epoch 1075 | loss 5.037 | ppl 32.83 | wps 517810 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5349 | lr 0.000432378 | gnorm 0.649 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51330
2023-02-11 09:49:57 | INFO | fairseq.trainer | begin training epoch 1076
2023-02-11 09:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:50:37 | INFO | fairseq_cli.train | end of epoch 1076 (average epoch stats below)
2023-02-11 09:50:37 | INFO | train | epoch 1076 | loss 5.033 | ppl 32.74 | wps 516160 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5354 | lr 0.000432176 | gnorm 0.588 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51371
2023-02-11 09:50:37 | INFO | fairseq.trainer | begin training epoch 1077
2023-02-11 09:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:51:19 | INFO | fairseq_cli.train | end of epoch 1077 (average epoch stats below)
2023-02-11 09:51:19 | INFO | train | epoch 1077 | loss 5.03 | ppl 32.67 | wps 505262 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5359 | lr 0.000431975 | gnorm 0.609 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51413
2023-02-11 09:51:19 | INFO | fairseq.trainer | begin training epoch 1078
2023-02-11 09:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:51:59 | INFO | fairseq_cli.train | end of epoch 1078 (average epoch stats below)
2023-02-11 09:51:59 | INFO | train | epoch 1078 | loss 5.025 | ppl 32.56 | wps 522253 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5364 | lr 0.000431773 | gnorm 0.546 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51453
2023-02-11 09:51:59 | INFO | fairseq.trainer | begin training epoch 1079
2023-02-11 09:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:52:40 | INFO | fairseq_cli.train | end of epoch 1079 (average epoch stats below)
2023-02-11 09:52:40 | INFO | train | epoch 1079 | loss 5.025 | ppl 32.55 | wps 513976 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5369 | lr 0.000431572 | gnorm 0.647 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51494
2023-02-11 09:52:40 | INFO | fairseq.trainer | begin training epoch 1080
2023-02-11 09:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 09:53:28 | INFO | valid | epoch 1080 | valid on 'valid' subset | loss 5.138 | ppl 35.21 | wps 0 | wpb 11230 | bsz 22 | num_updates 5374 | best_loss 5.118
2023-02-11 09:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1080 @ 5374 updates
2023-02-11 09:53:28 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1080.pt
2023-02-11 09:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1080.pt
2023-02-11 09:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1080.pt (epoch 1080 @ 5374 updates, score 5.138) (writing took 62.38054444899899 seconds)
2023-02-11 09:54:31 | INFO | fairseq_cli.train | end of epoch 1080 (average epoch stats below)
2023-02-11 09:54:31 | INFO | train | epoch 1080 | loss 5.024 | ppl 32.54 | wps 190200 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5374 | lr 0.000431371 | gnorm 0.555 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51605
2023-02-11 09:54:31 | INFO | fairseq.trainer | begin training epoch 1081
2023-02-11 09:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:55:20 | INFO | fairseq_cli.train | end of epoch 1081 (average epoch stats below)
2023-02-11 09:55:20 | INFO | train | epoch 1081 | loss 5.023 | ppl 32.52 | wps 427872 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5379 | lr 0.000431171 | gnorm 0.583 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51654
2023-02-11 09:55:20 | INFO | fairseq.trainer | begin training epoch 1082
2023-02-11 09:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:55:59 | INFO | fairseq_cli.train | end of epoch 1082 (average epoch stats below)
2023-02-11 09:55:59 | INFO | train | epoch 1082 | loss 5.021 | ppl 32.46 | wps 528738 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5384 | lr 0.00043097 | gnorm 0.56 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51694
2023-02-11 09:56:00 | INFO | fairseq.trainer | begin training epoch 1083
2023-02-11 09:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:56:41 | INFO | fairseq_cli.train | end of epoch 1083 (average epoch stats below)
2023-02-11 09:56:41 | INFO | train | epoch 1083 | loss 5.024 | ppl 32.54 | wps 509937 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5389 | lr 0.00043077 | gnorm 0.65 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51735
2023-02-11 09:56:41 | INFO | fairseq.trainer | begin training epoch 1084
2023-02-11 09:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:57:22 | INFO | fairseq_cli.train | end of epoch 1084 (average epoch stats below)
2023-02-11 09:57:22 | INFO | train | epoch 1084 | loss 5.018 | ppl 32.4 | wps 508296 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5394 | lr 0.000430571 | gnorm 0.514 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51776
2023-02-11 09:57:22 | INFO | fairseq.trainer | begin training epoch 1085
2023-02-11 09:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:58:02 | INFO | fairseq_cli.train | end of epoch 1085 (average epoch stats below)
2023-02-11 09:58:02 | INFO | train | epoch 1085 | loss 5.021 | ppl 32.47 | wps 524379 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5399 | lr 0.000430371 | gnorm 0.665 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51816
2023-02-11 09:58:03 | INFO | fairseq.trainer | begin training epoch 1086
2023-02-11 09:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:58:18 | INFO | train_inner | epoch 1086:      1 / 5 loss=5.028, ppl=32.63, wps=431975, ups=0.1, wpb=4.20574e+06, bsz=8214.4, num_updates=5400, lr=0.000430331, gnorm=0.586, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=51832
2023-02-11 09:58:43 | INFO | fairseq_cli.train | end of epoch 1086 (average epoch stats below)
2023-02-11 09:58:43 | INFO | train | epoch 1086 | loss 5.017 | ppl 32.38 | wps 511099 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5404 | lr 0.000430172 | gnorm 0.575 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51857
2023-02-11 09:58:44 | INFO | fairseq.trainer | begin training epoch 1087
2023-02-11 09:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 09:59:24 | INFO | fairseq_cli.train | end of epoch 1087 (average epoch stats below)
2023-02-11 09:59:24 | INFO | train | epoch 1087 | loss 5.014 | ppl 32.3 | wps 512753 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5409 | lr 0.000429973 | gnorm 0.477 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51898
2023-02-11 09:59:25 | INFO | fairseq.trainer | begin training epoch 1088
2023-02-11 09:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:00:05 | INFO | fairseq_cli.train | end of epoch 1088 (average epoch stats below)
2023-02-11 10:00:05 | INFO | train | epoch 1088 | loss 5.015 | ppl 32.34 | wps 518048 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5414 | lr 0.000429775 | gnorm 0.602 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51939
2023-02-11 10:00:05 | INFO | fairseq.trainer | begin training epoch 1089
2023-02-11 10:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:00:47 | INFO | fairseq_cli.train | end of epoch 1089 (average epoch stats below)
2023-02-11 10:00:47 | INFO | train | epoch 1089 | loss 5.016 | ppl 32.35 | wps 503062 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5419 | lr 0.000429576 | gnorm 0.602 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 51981
2023-02-11 10:00:47 | INFO | fairseq.trainer | begin training epoch 1090
2023-02-11 10:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:01:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:01:34 | INFO | valid | epoch 1090 | valid on 'valid' subset | loss 5.146 | ppl 35.42 | wps 0 | wpb 11230 | bsz 22 | num_updates 5424 | best_loss 5.118
2023-02-11 10:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1090 @ 5424 updates
2023-02-11 10:01:34 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1090.pt
2023-02-11 10:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1090.pt
2023-02-11 10:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1090.pt (epoch 1090 @ 5424 updates, score 5.146) (writing took 64.70927201100858 seconds)
2023-02-11 10:02:39 | INFO | fairseq_cli.train | end of epoch 1090 (average epoch stats below)
2023-02-11 10:02:39 | INFO | train | epoch 1090 | loss 5.015 | ppl 32.34 | wps 188185 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5424 | lr 0.000429378 | gnorm 0.58 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52093
2023-02-11 10:02:39 | INFO | fairseq.trainer | begin training epoch 1091
2023-02-11 10:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:03:27 | INFO | fairseq_cli.train | end of epoch 1091 (average epoch stats below)
2023-02-11 10:03:27 | INFO | train | epoch 1091 | loss 5.011 | ppl 32.25 | wps 438887 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5429 | lr 0.000429181 | gnorm 0.539 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52141
2023-02-11 10:03:27 | INFO | fairseq.trainer | begin training epoch 1092
2023-02-11 10:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:04:06 | INFO | fairseq_cli.train | end of epoch 1092 (average epoch stats below)
2023-02-11 10:04:06 | INFO | train | epoch 1092 | loss 5.011 | ppl 32.24 | wps 536188 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5434 | lr 0.000428983 | gnorm 0.561 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52180
2023-02-11 10:04:06 | INFO | fairseq.trainer | begin training epoch 1093
2023-02-11 10:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:04:47 | INFO | fairseq_cli.train | end of epoch 1093 (average epoch stats below)
2023-02-11 10:04:47 | INFO | train | epoch 1093 | loss 5.012 | ppl 32.27 | wps 508646 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5439 | lr 0.000428786 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52221
2023-02-11 10:04:47 | INFO | fairseq.trainer | begin training epoch 1094
2023-02-11 10:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:05:28 | INFO | fairseq_cli.train | end of epoch 1094 (average epoch stats below)
2023-02-11 10:05:28 | INFO | train | epoch 1094 | loss 5.014 | ppl 32.32 | wps 514386 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5444 | lr 0.000428589 | gnorm 0.659 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52262
2023-02-11 10:05:28 | INFO | fairseq.trainer | begin training epoch 1095
2023-02-11 10:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:06:08 | INFO | fairseq_cli.train | end of epoch 1095 (average epoch stats below)
2023-02-11 10:06:08 | INFO | train | epoch 1095 | loss 5.016 | ppl 32.36 | wps 527114 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5449 | lr 0.000428392 | gnorm 0.727 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52302
2023-02-11 10:06:08 | INFO | fairseq.trainer | begin training epoch 1096
2023-02-11 10:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:06:50 | INFO | fairseq_cli.train | end of epoch 1096 (average epoch stats below)
2023-02-11 10:06:50 | INFO | train | epoch 1096 | loss 5.018 | ppl 32.4 | wps 496032 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5454 | lr 0.000428196 | gnorm 0.703 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52344
2023-02-11 10:06:51 | INFO | fairseq.trainer | begin training epoch 1097
2023-02-11 10:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:07:31 | INFO | fairseq_cli.train | end of epoch 1097 (average epoch stats below)
2023-02-11 10:07:31 | INFO | train | epoch 1097 | loss 5.011 | ppl 32.24 | wps 518102 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5459 | lr 0.000428 | gnorm 0.569 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52385
2023-02-11 10:07:31 | INFO | fairseq.trainer | begin training epoch 1098
2023-02-11 10:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:08:11 | INFO | fairseq_cli.train | end of epoch 1098 (average epoch stats below)
2023-02-11 10:08:11 | INFO | train | epoch 1098 | loss 5.008 | ppl 32.19 | wps 520004 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5464 | lr 0.000427804 | gnorm 0.562 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52425
2023-02-11 10:08:12 | INFO | fairseq.trainer | begin training epoch 1099
2023-02-11 10:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:08:53 | INFO | fairseq_cli.train | end of epoch 1099 (average epoch stats below)
2023-02-11 10:08:53 | INFO | train | epoch 1099 | loss 5.006 | ppl 32.14 | wps 506792 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5469 | lr 0.000427608 | gnorm 0.571 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52467
2023-02-11 10:08:53 | INFO | fairseq.trainer | begin training epoch 1100
2023-02-11 10:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:09:41 | INFO | valid | epoch 1100 | valid on 'valid' subset | loss 5.153 | ppl 35.59 | wps 0 | wpb 11230 | bsz 22 | num_updates 5474 | best_loss 5.118
2023-02-11 10:09:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1100 @ 5474 updates
2023-02-11 10:09:41 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1100.pt
2023-02-11 10:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1100.pt
2023-02-11 10:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1100.pt (epoch 1100 @ 5474 updates, score 5.153) (writing took 59.64561738699558 seconds)
2023-02-11 10:10:40 | INFO | fairseq_cli.train | end of epoch 1100 (average epoch stats below)
2023-02-11 10:10:40 | INFO | train | epoch 1100 | loss 5.006 | ppl 32.14 | wps 195899 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5474 | lr 0.000427413 | gnorm 0.584 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52574
2023-02-11 10:10:41 | INFO | fairseq.trainer | begin training epoch 1101
2023-02-11 10:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:11:26 | INFO | fairseq_cli.train | end of epoch 1101 (average epoch stats below)
2023-02-11 10:11:26 | INFO | train | epoch 1101 | loss 5 | ppl 32.01 | wps 456343 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5479 | lr 0.000427218 | gnorm 0.499 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 52620
2023-02-11 10:11:27 | INFO | fairseq.trainer | begin training epoch 1102
2023-02-11 10:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:12:07 | INFO | fairseq_cli.train | end of epoch 1102 (average epoch stats below)
2023-02-11 10:12:07 | INFO | train | epoch 1102 | loss 5 | ppl 31.99 | wps 519507 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5484 | lr 0.000427023 | gnorm 0.514 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52661
2023-02-11 10:12:07 | INFO | fairseq.trainer | begin training epoch 1103
2023-02-11 10:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:12:49 | INFO | fairseq_cli.train | end of epoch 1103 (average epoch stats below)
2023-02-11 10:12:49 | INFO | train | epoch 1103 | loss 4.998 | ppl 31.97 | wps 496858 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5489 | lr 0.000426828 | gnorm 0.5 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52703
2023-02-11 10:12:49 | INFO | fairseq.trainer | begin training epoch 1104
2023-02-11 10:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:13:29 | INFO | fairseq_cli.train | end of epoch 1104 (average epoch stats below)
2023-02-11 10:13:29 | INFO | train | epoch 1104 | loss 5.003 | ppl 32.06 | wps 528081 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5494 | lr 0.000426634 | gnorm 0.659 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52743
2023-02-11 10:13:29 | INFO | fairseq.trainer | begin training epoch 1105
2023-02-11 10:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:14:10 | INFO | fairseq_cli.train | end of epoch 1105 (average epoch stats below)
2023-02-11 10:14:10 | INFO | train | epoch 1105 | loss 5.011 | ppl 32.25 | wps 511871 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5499 | lr 0.00042644 | gnorm 0.741 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52784
2023-02-11 10:14:10 | INFO | fairseq.trainer | begin training epoch 1106
2023-02-11 10:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:14:27 | INFO | train_inner | epoch 1106:      1 / 5 loss=5.01, ppl=32.23, wps=434456, ups=0.1, wpb=4.20777e+06, bsz=8218.4, num_updates=5500, lr=0.000426401, gnorm=0.592, loss_scale=1, train_wall=661, gb_free=5.4, wall=52801
2023-02-11 10:14:52 | INFO | fairseq_cli.train | end of epoch 1106 (average epoch stats below)
2023-02-11 10:14:52 | INFO | train | epoch 1106 | loss 5.008 | ppl 32.19 | wps 502879 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5504 | lr 0.000426246 | gnorm 0.647 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52826
2023-02-11 10:14:52 | INFO | fairseq.trainer | begin training epoch 1107
2023-02-11 10:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:15:32 | INFO | fairseq_cli.train | end of epoch 1107 (average epoch stats below)
2023-02-11 10:15:32 | INFO | train | epoch 1107 | loss 5.003 | ppl 32.07 | wps 524700 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5509 | lr 0.000426053 | gnorm 0.582 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52866
2023-02-11 10:15:32 | INFO | fairseq.trainer | begin training epoch 1108
2023-02-11 10:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:16:13 | INFO | fairseq_cli.train | end of epoch 1108 (average epoch stats below)
2023-02-11 10:16:13 | INFO | train | epoch 1108 | loss 4.997 | ppl 31.94 | wps 511117 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5514 | lr 0.00042586 | gnorm 0.474 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52907
2023-02-11 10:16:14 | INFO | fairseq.trainer | begin training epoch 1109
2023-02-11 10:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:16:54 | INFO | fairseq_cli.train | end of epoch 1109 (average epoch stats below)
2023-02-11 10:16:54 | INFO | train | epoch 1109 | loss 4.999 | ppl 31.97 | wps 510001 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5519 | lr 0.000425667 | gnorm 0.571 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 52948
2023-02-11 10:16:55 | INFO | fairseq.trainer | begin training epoch 1110
2023-02-11 10:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:17:42 | INFO | valid | epoch 1110 | valid on 'valid' subset | loss 5.113 | ppl 34.61 | wps 0 | wpb 11230 | bsz 22 | num_updates 5524 | best_loss 5.113
2023-02-11 10:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1110 @ 5524 updates
2023-02-11 10:17:42 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1110.pt
2023-02-11 10:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1110.pt
2023-02-11 10:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1110.pt (epoch 1110 @ 5524 updates, score 5.113) (writing took 64.10794435700518 seconds)
2023-02-11 10:18:46 | INFO | fairseq_cli.train | end of epoch 1110 (average epoch stats below)
2023-02-11 10:18:46 | INFO | train | epoch 1110 | loss 5.005 | ppl 32.11 | wps 188134 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5524 | lr 0.000425474 | gnorm 0.737 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53060
2023-02-11 10:18:47 | INFO | fairseq.trainer | begin training epoch 1111
2023-02-11 10:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:19:33 | INFO | fairseq_cli.train | end of epoch 1111 (average epoch stats below)
2023-02-11 10:19:33 | INFO | train | epoch 1111 | loss 5.001 | ppl 32.01 | wps 453952 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5529 | lr 0.000425282 | gnorm 0.6 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53107
2023-02-11 10:19:33 | INFO | fairseq.trainer | begin training epoch 1112
2023-02-11 10:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:20:14 | INFO | fairseq_cli.train | end of epoch 1112 (average epoch stats below)
2023-02-11 10:20:14 | INFO | train | epoch 1112 | loss 4.994 | ppl 31.86 | wps 505844 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5534 | lr 0.00042509 | gnorm 0.497 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53148
2023-02-11 10:20:14 | INFO | fairseq.trainer | begin training epoch 1113
2023-02-11 10:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:20:55 | INFO | fairseq_cli.train | end of epoch 1113 (average epoch stats below)
2023-02-11 10:20:55 | INFO | train | epoch 1113 | loss 4.994 | ppl 31.87 | wps 510333 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5539 | lr 0.000424898 | gnorm 0.573 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53189
2023-02-11 10:20:56 | INFO | fairseq.trainer | begin training epoch 1114
2023-02-11 10:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:21:36 | INFO | fairseq_cli.train | end of epoch 1114 (average epoch stats below)
2023-02-11 10:21:36 | INFO | train | epoch 1114 | loss 4.99 | ppl 31.78 | wps 522294 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5544 | lr 0.000424706 | gnorm 0.53 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53230
2023-02-11 10:21:36 | INFO | fairseq.trainer | begin training epoch 1115
2023-02-11 10:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:22:17 | INFO | fairseq_cli.train | end of epoch 1115 (average epoch stats below)
2023-02-11 10:22:17 | INFO | train | epoch 1115 | loss 4.997 | ppl 31.94 | wps 503350 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5549 | lr 0.000424515 | gnorm 0.668 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53271
2023-02-11 10:22:18 | INFO | fairseq.trainer | begin training epoch 1116
2023-02-11 10:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:22:57 | INFO | fairseq_cli.train | end of epoch 1116 (average epoch stats below)
2023-02-11 10:22:57 | INFO | train | epoch 1116 | loss 4.991 | ppl 31.8 | wps 530292 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5554 | lr 0.000424323 | gnorm 0.563 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53311
2023-02-11 10:22:57 | INFO | fairseq.trainer | begin training epoch 1117
2023-02-11 10:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:23:38 | INFO | fairseq_cli.train | end of epoch 1117 (average epoch stats below)
2023-02-11 10:23:38 | INFO | train | epoch 1117 | loss 4.99 | ppl 31.77 | wps 508675 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5559 | lr 0.000424133 | gnorm 0.579 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53352
2023-02-11 10:23:39 | INFO | fairseq.trainer | begin training epoch 1118
2023-02-11 10:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:24:20 | INFO | fairseq_cli.train | end of epoch 1118 (average epoch stats below)
2023-02-11 10:24:20 | INFO | train | epoch 1118 | loss 4.99 | ppl 31.78 | wps 506348 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5564 | lr 0.000423942 | gnorm 0.596 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53394
2023-02-11 10:24:20 | INFO | fairseq.trainer | begin training epoch 1119
2023-02-11 10:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:25:01 | INFO | fairseq_cli.train | end of epoch 1119 (average epoch stats below)
2023-02-11 10:25:01 | INFO | train | epoch 1119 | loss 4.985 | ppl 31.67 | wps 510242 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5569 | lr 0.000423752 | gnorm 0.476 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53435
2023-02-11 10:25:01 | INFO | fairseq.trainer | begin training epoch 1120
2023-02-11 10:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:25:49 | INFO | valid | epoch 1120 | valid on 'valid' subset | loss 5.16 | ppl 35.74 | wps 0 | wpb 11230 | bsz 22 | num_updates 5574 | best_loss 5.113
2023-02-11 10:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1120 @ 5574 updates
2023-02-11 10:25:49 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1120.pt
2023-02-11 10:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1120.pt
2023-02-11 10:26:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1120.pt (epoch 1120 @ 5574 updates, score 5.16) (writing took 57.637955840997165 seconds)
2023-02-11 10:26:47 | INFO | fairseq_cli.train | end of epoch 1120 (average epoch stats below)
2023-02-11 10:26:47 | INFO | train | epoch 1120 | loss 4.989 | ppl 31.75 | wps 199383 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5574 | lr 0.000423562 | gnorm 0.626 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53541
2023-02-11 10:26:47 | INFO | fairseq.trainer | begin training epoch 1121
2023-02-11 10:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:27:33 | INFO | fairseq_cli.train | end of epoch 1121 (average epoch stats below)
2023-02-11 10:27:33 | INFO | train | epoch 1121 | loss 4.999 | ppl 31.98 | wps 450008 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5579 | lr 0.000423372 | gnorm 0.788 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53587
2023-02-11 10:27:34 | INFO | fairseq.trainer | begin training epoch 1122
2023-02-11 10:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:28:16 | INFO | fairseq_cli.train | end of epoch 1122 (average epoch stats below)
2023-02-11 10:28:16 | INFO | train | epoch 1122 | loss 4.996 | ppl 31.91 | wps 499097 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5584 | lr 0.000423182 | gnorm 0.7 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53630
2023-02-11 10:28:16 | INFO | fairseq.trainer | begin training epoch 1123
2023-02-11 10:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:28:56 | INFO | fairseq_cli.train | end of epoch 1123 (average epoch stats below)
2023-02-11 10:28:56 | INFO | train | epoch 1123 | loss 4.994 | ppl 31.87 | wps 515008 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5589 | lr 0.000422993 | gnorm 0.677 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53670
2023-02-11 10:28:57 | INFO | fairseq.trainer | begin training epoch 1124
2023-02-11 10:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:29:37 | INFO | fairseq_cli.train | end of epoch 1124 (average epoch stats below)
2023-02-11 10:29:37 | INFO | train | epoch 1124 | loss 4.99 | ppl 31.78 | wps 514483 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5594 | lr 0.000422804 | gnorm 0.61 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53711
2023-02-11 10:29:38 | INFO | fairseq.trainer | begin training epoch 1125
2023-02-11 10:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:30:19 | INFO | fairseq_cli.train | end of epoch 1125 (average epoch stats below)
2023-02-11 10:30:19 | INFO | train | epoch 1125 | loss 4.987 | ppl 31.71 | wps 505506 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5599 | lr 0.000422615 | gnorm 0.574 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53753
2023-02-11 10:30:19 | INFO | fairseq.trainer | begin training epoch 1126
2023-02-11 10:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:30:34 | INFO | train_inner | epoch 1126:      1 / 5 loss=4.994, ppl=31.88, wps=434864, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=5600, lr=0.000422577, gnorm=0.602, loss_scale=1, train_wall=662, gb_free=5.4, wall=53768
2023-02-11 10:30:59 | INFO | fairseq_cli.train | end of epoch 1126 (average epoch stats below)
2023-02-11 10:30:59 | INFO | train | epoch 1126 | loss 4.982 | ppl 31.59 | wps 522452 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5604 | lr 0.000422426 | gnorm 0.533 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53793
2023-02-11 10:30:59 | INFO | fairseq.trainer | begin training epoch 1127
2023-02-11 10:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:31:40 | INFO | fairseq_cli.train | end of epoch 1127 (average epoch stats below)
2023-02-11 10:31:40 | INFO | train | epoch 1127 | loss 4.98 | ppl 31.56 | wps 515427 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5609 | lr 0.000422238 | gnorm 0.495 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53834
2023-02-11 10:31:40 | INFO | fairseq.trainer | begin training epoch 1128
2023-02-11 10:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:32:22 | INFO | fairseq_cli.train | end of epoch 1128 (average epoch stats below)
2023-02-11 10:32:22 | INFO | train | epoch 1128 | loss 4.977 | ppl 31.5 | wps 503194 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5614 | lr 0.00042205 | gnorm 0.509 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53876
2023-02-11 10:32:22 | INFO | fairseq.trainer | begin training epoch 1129
2023-02-11 10:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:33:02 | INFO | fairseq_cli.train | end of epoch 1129 (average epoch stats below)
2023-02-11 10:33:02 | INFO | train | epoch 1129 | loss 4.978 | ppl 31.52 | wps 523982 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5619 | lr 0.000421862 | gnorm 0.604 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 53916
2023-02-11 10:33:02 | INFO | fairseq.trainer | begin training epoch 1130
2023-02-11 10:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:33:51 | INFO | valid | epoch 1130 | valid on 'valid' subset | loss 5.115 | ppl 34.66 | wps 0 | wpb 11230 | bsz 22 | num_updates 5624 | best_loss 5.113
2023-02-11 10:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1130 @ 5624 updates
2023-02-11 10:33:51 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1130.pt
2023-02-11 10:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1130.pt
2023-02-11 10:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1130.pt (epoch 1130 @ 5624 updates, score 5.115) (writing took 73.03194661799353 seconds)
2023-02-11 10:35:04 | INFO | fairseq_cli.train | end of epoch 1130 (average epoch stats below)
2023-02-11 10:35:04 | INFO | train | epoch 1130 | loss 4.988 | ppl 31.73 | wps 172294 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5624 | lr 0.000421675 | gnorm 0.791 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54038
2023-02-11 10:35:04 | INFO | fairseq.trainer | begin training epoch 1131
2023-02-11 10:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:35:50 | INFO | fairseq_cli.train | end of epoch 1131 (average epoch stats below)
2023-02-11 10:35:50 | INFO | train | epoch 1131 | loss 4.985 | ppl 31.66 | wps 457300 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5629 | lr 0.000421487 | gnorm 0.658 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54084
2023-02-11 10:35:50 | INFO | fairseq.trainer | begin training epoch 1132
2023-02-11 10:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:36:32 | INFO | fairseq_cli.train | end of epoch 1132 (average epoch stats below)
2023-02-11 10:36:32 | INFO | train | epoch 1132 | loss 4.981 | ppl 31.57 | wps 501917 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5634 | lr 0.0004213 | gnorm 0.55 | loss_scale 1 | train_wall 33 | gb_free 13.6 | wall 54126
2023-02-11 10:36:32 | INFO | fairseq.trainer | begin training epoch 1133
2023-02-11 10:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:37:14 | INFO | fairseq_cli.train | end of epoch 1133 (average epoch stats below)
2023-02-11 10:37:14 | INFO | train | epoch 1133 | loss 4.979 | ppl 31.54 | wps 502908 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5639 | lr 0.000421113 | gnorm 0.568 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54168
2023-02-11 10:37:14 | INFO | fairseq.trainer | begin training epoch 1134
2023-02-11 10:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:37:53 | INFO | fairseq_cli.train | end of epoch 1134 (average epoch stats below)
2023-02-11 10:37:53 | INFO | train | epoch 1134 | loss 4.974 | ppl 31.44 | wps 532150 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5644 | lr 0.000420927 | gnorm 0.488 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54207
2023-02-11 10:37:54 | INFO | fairseq.trainer | begin training epoch 1135
2023-02-11 10:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:38:35 | INFO | fairseq_cli.train | end of epoch 1135 (average epoch stats below)
2023-02-11 10:38:35 | INFO | train | epoch 1135 | loss 4.977 | ppl 31.5 | wps 503029 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5649 | lr 0.00042074 | gnorm 0.608 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54249
2023-02-11 10:38:35 | INFO | fairseq.trainer | begin training epoch 1136
2023-02-11 10:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:39:16 | INFO | fairseq_cli.train | end of epoch 1136 (average epoch stats below)
2023-02-11 10:39:16 | INFO | train | epoch 1136 | loss 4.978 | ppl 31.52 | wps 516852 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5654 | lr 0.000420554 | gnorm 0.637 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54290
2023-02-11 10:39:16 | INFO | fairseq.trainer | begin training epoch 1137
2023-02-11 10:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:39:56 | INFO | fairseq_cli.train | end of epoch 1137 (average epoch stats below)
2023-02-11 10:39:56 | INFO | train | epoch 1137 | loss 4.974 | ppl 31.43 | wps 519211 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5659 | lr 0.000420368 | gnorm 0.561 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54330
2023-02-11 10:39:57 | INFO | fairseq.trainer | begin training epoch 1138
2023-02-11 10:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:40:38 | INFO | fairseq_cli.train | end of epoch 1138 (average epoch stats below)
2023-02-11 10:40:38 | INFO | train | epoch 1138 | loss 4.973 | ppl 31.4 | wps 501658 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5664 | lr 0.000420183 | gnorm 0.524 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54372
2023-02-11 10:40:38 | INFO | fairseq.trainer | begin training epoch 1139
2023-02-11 10:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:41:19 | INFO | fairseq_cli.train | end of epoch 1139 (average epoch stats below)
2023-02-11 10:41:19 | INFO | train | epoch 1139 | loss 4.973 | ppl 31.4 | wps 512358 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5669 | lr 0.000419998 | gnorm 0.612 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54413
2023-02-11 10:41:20 | INFO | fairseq.trainer | begin training epoch 1140
2023-02-11 10:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:42:07 | INFO | valid | epoch 1140 | valid on 'valid' subset | loss 5.165 | ppl 35.88 | wps 0 | wpb 11230 | bsz 22 | num_updates 5674 | best_loss 5.113
2023-02-11 10:42:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1140 @ 5674 updates
2023-02-11 10:42:07 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1140.pt
2023-02-11 10:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1140.pt
2023-02-11 10:43:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1140.pt (epoch 1140 @ 5674 updates, score 5.165) (writing took 63.73474045001785 seconds)
2023-02-11 10:43:11 | INFO | fairseq_cli.train | end of epoch 1140 (average epoch stats below)
2023-02-11 10:43:11 | INFO | train | epoch 1140 | loss 4.975 | ppl 31.45 | wps 188569 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5674 | lr 0.000419812 | gnorm 0.614 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54525
2023-02-11 10:43:11 | INFO | fairseq.trainer | begin training epoch 1141
2023-02-11 10:43:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:44:00 | INFO | fairseq_cli.train | end of epoch 1141 (average epoch stats below)
2023-02-11 10:44:00 | INFO | train | epoch 1141 | loss 4.974 | ppl 31.43 | wps 428562 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5679 | lr 0.000419628 | gnorm 0.621 | loss_scale 1 | train_wall 33 | gb_free 13.6 | wall 54574
2023-02-11 10:44:00 | INFO | fairseq.trainer | begin training epoch 1142
2023-02-11 10:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:44:40 | INFO | fairseq_cli.train | end of epoch 1142 (average epoch stats below)
2023-02-11 10:44:40 | INFO | train | epoch 1142 | loss 4.974 | ppl 31.43 | wps 530115 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5684 | lr 0.000419443 | gnorm 0.634 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54614
2023-02-11 10:44:40 | INFO | fairseq.trainer | begin training epoch 1143
2023-02-11 10:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:45:20 | INFO | fairseq_cli.train | end of epoch 1143 (average epoch stats below)
2023-02-11 10:45:20 | INFO | train | epoch 1143 | loss 4.982 | ppl 31.6 | wps 517324 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5689 | lr 0.000419259 | gnorm 0.75 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54654
2023-02-11 10:45:21 | INFO | fairseq.trainer | begin training epoch 1144
2023-02-11 10:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:46:00 | INFO | fairseq_cli.train | end of epoch 1144 (average epoch stats below)
2023-02-11 10:46:00 | INFO | train | epoch 1144 | loss 4.973 | ppl 31.4 | wps 526906 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5694 | lr 0.000419075 | gnorm 0.569 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54694
2023-02-11 10:46:00 | INFO | fairseq.trainer | begin training epoch 1145
2023-02-11 10:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:46:42 | INFO | fairseq_cli.train | end of epoch 1145 (average epoch stats below)
2023-02-11 10:46:42 | INFO | train | epoch 1145 | loss 4.97 | ppl 31.35 | wps 503130 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5699 | lr 0.000418891 | gnorm 0.582 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54736
2023-02-11 10:46:42 | INFO | fairseq.trainer | begin training epoch 1146
2023-02-11 10:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:46:57 | INFO | train_inner | epoch 1146:      1 / 5 loss=4.977, ppl=31.5, wps=428020, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=5700, lr=0.000418854, gnorm=0.596, loss_scale=1, train_wall=662, gb_free=5.4, wall=54751
2023-02-11 10:47:22 | INFO | fairseq_cli.train | end of epoch 1146 (average epoch stats below)
2023-02-11 10:47:22 | INFO | train | epoch 1146 | loss 4.967 | ppl 31.27 | wps 523842 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5704 | lr 0.000418707 | gnorm 0.518 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54776
2023-02-11 10:47:22 | INFO | fairseq.trainer | begin training epoch 1147
2023-02-11 10:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:48:02 | INFO | fairseq_cli.train | end of epoch 1147 (average epoch stats below)
2023-02-11 10:48:02 | INFO | train | epoch 1147 | loss 4.967 | ppl 31.28 | wps 521357 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5709 | lr 0.000418524 | gnorm 0.588 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54817
2023-02-11 10:48:03 | INFO | fairseq.trainer | begin training epoch 1148
2023-02-11 10:48:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:48:45 | INFO | fairseq_cli.train | end of epoch 1148 (average epoch stats below)
2023-02-11 10:48:45 | INFO | train | epoch 1148 | loss 4.968 | ppl 31.3 | wps 496810 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5714 | lr 0.00041834 | gnorm 0.638 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54859
2023-02-11 10:48:45 | INFO | fairseq.trainer | begin training epoch 1149
2023-02-11 10:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:49:26 | INFO | fairseq_cli.train | end of epoch 1149 (average epoch stats below)
2023-02-11 10:49:26 | INFO | train | epoch 1149 | loss 4.972 | ppl 31.38 | wps 510450 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5719 | lr 0.000418158 | gnorm 0.659 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 54900
2023-02-11 10:49:26 | INFO | fairseq.trainer | begin training epoch 1150
2023-02-11 10:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:50:14 | INFO | valid | epoch 1150 | valid on 'valid' subset | loss 5.126 | ppl 34.91 | wps 0 | wpb 11230 | bsz 22 | num_updates 5724 | best_loss 5.113
2023-02-11 10:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1150 @ 5724 updates
2023-02-11 10:50:14 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1150.pt
2023-02-11 10:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1150.pt
2023-02-11 10:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1150.pt (epoch 1150 @ 5724 updates, score 5.126) (writing took 56.23258900898509 seconds)
2023-02-11 10:51:10 | INFO | fairseq_cli.train | end of epoch 1150 (average epoch stats below)
2023-02-11 10:51:10 | INFO | train | epoch 1150 | loss 4.967 | ppl 31.29 | wps 202302 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5724 | lr 0.000417975 | gnorm 0.586 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55004
2023-02-11 10:51:10 | INFO | fairseq.trainer | begin training epoch 1151
2023-02-11 10:51:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:52:03 | INFO | fairseq_cli.train | end of epoch 1151 (average epoch stats below)
2023-02-11 10:52:03 | INFO | train | epoch 1151 | loss 4.962 | ppl 31.16 | wps 400519 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5729 | lr 0.000417792 | gnorm 0.49 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55057
2023-02-11 10:52:03 | INFO | fairseq.trainer | begin training epoch 1152
2023-02-11 10:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:52:46 | INFO | fairseq_cli.train | end of epoch 1152 (average epoch stats below)
2023-02-11 10:52:46 | INFO | train | epoch 1152 | loss 4.961 | ppl 31.15 | wps 484799 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5734 | lr 0.00041761 | gnorm 0.514 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55100
2023-02-11 10:52:46 | INFO | fairseq.trainer | begin training epoch 1153
2023-02-11 10:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:53:26 | INFO | fairseq_cli.train | end of epoch 1153 (average epoch stats below)
2023-02-11 10:53:26 | INFO | train | epoch 1153 | loss 4.97 | ppl 31.35 | wps 529349 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5739 | lr 0.000417428 | gnorm 0.688 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55140
2023-02-11 10:53:26 | INFO | fairseq.trainer | begin training epoch 1154
2023-02-11 10:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-02-11 10:54:06 | INFO | fairseq_cli.train | end of epoch 1154 (average epoch stats below)
2023-02-11 10:54:06 | INFO | train | epoch 1154 | loss 4.969 | ppl 31.32 | wps 386818 | ups 0.1 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 5743 | lr 0.000417283 | gnorm 0.657 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55180
2023-02-11 10:54:07 | INFO | fairseq.trainer | begin training epoch 1155
2023-02-11 10:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:54:49 | INFO | fairseq_cli.train | end of epoch 1155 (average epoch stats below)
2023-02-11 10:54:49 | INFO | train | epoch 1155 | loss 4.968 | ppl 31.3 | wps 497705 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5748 | lr 0.000417101 | gnorm 0.622 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55223
2023-02-11 10:54:49 | INFO | fairseq.trainer | begin training epoch 1156
2023-02-11 10:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:55:28 | INFO | fairseq_cli.train | end of epoch 1156 (average epoch stats below)
2023-02-11 10:55:28 | INFO | train | epoch 1156 | loss 4.968 | ppl 31.29 | wps 535325 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5753 | lr 0.00041692 | gnorm 0.651 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55262
2023-02-11 10:55:28 | INFO | fairseq.trainer | begin training epoch 1157
2023-02-11 10:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:56:09 | INFO | fairseq_cli.train | end of epoch 1157 (average epoch stats below)
2023-02-11 10:56:09 | INFO | train | epoch 1157 | loss 4.963 | ppl 31.18 | wps 512665 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5758 | lr 0.000416739 | gnorm 0.591 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55303
2023-02-11 10:56:09 | INFO | fairseq.trainer | begin training epoch 1158
2023-02-11 10:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:56:52 | INFO | fairseq_cli.train | end of epoch 1158 (average epoch stats below)
2023-02-11 10:56:52 | INFO | train | epoch 1158 | loss 4.961 | ppl 31.15 | wps 494516 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5763 | lr 0.000416558 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55346
2023-02-11 10:56:52 | INFO | fairseq.trainer | begin training epoch 1159
2023-02-11 10:56:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:57:31 | INFO | fairseq_cli.train | end of epoch 1159 (average epoch stats below)
2023-02-11 10:57:31 | INFO | train | epoch 1159 | loss 4.957 | ppl 31.07 | wps 528387 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5768 | lr 0.000416378 | gnorm 0.552 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55385
2023-02-11 10:57:32 | INFO | fairseq.trainer | begin training epoch 1160
2023-02-11 10:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 10:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 10:58:21 | INFO | valid | epoch 1160 | valid on 'valid' subset | loss 5.135 | ppl 35.13 | wps 0 | wpb 11230 | bsz 22 | num_updates 5773 | best_loss 5.113
2023-02-11 10:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1160 @ 5773 updates
2023-02-11 10:58:21 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1160.pt
2023-02-11 10:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1160.pt
2023-02-11 10:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1160.pt (epoch 1160 @ 5773 updates, score 5.135) (writing took 70.42549088399392 seconds)
2023-02-11 10:59:31 | INFO | fairseq_cli.train | end of epoch 1160 (average epoch stats below)
2023-02-11 10:59:31 | INFO | train | epoch 1160 | loss 4.955 | ppl 31.01 | wps 175748 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5773 | lr 0.000416197 | gnorm 0.53 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55505
2023-02-11 10:59:31 | INFO | fairseq.trainer | begin training epoch 1161
2023-02-11 10:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:00:20 | INFO | fairseq_cli.train | end of epoch 1161 (average epoch stats below)
2023-02-11 11:00:20 | INFO | train | epoch 1161 | loss 4.955 | ppl 31.02 | wps 433290 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5778 | lr 0.000416017 | gnorm 0.586 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55554
2023-02-11 11:00:20 | INFO | fairseq.trainer | begin training epoch 1162
2023-02-11 11:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:01:02 | INFO | fairseq_cli.train | end of epoch 1162 (average epoch stats below)
2023-02-11 11:01:02 | INFO | train | epoch 1162 | loss 4.958 | ppl 31.09 | wps 496337 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5783 | lr 0.000415837 | gnorm 0.667 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 55596
2023-02-11 11:01:02 | INFO | fairseq.trainer | begin training epoch 1163
2023-02-11 11:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:01:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 11:01:43 | INFO | fairseq_cli.train | end of epoch 1163 (average epoch stats below)
2023-02-11 11:01:43 | INFO | train | epoch 1163 | loss 4.962 | ppl 31.17 | wps 386835 | ups 0.1 | wpb 3.94778e+06 | bsz 7710.5 | num_updates 5787 | lr 0.000415694 | gnorm 0.774 | loss_scale 0.5 | train_wall 33 | gb_free 5.4 | wall 55637
2023-02-11 11:01:43 | INFO | fairseq.trainer | begin training epoch 1164
2023-02-11 11:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:02:23 | INFO | fairseq_cli.train | end of epoch 1164 (average epoch stats below)
2023-02-11 11:02:23 | INFO | train | epoch 1164 | loss 4.971 | ppl 31.36 | wps 525127 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5792 | lr 0.000415514 | gnorm 0.819 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55677
2023-02-11 11:02:23 | INFO | fairseq.trainer | begin training epoch 1165
2023-02-11 11:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:03:05 | INFO | fairseq_cli.train | end of epoch 1165 (average epoch stats below)
2023-02-11 11:03:05 | INFO | train | epoch 1165 | loss 4.965 | ppl 31.23 | wps 497882 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5797 | lr 0.000415335 | gnorm 0.64 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55719
2023-02-11 11:03:05 | INFO | fairseq.trainer | begin training epoch 1166
2023-02-11 11:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:03:37 | INFO | train_inner | epoch 1166:      3 / 5 loss=4.964, ppl=31.21, wps=420576, ups=0.1, wpb=4.20595e+06, bsz=8214.8, num_updates=5800, lr=0.000415227, gnorm=0.616, loss_scale=0.5, train_wall=677, gb_free=5.4, wall=55751
2023-02-11 11:03:46 | INFO | fairseq_cli.train | end of epoch 1166 (average epoch stats below)
2023-02-11 11:03:46 | INFO | train | epoch 1166 | loss 4.958 | ppl 31.08 | wps 519663 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5802 | lr 0.000415156 | gnorm 0.572 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55760
2023-02-11 11:03:46 | INFO | fairseq.trainer | begin training epoch 1167
2023-02-11 11:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:04:26 | INFO | fairseq_cli.train | end of epoch 1167 (average epoch stats below)
2023-02-11 11:04:26 | INFO | train | epoch 1167 | loss 4.954 | ppl 30.99 | wps 525445 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5807 | lr 0.000414977 | gnorm 0.538 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55800
2023-02-11 11:04:26 | INFO | fairseq.trainer | begin training epoch 1168
2023-02-11 11:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:05:08 | INFO | fairseq_cli.train | end of epoch 1168 (average epoch stats below)
2023-02-11 11:05:08 | INFO | train | epoch 1168 | loss 4.95 | ppl 30.92 | wps 494480 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5812 | lr 0.000414799 | gnorm 0.539 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55842
2023-02-11 11:05:08 | INFO | fairseq.trainer | begin training epoch 1169
2023-02-11 11:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:05:49 | INFO | fairseq_cli.train | end of epoch 1169 (average epoch stats below)
2023-02-11 11:05:49 | INFO | train | epoch 1169 | loss 4.951 | ppl 30.93 | wps 519088 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5817 | lr 0.00041462 | gnorm 0.603 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55883
2023-02-11 11:05:49 | INFO | fairseq.trainer | begin training epoch 1170
2023-02-11 11:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:06:37 | INFO | valid | epoch 1170 | valid on 'valid' subset | loss 5.127 | ppl 34.94 | wps 0 | wpb 11230 | bsz 22 | num_updates 5822 | best_loss 5.113
2023-02-11 11:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1170 @ 5822 updates
2023-02-11 11:06:37 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1170.pt
2023-02-11 11:06:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1170.pt
2023-02-11 11:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1170.pt (epoch 1170 @ 5822 updates, score 5.127) (writing took 64.38575045601465 seconds)
2023-02-11 11:07:42 | INFO | fairseq_cli.train | end of epoch 1170 (average epoch stats below)
2023-02-11 11:07:42 | INFO | train | epoch 1170 | loss 4.949 | ppl 30.88 | wps 186358 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5822 | lr 0.000414442 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 55996
2023-02-11 11:07:42 | INFO | fairseq.trainer | begin training epoch 1171
2023-02-11 11:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:08:32 | INFO | fairseq_cli.train | end of epoch 1171 (average epoch stats below)
2023-02-11 11:08:32 | INFO | train | epoch 1171 | loss 4.947 | ppl 30.84 | wps 418719 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5827 | lr 0.000414264 | gnorm 0.497 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56046
2023-02-11 11:08:32 | INFO | fairseq.trainer | begin training epoch 1172
2023-02-11 11:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:09:14 | INFO | fairseq_cli.train | end of epoch 1172 (average epoch stats below)
2023-02-11 11:09:14 | INFO | train | epoch 1172 | loss 4.945 | ppl 30.8 | wps 499530 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5832 | lr 0.000414087 | gnorm 0.495 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56088
2023-02-11 11:09:14 | INFO | fairseq.trainer | begin training epoch 1173
2023-02-11 11:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:09:54 | INFO | fairseq_cli.train | end of epoch 1173 (average epoch stats below)
2023-02-11 11:09:54 | INFO | train | epoch 1173 | loss 4.943 | ppl 30.77 | wps 518695 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5837 | lr 0.000413909 | gnorm 0.538 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56128
2023-02-11 11:09:55 | INFO | fairseq.trainer | begin training epoch 1174
2023-02-11 11:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:10:34 | INFO | fairseq_cli.train | end of epoch 1174 (average epoch stats below)
2023-02-11 11:10:34 | INFO | train | epoch 1174 | loss 4.951 | ppl 30.94 | wps 528661 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5842 | lr 0.000413732 | gnorm 0.689 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56168
2023-02-11 11:10:35 | INFO | fairseq.trainer | begin training epoch 1175
2023-02-11 11:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:11:17 | INFO | fairseq_cli.train | end of epoch 1175 (average epoch stats below)
2023-02-11 11:11:17 | INFO | train | epoch 1175 | loss 4.952 | ppl 30.95 | wps 493734 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5847 | lr 0.000413555 | gnorm 0.725 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56211
2023-02-11 11:11:17 | INFO | fairseq.trainer | begin training epoch 1176
2023-02-11 11:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:11:57 | INFO | fairseq_cli.train | end of epoch 1176 (average epoch stats below)
2023-02-11 11:11:57 | INFO | train | epoch 1176 | loss 4.951 | ppl 30.93 | wps 522938 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5852 | lr 0.000413378 | gnorm 0.697 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56251
2023-02-11 11:11:57 | INFO | fairseq.trainer | begin training epoch 1177
2023-02-11 11:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:12:38 | INFO | fairseq_cli.train | end of epoch 1177 (average epoch stats below)
2023-02-11 11:12:38 | INFO | train | epoch 1177 | loss 4.952 | ppl 30.95 | wps 517750 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5857 | lr 0.000413202 | gnorm 0.711 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56292
2023-02-11 11:12:38 | INFO | fairseq.trainer | begin training epoch 1178
2023-02-11 11:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:13:19 | INFO | fairseq_cli.train | end of epoch 1178 (average epoch stats below)
2023-02-11 11:13:19 | INFO | train | epoch 1178 | loss 4.95 | ppl 30.92 | wps 504561 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5862 | lr 0.000413026 | gnorm 0.698 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56333
2023-02-11 11:13:20 | INFO | fairseq.trainer | begin training epoch 1179
2023-02-11 11:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:14:00 | INFO | fairseq_cli.train | end of epoch 1179 (average epoch stats below)
2023-02-11 11:14:00 | INFO | train | epoch 1179 | loss 4.943 | ppl 30.77 | wps 512489 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5867 | lr 0.00041285 | gnorm 0.581 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56374
2023-02-11 11:14:01 | INFO | fairseq.trainer | begin training epoch 1180
2023-02-11 11:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:14:48 | INFO | valid | epoch 1180 | valid on 'valid' subset | loss 5.151 | ppl 35.53 | wps 0 | wpb 11230 | bsz 22 | num_updates 5872 | best_loss 5.113
2023-02-11 11:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1180 @ 5872 updates
2023-02-11 11:14:48 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1180.pt
2023-02-11 11:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1180.pt
2023-02-11 11:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1180.pt (epoch 1180 @ 5872 updates, score 5.151) (writing took 47.47127104201354 seconds)
2023-02-11 11:15:36 | INFO | fairseq_cli.train | end of epoch 1180 (average epoch stats below)
2023-02-11 11:15:36 | INFO | train | epoch 1180 | loss 4.943 | ppl 30.75 | wps 220526 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5872 | lr 0.000412674 | gnorm 0.596 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56470
2023-02-11 11:15:36 | INFO | fairseq.trainer | begin training epoch 1181
2023-02-11 11:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:16:35 | INFO | fairseq_cli.train | end of epoch 1181 (average epoch stats below)
2023-02-11 11:16:35 | INFO | train | epoch 1181 | loss 4.94 | ppl 30.69 | wps 354980 | ups 0.08 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5877 | lr 0.000412498 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56529
2023-02-11 11:16:35 | INFO | fairseq.trainer | begin training epoch 1182
2023-02-11 11:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:17:15 | INFO | fairseq_cli.train | end of epoch 1182 (average epoch stats below)
2023-02-11 11:17:15 | INFO | train | epoch 1182 | loss 4.936 | ppl 30.62 | wps 525956 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5882 | lr 0.000412323 | gnorm 0.478 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56569
2023-02-11 11:17:15 | INFO | fairseq.trainer | begin training epoch 1183
2023-02-11 11:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:17:55 | INFO | fairseq_cli.train | end of epoch 1183 (average epoch stats below)
2023-02-11 11:17:55 | INFO | train | epoch 1183 | loss 4.939 | ppl 30.67 | wps 526413 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5887 | lr 0.000412148 | gnorm 0.58 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56609
2023-02-11 11:17:55 | INFO | fairseq.trainer | begin training epoch 1184
2023-02-11 11:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:18:37 | INFO | fairseq_cli.train | end of epoch 1184 (average epoch stats below)
2023-02-11 11:18:37 | INFO | train | epoch 1184 | loss 4.94 | ppl 30.7 | wps 504346 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5892 | lr 0.000411973 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56651
2023-02-11 11:18:37 | INFO | fairseq.trainer | begin training epoch 1185
2023-02-11 11:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:19:17 | INFO | fairseq_cli.train | end of epoch 1185 (average epoch stats below)
2023-02-11 11:19:17 | INFO | train | epoch 1185 | loss 4.934 | ppl 30.58 | wps 517713 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5897 | lr 0.000411798 | gnorm 0.501 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56691
2023-02-11 11:19:18 | INFO | fairseq.trainer | begin training epoch 1186
2023-02-11 11:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:19:49 | INFO | train_inner | epoch 1186:      3 / 5 loss=4.946, ppl=30.81, wps=432618, ups=0.1, wpb=4.20736e+06, bsz=8217.6, num_updates=5900, lr=0.000411693, gnorm=0.585, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=56723
2023-02-11 11:19:58 | INFO | fairseq_cli.train | end of epoch 1186 (average epoch stats below)
2023-02-11 11:19:58 | INFO | train | epoch 1186 | loss 4.934 | ppl 30.57 | wps 515257 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5902 | lr 0.000411624 | gnorm 0.514 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56732
2023-02-11 11:19:58 | INFO | fairseq.trainer | begin training epoch 1187
2023-02-11 11:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:20:40 | INFO | fairseq_cli.train | end of epoch 1187 (average epoch stats below)
2023-02-11 11:20:40 | INFO | train | epoch 1187 | loss 4.935 | ppl 30.59 | wps 508026 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5907 | lr 0.000411449 | gnorm 0.577 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56774
2023-02-11 11:20:40 | INFO | fairseq.trainer | begin training epoch 1188
2023-02-11 11:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:21:19 | INFO | fairseq_cli.train | end of epoch 1188 (average epoch stats below)
2023-02-11 11:21:19 | INFO | train | epoch 1188 | loss 4.936 | ppl 30.61 | wps 531082 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5912 | lr 0.000411275 | gnorm 0.646 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56813
2023-02-11 11:21:20 | INFO | fairseq.trainer | begin training epoch 1189
2023-02-11 11:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:22:00 | INFO | fairseq_cli.train | end of epoch 1189 (average epoch stats below)
2023-02-11 11:22:00 | INFO | train | epoch 1189 | loss 4.939 | ppl 30.68 | wps 509986 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5917 | lr 0.000411102 | gnorm 0.687 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56854
2023-02-11 11:22:01 | INFO | fairseq.trainer | begin training epoch 1190
2023-02-11 11:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:22:50 | INFO | valid | epoch 1190 | valid on 'valid' subset | loss 5.172 | ppl 36.05 | wps 0 | wpb 11230 | bsz 22 | num_updates 5922 | best_loss 5.113
2023-02-11 11:22:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1190 @ 5922 updates
2023-02-11 11:22:50 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1190.pt
2023-02-11 11:22:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1190.pt
2023-02-11 11:24:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1190.pt (epoch 1190 @ 5922 updates, score 5.172) (writing took 73.27523471598397 seconds)
2023-02-11 11:24:03 | INFO | fairseq_cli.train | end of epoch 1190 (average epoch stats below)
2023-02-11 11:24:03 | INFO | train | epoch 1190 | loss 4.936 | ppl 30.61 | wps 171394 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5922 | lr 0.000410928 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 56977
2023-02-11 11:24:04 | INFO | fairseq.trainer | begin training epoch 1191
2023-02-11 11:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:25:31 | INFO | fairseq_cli.train | end of epoch 1191 (average epoch stats below)
2023-02-11 11:25:31 | INFO | train | epoch 1191 | loss 4.94 | ppl 30.7 | wps 238934 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5927 | lr 0.000410755 | gnorm 0.662 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57065
2023-02-11 11:25:32 | INFO | fairseq.trainer | begin training epoch 1192
2023-02-11 11:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:26:12 | INFO | fairseq_cli.train | end of epoch 1192 (average epoch stats below)
2023-02-11 11:26:12 | INFO | train | epoch 1192 | loss 4.938 | ppl 30.65 | wps 515078 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5932 | lr 0.000410582 | gnorm 0.606 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57106
2023-02-11 11:26:12 | INFO | fairseq.trainer | begin training epoch 1193
2023-02-11 11:26:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:26:53 | INFO | fairseq_cli.train | end of epoch 1193 (average epoch stats below)
2023-02-11 11:26:53 | INFO | train | epoch 1193 | loss 4.935 | ppl 30.59 | wps 507399 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5937 | lr 0.000410409 | gnorm 0.628 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57148
2023-02-11 11:26:54 | INFO | fairseq.trainer | begin training epoch 1194
2023-02-11 11:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:27:34 | INFO | fairseq_cli.train | end of epoch 1194 (average epoch stats below)
2023-02-11 11:27:35 | INFO | train | epoch 1194 | loss 4.936 | ppl 30.61 | wps 512836 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5942 | lr 0.000410236 | gnorm 0.663 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57189
2023-02-11 11:27:35 | INFO | fairseq.trainer | begin training epoch 1195
2023-02-11 11:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:28:15 | INFO | fairseq_cli.train | end of epoch 1195 (average epoch stats below)
2023-02-11 11:28:15 | INFO | train | epoch 1195 | loss 4.936 | ppl 30.62 | wps 523229 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5947 | lr 0.000410063 | gnorm 0.679 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57229
2023-02-11 11:28:15 | INFO | fairseq.trainer | begin training epoch 1196
2023-02-11 11:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:28:55 | INFO | fairseq_cli.train | end of epoch 1196 (average epoch stats below)
2023-02-11 11:28:55 | INFO | train | epoch 1196 | loss 4.932 | ppl 30.53 | wps 515793 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5952 | lr 0.000409891 | gnorm 0.611 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57270
2023-02-11 11:28:56 | INFO | fairseq.trainer | begin training epoch 1197
2023-02-11 11:28:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:29:38 | INFO | fairseq_cli.train | end of epoch 1197 (average epoch stats below)
2023-02-11 11:29:38 | INFO | train | epoch 1197 | loss 4.93 | ppl 30.49 | wps 498450 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5957 | lr 0.000409719 | gnorm 0.599 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57312
2023-02-11 11:29:38 | INFO | fairseq.trainer | begin training epoch 1198
2023-02-11 11:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:30:18 | INFO | fairseq_cli.train | end of epoch 1198 (average epoch stats below)
2023-02-11 11:30:18 | INFO | train | epoch 1198 | loss 4.927 | ppl 30.41 | wps 524074 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5962 | lr 0.000409547 | gnorm 0.515 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57352
2023-02-11 11:30:18 | INFO | fairseq.trainer | begin training epoch 1199
2023-02-11 11:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:30:59 | INFO | fairseq_cli.train | end of epoch 1199 (average epoch stats below)
2023-02-11 11:30:59 | INFO | train | epoch 1199 | loss 4.93 | ppl 30.49 | wps 515711 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5967 | lr 0.000409376 | gnorm 0.658 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57393
2023-02-11 11:30:59 | INFO | fairseq.trainer | begin training epoch 1200
2023-02-11 11:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:31:47 | INFO | valid | epoch 1200 | valid on 'valid' subset | loss 5.157 | ppl 35.69 | wps 0 | wpb 11230 | bsz 22 | num_updates 5972 | best_loss 5.113
2023-02-11 11:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1200 @ 5972 updates
2023-02-11 11:31:47 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1200.pt
2023-02-11 11:31:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1200.pt
2023-02-11 11:32:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1200.pt (epoch 1200 @ 5972 updates, score 5.157) (writing took 71.41410139598884 seconds)
2023-02-11 11:32:58 | INFO | fairseq_cli.train | end of epoch 1200 (average epoch stats below)
2023-02-11 11:32:58 | INFO | train | epoch 1200 | loss 4.931 | ppl 30.5 | wps 175664 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5972 | lr 0.000409204 | gnorm 0.665 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57512
2023-02-11 11:32:59 | INFO | fairseq.trainer | begin training epoch 1201
2023-02-11 11:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:33:57 | INFO | fairseq_cli.train | end of epoch 1201 (average epoch stats below)
2023-02-11 11:33:57 | INFO | train | epoch 1201 | loss 4.93 | ppl 30.49 | wps 360510 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5977 | lr 0.000409033 | gnorm 0.653 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57571
2023-02-11 11:33:57 | INFO | fairseq.trainer | begin training epoch 1202
2023-02-11 11:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:34:39 | INFO | fairseq_cli.train | end of epoch 1202 (average epoch stats below)
2023-02-11 11:34:39 | INFO | train | epoch 1202 | loss 4.926 | ppl 30.41 | wps 498133 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5982 | lr 0.000408862 | gnorm 0.558 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57613
2023-02-11 11:34:39 | INFO | fairseq.trainer | begin training epoch 1203
2023-02-11 11:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:35:20 | INFO | fairseq_cli.train | end of epoch 1203 (average epoch stats below)
2023-02-11 11:35:20 | INFO | train | epoch 1203 | loss 4.927 | ppl 30.41 | wps 516436 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5987 | lr 0.000408691 | gnorm 0.61 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57654
2023-02-11 11:35:20 | INFO | fairseq.trainer | begin training epoch 1204
2023-02-11 11:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:36:01 | INFO | fairseq_cli.train | end of epoch 1204 (average epoch stats below)
2023-02-11 11:36:01 | INFO | train | epoch 1204 | loss 4.927 | ppl 30.42 | wps 505278 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5992 | lr 0.000408521 | gnorm 0.633 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57695
2023-02-11 11:36:02 | INFO | fairseq.trainer | begin training epoch 1205
2023-02-11 11:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:36:42 | INFO | fairseq_cli.train | end of epoch 1205 (average epoch stats below)
2023-02-11 11:36:42 | INFO | train | epoch 1205 | loss 4.926 | ppl 30.4 | wps 514223 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 5997 | lr 0.00040835 | gnorm 0.624 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57736
2023-02-11 11:36:43 | INFO | fairseq.trainer | begin training epoch 1206
2023-02-11 11:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:37:14 | INFO | train_inner | epoch 1206:      3 / 5 loss=4.932, ppl=30.53, wps=402907, ups=0.1, wpb=4.20696e+06, bsz=8216.8, num_updates=6000, lr=0.000408248, gnorm=0.623, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=57768
2023-02-11 11:37:22 | INFO | fairseq_cli.train | end of epoch 1206 (average epoch stats below)
2023-02-11 11:37:22 | INFO | train | epoch 1206 | loss 4.925 | ppl 30.38 | wps 524002 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6002 | lr 0.00040818 | gnorm 0.642 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57776
2023-02-11 11:37:23 | INFO | fairseq.trainer | begin training epoch 1207
2023-02-11 11:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:38:03 | INFO | fairseq_cli.train | end of epoch 1207 (average epoch stats below)
2023-02-11 11:38:03 | INFO | train | epoch 1207 | loss 4.923 | ppl 30.34 | wps 513694 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6007 | lr 0.00040801 | gnorm 0.593 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57817
2023-02-11 11:38:04 | INFO | fairseq.trainer | begin training epoch 1208
2023-02-11 11:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:38:45 | INFO | fairseq_cli.train | end of epoch 1208 (average epoch stats below)
2023-02-11 11:38:45 | INFO | train | epoch 1208 | loss 4.921 | ppl 30.3 | wps 504340 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6012 | lr 0.000407841 | gnorm 0.564 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57859
2023-02-11 11:38:45 | INFO | fairseq.trainer | begin training epoch 1209
2023-02-11 11:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:39:25 | INFO | fairseq_cli.train | end of epoch 1209 (average epoch stats below)
2023-02-11 11:39:25 | INFO | train | epoch 1209 | loss 4.92 | ppl 30.28 | wps 519444 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6017 | lr 0.000407671 | gnorm 0.578 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 57900
2023-02-11 11:39:26 | INFO | fairseq.trainer | begin training epoch 1210
2023-02-11 11:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:40:14 | INFO | valid | epoch 1210 | valid on 'valid' subset | loss 5.129 | ppl 35 | wps 0 | wpb 11230 | bsz 22 | num_updates 6022 | best_loss 5.113
2023-02-11 11:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1210 @ 6022 updates
2023-02-11 11:40:14 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1210.pt
2023-02-11 11:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1210.pt
2023-02-11 11:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1210.pt (epoch 1210 @ 6022 updates, score 5.129) (writing took 60.731753253989154 seconds)
2023-02-11 11:41:15 | INFO | fairseq_cli.train | end of epoch 1210 (average epoch stats below)
2023-02-11 11:41:15 | INFO | train | epoch 1210 | loss 4.923 | ppl 30.34 | wps 192598 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6022 | lr 0.000407502 | gnorm 0.683 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 58009
2023-02-11 11:41:15 | INFO | fairseq.trainer | begin training epoch 1211
2023-02-11 11:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:42:51 | INFO | fairseq_cli.train | end of epoch 1211 (average epoch stats below)
2023-02-11 11:42:51 | INFO | train | epoch 1211 | loss 4.922 | ppl 30.31 | wps 218899 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6027 | lr 0.000407333 | gnorm 0.635 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 58105
2023-02-11 11:42:51 | INFO | fairseq.trainer | begin training epoch 1212
2023-02-11 11:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:43:32 | INFO | fairseq_cli.train | end of epoch 1212 (average epoch stats below)
2023-02-11 11:43:32 | INFO | train | epoch 1212 | loss 4.921 | ppl 30.29 | wps 516391 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6032 | lr 0.000407164 | gnorm 0.62 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 58146
2023-02-11 11:43:32 | INFO | fairseq.trainer | begin training epoch 1213
2023-02-11 11:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:44:13 | INFO | fairseq_cli.train | end of epoch 1213 (average epoch stats below)
2023-02-11 11:44:13 | INFO | train | epoch 1213 | loss 4.916 | ppl 30.19 | wps 511464 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6037 | lr 0.000406995 | gnorm 0.491 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 58187
2023-02-11 11:44:13 | INFO | fairseq.trainer | begin training epoch 1214
2023-02-11 11:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:44:54 | INFO | fairseq_cli.train | end of epoch 1214 (average epoch stats below)
2023-02-11 11:44:54 | INFO | train | epoch 1214 | loss 4.916 | ppl 30.19 | wps 504823 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6042 | lr 0.000406827 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58228
2023-02-11 11:44:55 | INFO | fairseq.trainer | begin training epoch 1215
2023-02-11 11:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:45:34 | INFO | fairseq_cli.train | end of epoch 1215 (average epoch stats below)
2023-02-11 11:45:34 | INFO | train | epoch 1215 | loss 4.926 | ppl 30.4 | wps 524923 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6047 | lr 0.000406659 | gnorm 0.81 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58268
2023-02-11 11:45:35 | INFO | fairseq.trainer | begin training epoch 1216
2023-02-11 11:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:46:15 | INFO | fairseq_cli.train | end of epoch 1216 (average epoch stats below)
2023-02-11 11:46:15 | INFO | train | epoch 1216 | loss 4.921 | ppl 30.3 | wps 512928 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6052 | lr 0.000406491 | gnorm 0.637 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58309
2023-02-11 11:46:16 | INFO | fairseq.trainer | begin training epoch 1217
2023-02-11 11:46:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:46:57 | INFO | fairseq_cli.train | end of epoch 1217 (average epoch stats below)
2023-02-11 11:46:57 | INFO | train | epoch 1217 | loss 4.92 | ppl 30.28 | wps 505256 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6057 | lr 0.000406323 | gnorm 0.623 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58351
2023-02-11 11:46:57 | INFO | fairseq.trainer | begin training epoch 1218
2023-02-11 11:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:47:37 | INFO | fairseq_cli.train | end of epoch 1218 (average epoch stats below)
2023-02-11 11:47:37 | INFO | train | epoch 1218 | loss 4.917 | ppl 30.22 | wps 526497 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6062 | lr 0.000406155 | gnorm 0.602 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58391
2023-02-11 11:47:37 | INFO | fairseq.trainer | begin training epoch 1219
2023-02-11 11:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:48:19 | INFO | fairseq_cli.train | end of epoch 1219 (average epoch stats below)
2023-02-11 11:48:19 | INFO | train | epoch 1219 | loss 4.913 | ppl 30.13 | wps 504712 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6067 | lr 0.000405988 | gnorm 0.524 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58433
2023-02-11 11:48:19 | INFO | fairseq.trainer | begin training epoch 1220
2023-02-11 11:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:49:06 | INFO | valid | epoch 1220 | valid on 'valid' subset | loss 5.146 | ppl 35.4 | wps 0 | wpb 11230 | bsz 22 | num_updates 6072 | best_loss 5.113
2023-02-11 11:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1220 @ 6072 updates
2023-02-11 11:49:06 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1220.pt
2023-02-11 11:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1220.pt
2023-02-11 11:50:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1220.pt (epoch 1220 @ 6072 updates, score 5.146) (writing took 65.16041828400921 seconds)
2023-02-11 11:50:11 | INFO | fairseq_cli.train | end of epoch 1220 (average epoch stats below)
2023-02-11 11:50:11 | INFO | train | epoch 1220 | loss 4.912 | ppl 30.1 | wps 186882 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6072 | lr 0.000405821 | gnorm 0.539 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58545
2023-02-11 11:50:12 | INFO | fairseq.trainer | begin training epoch 1221
2023-02-11 11:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:51:01 | INFO | fairseq_cli.train | end of epoch 1221 (average epoch stats below)
2023-02-11 11:51:01 | INFO | train | epoch 1221 | loss 4.913 | ppl 30.13 | wps 422807 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6077 | lr 0.000405654 | gnorm 0.626 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58595
2023-02-11 11:51:01 | INFO | fairseq.trainer | begin training epoch 1222
2023-02-11 11:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:51:43 | INFO | fairseq_cli.train | end of epoch 1222 (average epoch stats below)
2023-02-11 11:51:43 | INFO | train | epoch 1222 | loss 4.91 | ppl 30.07 | wps 501908 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6082 | lr 0.000405487 | gnorm 0.543 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58637
2023-02-11 11:51:43 | INFO | fairseq.trainer | begin training epoch 1223
2023-02-11 11:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:52:24 | INFO | fairseq_cli.train | end of epoch 1223 (average epoch stats below)
2023-02-11 11:52:24 | INFO | train | epoch 1223 | loss 4.91 | ppl 30.07 | wps 507589 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6087 | lr 0.00040532 | gnorm 0.593 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58678
2023-02-11 11:52:25 | INFO | fairseq.trainer | begin training epoch 1224
2023-02-11 11:52:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:53:06 | INFO | fairseq_cli.train | end of epoch 1224 (average epoch stats below)
2023-02-11 11:53:06 | INFO | train | epoch 1224 | loss 4.914 | ppl 30.14 | wps 508125 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6092 | lr 0.000405154 | gnorm 0.678 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58720
2023-02-11 11:53:06 | INFO | fairseq.trainer | begin training epoch 1225
2023-02-11 11:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:53:46 | INFO | fairseq_cli.train | end of epoch 1225 (average epoch stats below)
2023-02-11 11:53:46 | INFO | train | epoch 1225 | loss 4.912 | ppl 30.1 | wps 522144 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6097 | lr 0.000404988 | gnorm 0.62 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58760
2023-02-11 11:53:46 | INFO | fairseq.trainer | begin training epoch 1226
2023-02-11 11:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:54:18 | INFO | train_inner | epoch 1226:      3 / 5 loss=4.917, ppl=30.21, wps=410498, ups=0.1, wpb=4.20574e+06, bsz=8214.4, num_updates=6100, lr=0.000404888, gnorm=0.607, loss_scale=1, train_wall=663, gb_free=5.4, wall=58792
2023-02-11 11:54:27 | INFO | fairseq_cli.train | end of epoch 1226 (average epoch stats below)
2023-02-11 11:54:27 | INFO | train | epoch 1226 | loss 4.908 | ppl 30.01 | wps 513812 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6102 | lr 0.000404822 | gnorm 0.531 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58801
2023-02-11 11:54:27 | INFO | fairseq.trainer | begin training epoch 1227
2023-02-11 11:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:55:08 | INFO | fairseq_cli.train | end of epoch 1227 (average epoch stats below)
2023-02-11 11:55:08 | INFO | train | epoch 1227 | loss 4.915 | ppl 30.17 | wps 511865 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6107 | lr 0.000404656 | gnorm 0.817 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58842
2023-02-11 11:55:08 | INFO | fairseq.trainer | begin training epoch 1228
2023-02-11 11:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:55:49 | INFO | fairseq_cli.train | end of epoch 1228 (average epoch stats below)
2023-02-11 11:55:49 | INFO | train | epoch 1228 | loss 4.912 | ppl 30.1 | wps 514563 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6112 | lr 0.000404491 | gnorm 0.611 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58883
2023-02-11 11:55:49 | INFO | fairseq.trainer | begin training epoch 1229
2023-02-11 11:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:56:30 | INFO | fairseq_cli.train | end of epoch 1229 (average epoch stats below)
2023-02-11 11:56:30 | INFO | train | epoch 1229 | loss 4.909 | ppl 30.05 | wps 510489 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6117 | lr 0.000404325 | gnorm 0.599 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 58924
2023-02-11 11:56:30 | INFO | fairseq.trainer | begin training epoch 1230
2023-02-11 11:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 11:57:18 | INFO | valid | epoch 1230 | valid on 'valid' subset | loss 5.154 | ppl 35.61 | wps 0 | wpb 11230 | bsz 22 | num_updates 6122 | best_loss 5.113
2023-02-11 11:57:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1230 @ 6122 updates
2023-02-11 11:57:18 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1230.pt
2023-02-11 11:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1230.pt
2023-02-11 11:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1230.pt (epoch 1230 @ 6122 updates, score 5.154) (writing took 64.1350321790087 seconds)
2023-02-11 11:58:22 | INFO | fairseq_cli.train | end of epoch 1230 (average epoch stats below)
2023-02-11 11:58:22 | INFO | train | epoch 1230 | loss 4.905 | ppl 29.97 | wps 188027 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6122 | lr 0.00040416 | gnorm 0.536 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 59036
2023-02-11 11:58:22 | INFO | fairseq.trainer | begin training epoch 1231
2023-02-11 11:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:58:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 11:59:12 | INFO | fairseq_cli.train | end of epoch 1231 (average epoch stats below)
2023-02-11 11:59:12 | INFO | train | epoch 1231 | loss 4.912 | ppl 30.1 | wps 317568 | ups 0.08 | wpb 3.96794e+06 | bsz 7750 | num_updates 6126 | lr 0.000404028 | gnorm 0.645 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59086
2023-02-11 11:59:12 | INFO | fairseq.trainer | begin training epoch 1232
2023-02-11 11:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 11:59:54 | INFO | fairseq_cli.train | end of epoch 1232 (average epoch stats below)
2023-02-11 11:59:54 | INFO | train | epoch 1232 | loss 4.907 | ppl 30 | wps 500439 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6131 | lr 0.000403863 | gnorm 0.58 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59128
2023-02-11 11:59:54 | INFO | fairseq.trainer | begin training epoch 1233
2023-02-11 11:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:00:35 | INFO | fairseq_cli.train | end of epoch 1233 (average epoch stats below)
2023-02-11 12:00:35 | INFO | train | epoch 1233 | loss 4.907 | ppl 30 | wps 512382 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6136 | lr 0.000403699 | gnorm 0.636 | loss_scale 0.5 | train_wall 32 | gb_free 5.6 | wall 59169
2023-02-11 12:00:35 | INFO | fairseq.trainer | begin training epoch 1234
2023-02-11 12:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:01:17 | INFO | fairseq_cli.train | end of epoch 1234 (average epoch stats below)
2023-02-11 12:01:17 | INFO | train | epoch 1234 | loss 4.905 | ppl 29.96 | wps 504375 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6141 | lr 0.000403534 | gnorm 0.596 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59211
2023-02-11 12:01:17 | INFO | fairseq.trainer | begin training epoch 1235
2023-02-11 12:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:01:57 | INFO | fairseq_cli.train | end of epoch 1235 (average epoch stats below)
2023-02-11 12:01:57 | INFO | train | epoch 1235 | loss 4.903 | ppl 29.92 | wps 522437 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6146 | lr 0.00040337 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59251
2023-02-11 12:01:57 | INFO | fairseq.trainer | begin training epoch 1236
2023-02-11 12:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:02:38 | INFO | fairseq_cli.train | end of epoch 1236 (average epoch stats below)
2023-02-11 12:02:38 | INFO | train | epoch 1236 | loss 4.904 | ppl 29.94 | wps 507447 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6151 | lr 0.000403206 | gnorm 0.647 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59292
2023-02-11 12:02:39 | INFO | fairseq.trainer | begin training epoch 1237
2023-02-11 12:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:03:20 | INFO | fairseq_cli.train | end of epoch 1237 (average epoch stats below)
2023-02-11 12:03:20 | INFO | train | epoch 1237 | loss 4.902 | ppl 29.89 | wps 509904 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6156 | lr 0.000403042 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59334
2023-02-11 12:03:20 | INFO | fairseq.trainer | begin training epoch 1238
2023-02-11 12:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:04:00 | INFO | fairseq_cli.train | end of epoch 1238 (average epoch stats below)
2023-02-11 12:04:00 | INFO | train | epoch 1238 | loss 4.9 | ppl 29.86 | wps 524272 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6161 | lr 0.000402879 | gnorm 0.6 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59374
2023-02-11 12:04:00 | INFO | fairseq.trainer | begin training epoch 1239
2023-02-11 12:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:04:41 | INFO | fairseq_cli.train | end of epoch 1239 (average epoch stats below)
2023-02-11 12:04:41 | INFO | train | epoch 1239 | loss 4.908 | ppl 30.01 | wps 505562 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6166 | lr 0.000402715 | gnorm 0.777 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59415
2023-02-11 12:04:42 | INFO | fairseq.trainer | begin training epoch 1240
2023-02-11 12:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:05:29 | INFO | valid | epoch 1240 | valid on 'valid' subset | loss 5.169 | ppl 35.97 | wps 0 | wpb 11230 | bsz 22 | num_updates 6171 | best_loss 5.113
2023-02-11 12:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1240 @ 6171 updates
2023-02-11 12:05:29 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1240.pt
2023-02-11 12:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1240.pt
2023-02-11 12:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1240.pt (epoch 1240 @ 6171 updates, score 5.169) (writing took 62.484605998004554 seconds)
2023-02-11 12:06:32 | INFO | fairseq_cli.train | end of epoch 1240 (average epoch stats below)
2023-02-11 12:06:32 | INFO | train | epoch 1240 | loss 4.902 | ppl 29.9 | wps 190908 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6171 | lr 0.000402552 | gnorm 0.636 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59526
2023-02-11 12:06:32 | INFO | fairseq.trainer | begin training epoch 1241
2023-02-11 12:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:07:22 | INFO | fairseq_cli.train | end of epoch 1241 (average epoch stats below)
2023-02-11 12:07:22 | INFO | train | epoch 1241 | loss 4.899 | ppl 29.83 | wps 420399 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6176 | lr 0.000402389 | gnorm 0.592 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59576
2023-02-11 12:07:22 | INFO | fairseq.trainer | begin training epoch 1242
2023-02-11 12:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:08:01 | INFO | fairseq_cli.train | end of epoch 1242 (average epoch stats below)
2023-02-11 12:08:01 | INFO | train | epoch 1242 | loss 4.897 | ppl 29.8 | wps 535081 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6181 | lr 0.000402226 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59615
2023-02-11 12:08:01 | INFO | fairseq.trainer | begin training epoch 1243
2023-02-11 12:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:08:43 | INFO | fairseq_cli.train | end of epoch 1243 (average epoch stats below)
2023-02-11 12:08:43 | INFO | train | epoch 1243 | loss 4.896 | ppl 29.77 | wps 505833 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6186 | lr 0.000402064 | gnorm 0.539 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59657
2023-02-11 12:08:43 | INFO | fairseq.trainer | begin training epoch 1244
2023-02-11 12:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:09:23 | INFO | fairseq_cli.train | end of epoch 1244 (average epoch stats below)
2023-02-11 12:09:23 | INFO | train | epoch 1244 | loss 4.894 | ppl 29.73 | wps 518302 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6191 | lr 0.000401901 | gnorm 0.544 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59697
2023-02-11 12:09:23 | INFO | fairseq.trainer | begin training epoch 1245
2023-02-11 12:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:10:03 | INFO | fairseq_cli.train | end of epoch 1245 (average epoch stats below)
2023-02-11 12:10:03 | INFO | train | epoch 1245 | loss 4.899 | ppl 29.83 | wps 524288 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6196 | lr 0.000401739 | gnorm 0.712 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59737
2023-02-11 12:10:04 | INFO | fairseq.trainer | begin training epoch 1246
2023-02-11 12:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:10:45 | INFO | train_inner | epoch 1246:      4 / 5 loss=4.903, ppl=29.93, wps=426461, ups=0.1, wpb=4.20756e+06, bsz=8218, num_updates=6200, lr=0.00040161, gnorm=0.618, loss_scale=0.5, train_wall=670, gb_free=5.4, wall=59779
2023-02-11 12:10:45 | INFO | fairseq_cli.train | end of epoch 1246 (average epoch stats below)
2023-02-11 12:10:45 | INFO | train | epoch 1246 | loss 4.896 | ppl 29.78 | wps 500777 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6201 | lr 0.000401577 | gnorm 0.607 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59779
2023-02-11 12:10:46 | INFO | fairseq.trainer | begin training epoch 1247
2023-02-11 12:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:11:27 | INFO | fairseq_cli.train | end of epoch 1247 (average epoch stats below)
2023-02-11 12:11:27 | INFO | train | epoch 1247 | loss 4.901 | ppl 29.88 | wps 506342 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6206 | lr 0.000401415 | gnorm 0.749 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59821
2023-02-11 12:11:27 | INFO | fairseq.trainer | begin training epoch 1248
2023-02-11 12:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:12:07 | INFO | fairseq_cli.train | end of epoch 1248 (average epoch stats below)
2023-02-11 12:12:07 | INFO | train | epoch 1248 | loss 4.9 | ppl 29.85 | wps 529622 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6211 | lr 0.000401254 | gnorm 0.716 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59861
2023-02-11 12:12:07 | INFO | fairseq.trainer | begin training epoch 1249
2023-02-11 12:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:12:48 | INFO | fairseq_cli.train | end of epoch 1249 (average epoch stats below)
2023-02-11 12:12:48 | INFO | train | epoch 1249 | loss 4.902 | ppl 29.89 | wps 509558 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6216 | lr 0.000401092 | gnorm 0.763 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 59902
2023-02-11 12:12:48 | INFO | fairseq.trainer | begin training epoch 1250
2023-02-11 12:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:13:35 | INFO | valid | epoch 1250 | valid on 'valid' subset | loss 5.161 | ppl 35.79 | wps 0 | wpb 11230 | bsz 22 | num_updates 6221 | best_loss 5.113
2023-02-11 12:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1250 @ 6221 updates
2023-02-11 12:13:35 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1250.pt
2023-02-11 12:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1250.pt
2023-02-11 12:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1250.pt (epoch 1250 @ 6221 updates, score 5.161) (writing took 64.14667885898962 seconds)
2023-02-11 12:14:39 | INFO | fairseq_cli.train | end of epoch 1250 (average epoch stats below)
2023-02-11 12:14:39 | INFO | train | epoch 1250 | loss 4.894 | ppl 29.73 | wps 188498 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6221 | lr 0.000400931 | gnorm 0.582 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60013
2023-02-11 12:14:40 | INFO | fairseq.trainer | begin training epoch 1251
2023-02-11 12:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:15:31 | INFO | fairseq_cli.train | end of epoch 1251 (average epoch stats below)
2023-02-11 12:15:31 | INFO | train | epoch 1251 | loss 4.891 | ppl 29.67 | wps 408631 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6226 | lr 0.00040077 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60065
2023-02-11 12:15:31 | INFO | fairseq.trainer | begin training epoch 1252
2023-02-11 12:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:16:12 | INFO | fairseq_cli.train | end of epoch 1252 (average epoch stats below)
2023-02-11 12:16:12 | INFO | train | epoch 1252 | loss 4.892 | ppl 29.7 | wps 512770 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6231 | lr 0.000400609 | gnorm 0.656 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60106
2023-02-11 12:16:12 | INFO | fairseq.trainer | begin training epoch 1253
2023-02-11 12:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:16:54 | INFO | fairseq_cli.train | end of epoch 1253 (average epoch stats below)
2023-02-11 12:16:54 | INFO | train | epoch 1253 | loss 4.894 | ppl 29.74 | wps 500453 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6236 | lr 0.000400449 | gnorm 0.673 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60148
2023-02-11 12:16:54 | INFO | fairseq.trainer | begin training epoch 1254
2023-02-11 12:16:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:17:34 | INFO | fairseq_cli.train | end of epoch 1254 (average epoch stats below)
2023-02-11 12:17:34 | INFO | train | epoch 1254 | loss 4.89 | ppl 29.66 | wps 518653 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6241 | lr 0.000400288 | gnorm 0.629 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60188
2023-02-11 12:17:35 | INFO | fairseq.trainer | begin training epoch 1255
2023-02-11 12:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:18:15 | INFO | fairseq_cli.train | end of epoch 1255 (average epoch stats below)
2023-02-11 12:18:15 | INFO | train | epoch 1255 | loss 4.889 | ppl 29.63 | wps 523231 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6246 | lr 0.000400128 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60229
2023-02-11 12:18:15 | INFO | fairseq.trainer | begin training epoch 1256
2023-02-11 12:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:18:57 | INFO | fairseq_cli.train | end of epoch 1256 (average epoch stats below)
2023-02-11 12:18:57 | INFO | train | epoch 1256 | loss 4.887 | ppl 29.59 | wps 501626 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6251 | lr 0.000399968 | gnorm 0.562 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60271
2023-02-11 12:18:57 | INFO | fairseq.trainer | begin training epoch 1257
2023-02-11 12:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:19:38 | INFO | fairseq_cli.train | end of epoch 1257 (average epoch stats below)
2023-02-11 12:19:38 | INFO | train | epoch 1257 | loss 4.884 | ppl 29.53 | wps 512704 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6256 | lr 0.000399808 | gnorm 0.511 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60312
2023-02-11 12:19:38 | INFO | fairseq.trainer | begin training epoch 1258
2023-02-11 12:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:20:18 | INFO | fairseq_cli.train | end of epoch 1258 (average epoch stats below)
2023-02-11 12:20:18 | INFO | train | epoch 1258 | loss 4.886 | ppl 29.58 | wps 525715 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6261 | lr 0.000399648 | gnorm 0.647 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60352
2023-02-11 12:20:18 | INFO | fairseq.trainer | begin training epoch 1259
2023-02-11 12:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:21:00 | INFO | fairseq_cli.train | end of epoch 1259 (average epoch stats below)
2023-02-11 12:21:00 | INFO | train | epoch 1259 | loss 4.884 | ppl 29.53 | wps 500167 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6266 | lr 0.000399489 | gnorm 0.561 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60394
2023-02-11 12:21:00 | INFO | fairseq.trainer | begin training epoch 1260
2023-02-11 12:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:21:47 | INFO | valid | epoch 1260 | valid on 'valid' subset | loss 5.167 | ppl 35.93 | wps 0 | wpb 11230 | bsz 22 | num_updates 6271 | best_loss 5.113
2023-02-11 12:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1260 @ 6271 updates
2023-02-11 12:21:47 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1260.pt
2023-02-11 12:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1260.pt
2023-02-11 12:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1260.pt (epoch 1260 @ 6271 updates, score 5.167) (writing took 59.98680247599259 seconds)
2023-02-11 12:22:47 | INFO | fairseq_cli.train | end of epoch 1260 (average epoch stats below)
2023-02-11 12:22:47 | INFO | train | epoch 1260 | loss 4.887 | ppl 29.59 | wps 196726 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6271 | lr 0.00039933 | gnorm 0.693 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60501
2023-02-11 12:22:47 | INFO | fairseq.trainer | begin training epoch 1261
2023-02-11 12:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:23:37 | INFO | fairseq_cli.train | end of epoch 1261 (average epoch stats below)
2023-02-11 12:23:37 | INFO | train | epoch 1261 | loss 4.89 | ppl 29.65 | wps 415146 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6276 | lr 0.000399171 | gnorm 0.71 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60551
2023-02-11 12:23:38 | INFO | fairseq.trainer | begin training epoch 1262
2023-02-11 12:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:24:18 | INFO | fairseq_cli.train | end of epoch 1262 (average epoch stats below)
2023-02-11 12:24:18 | INFO | train | epoch 1262 | loss 4.888 | ppl 29.61 | wps 513159 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6281 | lr 0.000399012 | gnorm 0.655 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60592
2023-02-11 12:24:19 | INFO | fairseq.trainer | begin training epoch 1263
2023-02-11 12:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:25:01 | INFO | fairseq_cli.train | end of epoch 1263 (average epoch stats below)
2023-02-11 12:25:01 | INFO | train | epoch 1263 | loss 4.887 | ppl 29.6 | wps 497033 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6286 | lr 0.000398853 | gnorm 0.676 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60635
2023-02-11 12:25:01 | INFO | fairseq.trainer | begin training epoch 1264
2023-02-11 12:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:25:41 | INFO | fairseq_cli.train | end of epoch 1264 (average epoch stats below)
2023-02-11 12:25:41 | INFO | train | epoch 1264 | loss 4.887 | ppl 29.6 | wps 522455 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6291 | lr 0.000398694 | gnorm 0.716 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60675
2023-02-11 12:25:41 | INFO | fairseq.trainer | begin training epoch 1265
2023-02-11 12:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:26:21 | INFO | fairseq_cli.train | end of epoch 1265 (average epoch stats below)
2023-02-11 12:26:21 | INFO | train | epoch 1265 | loss 4.881 | ppl 29.47 | wps 522669 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6296 | lr 0.000398536 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60715
2023-02-11 12:26:21 | INFO | fairseq.trainer | begin training epoch 1266
2023-02-11 12:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:27:03 | INFO | train_inner | epoch 1266:      4 / 5 loss=4.89, ppl=29.64, wps=429930, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=6300, lr=0.00039841, gnorm=0.64, loss_scale=0.5, train_wall=663, gb_free=5.4, wall=60757
2023-02-11 12:27:04 | INFO | fairseq_cli.train | end of epoch 1266 (average epoch stats below)
2023-02-11 12:27:04 | INFO | train | epoch 1266 | loss 4.88 | ppl 29.44 | wps 493418 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6301 | lr 0.000398378 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60758
2023-02-11 12:27:04 | INFO | fairseq.trainer | begin training epoch 1267
2023-02-11 12:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:27:44 | INFO | fairseq_cli.train | end of epoch 1267 (average epoch stats below)
2023-02-11 12:27:44 | INFO | train | epoch 1267 | loss 4.883 | ppl 29.5 | wps 524828 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6306 | lr 0.00039822 | gnorm 0.659 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60798
2023-02-11 12:27:44 | INFO | fairseq.trainer | begin training epoch 1268
2023-02-11 12:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:28:24 | INFO | fairseq_cli.train | end of epoch 1268 (average epoch stats below)
2023-02-11 12:28:24 | INFO | train | epoch 1268 | loss 4.883 | ppl 29.51 | wps 526240 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6311 | lr 0.000398062 | gnorm 0.704 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60838
2023-02-11 12:28:24 | INFO | fairseq.trainer | begin training epoch 1269
2023-02-11 12:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:29:06 | INFO | fairseq_cli.train | end of epoch 1269 (average epoch stats below)
2023-02-11 12:29:06 | INFO | train | epoch 1269 | loss 4.881 | ppl 29.46 | wps 493620 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6316 | lr 0.000397905 | gnorm 0.633 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60880
2023-02-11 12:29:07 | INFO | fairseq.trainer | begin training epoch 1270
2023-02-11 12:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:29:53 | INFO | valid | epoch 1270 | valid on 'valid' subset | loss 5.136 | ppl 35.17 | wps 0 | wpb 11230 | bsz 22 | num_updates 6321 | best_loss 5.113
2023-02-11 12:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1270 @ 6321 updates
2023-02-11 12:29:53 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1270.pt
2023-02-11 12:29:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1270.pt
2023-02-11 12:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1270.pt (epoch 1270 @ 6321 updates, score 5.136) (writing took 65.245146043977 seconds)
2023-02-11 12:30:58 | INFO | fairseq_cli.train | end of epoch 1270 (average epoch stats below)
2023-02-11 12:30:58 | INFO | train | epoch 1270 | loss 4.877 | ppl 29.39 | wps 188352 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6321 | lr 0.000397747 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 60992
2023-02-11 12:30:58 | INFO | fairseq.trainer | begin training epoch 1271
2023-02-11 12:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:31:47 | INFO | fairseq_cli.train | end of epoch 1271 (average epoch stats below)
2023-02-11 12:31:47 | INFO | train | epoch 1271 | loss 4.874 | ppl 29.33 | wps 425605 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6326 | lr 0.00039759 | gnorm 0.495 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61042
2023-02-11 12:31:48 | INFO | fairseq.trainer | begin training epoch 1272
2023-02-11 12:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:32:29 | INFO | fairseq_cli.train | end of epoch 1272 (average epoch stats below)
2023-02-11 12:32:29 | INFO | train | epoch 1272 | loss 4.878 | ppl 29.4 | wps 502277 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6331 | lr 0.000397433 | gnorm 0.663 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61083
2023-02-11 12:32:30 | INFO | fairseq.trainer | begin training epoch 1273
2023-02-11 12:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:33:12 | INFO | fairseq_cli.train | end of epoch 1273 (average epoch stats below)
2023-02-11 12:33:12 | INFO | train | epoch 1273 | loss 4.894 | ppl 29.74 | wps 489391 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6336 | lr 0.000397276 | gnorm 0.953 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61126
2023-02-11 12:33:13 | INFO | fairseq.trainer | begin training epoch 1274
2023-02-11 12:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:33:53 | INFO | fairseq_cli.train | end of epoch 1274 (average epoch stats below)
2023-02-11 12:33:53 | INFO | train | epoch 1274 | loss 4.886 | ppl 29.58 | wps 518108 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6341 | lr 0.000397119 | gnorm 0.635 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61167
2023-02-11 12:33:53 | INFO | fairseq.trainer | begin training epoch 1275
2023-02-11 12:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:34:33 | INFO | fairseq_cli.train | end of epoch 1275 (average epoch stats below)
2023-02-11 12:34:33 | INFO | train | epoch 1275 | loss 4.88 | ppl 29.44 | wps 528756 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6346 | lr 0.000396963 | gnorm 0.548 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61207
2023-02-11 12:34:33 | INFO | fairseq.trainer | begin training epoch 1276
2023-02-11 12:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:35:15 | INFO | fairseq_cli.train | end of epoch 1276 (average epoch stats below)
2023-02-11 12:35:15 | INFO | train | epoch 1276 | loss 4.877 | ppl 29.39 | wps 495590 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6351 | lr 0.000396807 | gnorm 0.551 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61249
2023-02-11 12:35:16 | INFO | fairseq.trainer | begin training epoch 1277
2023-02-11 12:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:35:55 | INFO | fairseq_cli.train | end of epoch 1277 (average epoch stats below)
2023-02-11 12:35:55 | INFO | train | epoch 1277 | loss 4.874 | ppl 29.32 | wps 523438 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6356 | lr 0.000396651 | gnorm 0.554 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61289
2023-02-11 12:35:56 | INFO | fairseq.trainer | begin training epoch 1278
2023-02-11 12:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:36:35 | INFO | fairseq_cli.train | end of epoch 1278 (average epoch stats below)
2023-02-11 12:36:35 | INFO | train | epoch 1278 | loss 4.875 | ppl 29.34 | wps 524036 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6361 | lr 0.000396495 | gnorm 0.613 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61330
2023-02-11 12:36:36 | INFO | fairseq.trainer | begin training epoch 1279
2023-02-11 12:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:37:18 | INFO | fairseq_cli.train | end of epoch 1279 (average epoch stats below)
2023-02-11 12:37:18 | INFO | train | epoch 1279 | loss 4.871 | ppl 29.27 | wps 500173 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6366 | lr 0.000396339 | gnorm 0.535 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61372
2023-02-11 12:37:18 | INFO | fairseq.trainer | begin training epoch 1280
2023-02-11 12:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:38:04 | INFO | valid | epoch 1280 | valid on 'valid' subset | loss 5.169 | ppl 35.98 | wps 0 | wpb 11230 | bsz 22 | num_updates 6371 | best_loss 5.113
2023-02-11 12:38:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1280 @ 6371 updates
2023-02-11 12:38:04 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1280.pt
2023-02-11 12:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1280.pt
2023-02-11 12:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1280.pt (epoch 1280 @ 6371 updates, score 5.169) (writing took 62.227688904007664 seconds)
2023-02-11 12:39:06 | INFO | fairseq_cli.train | end of epoch 1280 (average epoch stats below)
2023-02-11 12:39:06 | INFO | train | epoch 1280 | loss 4.872 | ppl 29.29 | wps 193049 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6371 | lr 0.000396183 | gnorm 0.613 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61481
2023-02-11 12:39:07 | INFO | fairseq.trainer | begin training epoch 1281
2023-02-11 12:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:39:55 | INFO | fairseq_cli.train | end of epoch 1281 (average epoch stats below)
2023-02-11 12:39:55 | INFO | train | epoch 1281 | loss 4.877 | ppl 29.39 | wps 430408 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6376 | lr 0.000396028 | gnorm 0.791 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61529
2023-02-11 12:39:56 | INFO | fairseq.trainer | begin training epoch 1282
2023-02-11 12:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:40:37 | INFO | fairseq_cli.train | end of epoch 1282 (average epoch stats below)
2023-02-11 12:40:37 | INFO | train | epoch 1282 | loss 4.874 | ppl 29.32 | wps 510309 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6381 | lr 0.000395873 | gnorm 0.629 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61571
2023-02-11 12:40:37 | INFO | fairseq.trainer | begin training epoch 1283
2023-02-11 12:40:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:41:19 | INFO | fairseq_cli.train | end of epoch 1283 (average epoch stats below)
2023-02-11 12:41:19 | INFO | train | epoch 1283 | loss 4.871 | ppl 29.26 | wps 495848 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6386 | lr 0.000395718 | gnorm 0.596 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61613
2023-02-11 12:41:19 | INFO | fairseq.trainer | begin training epoch 1284
2023-02-11 12:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:41:58 | INFO | fairseq_cli.train | end of epoch 1284 (average epoch stats below)
2023-02-11 12:41:58 | INFO | train | epoch 1284 | loss 4.874 | ppl 29.32 | wps 533176 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6391 | lr 0.000395563 | gnorm 0.705 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61653
2023-02-11 12:41:59 | INFO | fairseq.trainer | begin training epoch 1285
2023-02-11 12:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:42:39 | INFO | fairseq_cli.train | end of epoch 1285 (average epoch stats below)
2023-02-11 12:42:39 | INFO | train | epoch 1285 | loss 4.869 | ppl 29.22 | wps 519650 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6396 | lr 0.000395408 | gnorm 0.557 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61693
2023-02-11 12:42:39 | INFO | fairseq.trainer | begin training epoch 1286
2023-02-11 12:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:43:21 | INFO | train_inner | epoch 1286:      4 / 5 loss=4.877, ppl=29.38, wps=430129, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=6400, lr=0.000395285, gnorm=0.623, loss_scale=1, train_wall=663, gb_free=5.4, wall=61735
2023-02-11 12:43:22 | INFO | fairseq_cli.train | end of epoch 1286 (average epoch stats below)
2023-02-11 12:43:22 | INFO | train | epoch 1286 | loss 4.865 | ppl 29.14 | wps 491483 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6401 | lr 0.000395254 | gnorm 0.467 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61736
2023-02-11 12:43:22 | INFO | fairseq.trainer | begin training epoch 1287
2023-02-11 12:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:44:02 | INFO | fairseq_cli.train | end of epoch 1287 (average epoch stats below)
2023-02-11 12:44:02 | INFO | train | epoch 1287 | loss 4.866 | ppl 29.15 | wps 528308 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6406 | lr 0.0003951 | gnorm 0.569 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61776
2023-02-11 12:44:02 | INFO | fairseq.trainer | begin training epoch 1288
2023-02-11 12:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:44:42 | INFO | fairseq_cli.train | end of epoch 1288 (average epoch stats below)
2023-02-11 12:44:42 | INFO | train | epoch 1288 | loss 4.869 | ppl 29.23 | wps 514203 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6411 | lr 0.000394945 | gnorm 0.685 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61817
2023-02-11 12:44:43 | INFO | fairseq.trainer | begin training epoch 1289
2023-02-11 12:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:45:25 | INFO | fairseq_cli.train | end of epoch 1289 (average epoch stats below)
2023-02-11 12:45:25 | INFO | train | epoch 1289 | loss 4.871 | ppl 29.27 | wps 497560 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6416 | lr 0.000394792 | gnorm 0.688 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 61859
2023-02-11 12:45:25 | INFO | fairseq.trainer | begin training epoch 1290
2023-02-11 12:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:45:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 12:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:46:11 | INFO | valid | epoch 1290 | valid on 'valid' subset | loss 5.173 | ppl 36.08 | wps 0 | wpb 11230 | bsz 22 | num_updates 6420 | best_loss 5.113
2023-02-11 12:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1290 @ 6420 updates
2023-02-11 12:46:11 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1290.pt
2023-02-11 12:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1290.pt
2023-02-11 12:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1290.pt (epoch 1290 @ 6420 updates, score 5.173) (writing took 59.37096801100415 seconds)
2023-02-11 12:47:11 | INFO | fairseq_cli.train | end of epoch 1290 (average epoch stats below)
2023-02-11 12:47:11 | INFO | train | epoch 1290 | loss 4.875 | ppl 29.35 | wps 148918 | ups 0.04 | wpb 3.94772e+06 | bsz 7710.5 | num_updates 6420 | lr 0.000394669 | gnorm 0.75 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 61965
2023-02-11 12:47:11 | INFO | fairseq.trainer | begin training epoch 1291
2023-02-11 12:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:48:00 | INFO | fairseq_cli.train | end of epoch 1291 (average epoch stats below)
2023-02-11 12:48:00 | INFO | train | epoch 1291 | loss 4.869 | ppl 29.23 | wps 430358 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6425 | lr 0.000394515 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62014
2023-02-11 12:48:00 | INFO | fairseq.trainer | begin training epoch 1292
2023-02-11 12:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:48:39 | INFO | fairseq_cli.train | end of epoch 1292 (average epoch stats below)
2023-02-11 12:48:39 | INFO | train | epoch 1292 | loss 4.865 | ppl 29.14 | wps 531353 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6430 | lr 0.000394362 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62053
2023-02-11 12:48:40 | INFO | fairseq.trainer | begin training epoch 1293
2023-02-11 12:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:49:20 | INFO | fairseq_cli.train | end of epoch 1293 (average epoch stats below)
2023-02-11 12:49:20 | INFO | train | epoch 1293 | loss 4.864 | ppl 29.11 | wps 514145 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6435 | lr 0.000394208 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62094
2023-02-11 12:49:20 | INFO | fairseq.trainer | begin training epoch 1294
2023-02-11 12:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:50:00 | INFO | fairseq_cli.train | end of epoch 1294 (average epoch stats below)
2023-02-11 12:50:00 | INFO | train | epoch 1294 | loss 4.867 | ppl 29.17 | wps 533798 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6440 | lr 0.000394055 | gnorm 0.707 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62134
2023-02-11 12:50:00 | INFO | fairseq.trainer | begin training epoch 1295
2023-02-11 12:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:50:41 | INFO | fairseq_cli.train | end of epoch 1295 (average epoch stats below)
2023-02-11 12:50:41 | INFO | train | epoch 1295 | loss 4.87 | ppl 29.24 | wps 505838 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6445 | lr 0.000393902 | gnorm 0.747 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62175
2023-02-11 12:50:42 | INFO | fairseq.trainer | begin training epoch 1296
2023-02-11 12:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:51:23 | INFO | fairseq_cli.train | end of epoch 1296 (average epoch stats below)
2023-02-11 12:51:23 | INFO | train | epoch 1296 | loss 4.87 | ppl 29.23 | wps 506342 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6450 | lr 0.00039375 | gnorm 0.704 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62217
2023-02-11 12:51:23 | INFO | fairseq.trainer | begin training epoch 1297
2023-02-11 12:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:52:03 | INFO | fairseq_cli.train | end of epoch 1297 (average epoch stats below)
2023-02-11 12:52:03 | INFO | train | epoch 1297 | loss 4.861 | ppl 29.05 | wps 526171 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6455 | lr 0.000393597 | gnorm 0.498 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62257
2023-02-11 12:52:03 | INFO | fairseq.trainer | begin training epoch 1298
2023-02-11 12:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:52:44 | INFO | fairseq_cli.train | end of epoch 1298 (average epoch stats below)
2023-02-11 12:52:44 | INFO | train | epoch 1298 | loss 4.859 | ppl 29.02 | wps 502919 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6460 | lr 0.000393445 | gnorm 0.543 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62299
2023-02-11 12:52:45 | INFO | fairseq.trainer | begin training epoch 1299
2023-02-11 12:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:53:26 | INFO | fairseq_cli.train | end of epoch 1299 (average epoch stats below)
2023-02-11 12:53:26 | INFO | train | epoch 1299 | loss 4.873 | ppl 29.3 | wps 511520 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6465 | lr 0.000393293 | gnorm 0.874 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62340
2023-02-11 12:53:26 | INFO | fairseq.trainer | begin training epoch 1300
2023-02-11 12:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 12:54:13 | INFO | valid | epoch 1300 | valid on 'valid' subset | loss 5.182 | ppl 36.3 | wps 0 | wpb 11230 | bsz 22 | num_updates 6470 | best_loss 5.113
2023-02-11 12:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1300 @ 6470 updates
2023-02-11 12:54:13 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1300.pt
2023-02-11 12:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1300.pt
2023-02-11 12:55:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1300.pt (epoch 1300 @ 6470 updates, score 5.182) (writing took 67.53124596099951 seconds)
2023-02-11 12:55:21 | INFO | fairseq_cli.train | end of epoch 1300 (average epoch stats below)
2023-02-11 12:55:21 | INFO | train | epoch 1300 | loss 4.866 | ppl 29.16 | wps 182415 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6470 | lr 0.000393141 | gnorm 0.659 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62455
2023-02-11 12:55:21 | INFO | fairseq.trainer | begin training epoch 1301
2023-02-11 12:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:56:09 | INFO | fairseq_cli.train | end of epoch 1301 (average epoch stats below)
2023-02-11 12:56:09 | INFO | train | epoch 1301 | loss 4.86 | ppl 29.04 | wps 439837 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6475 | lr 0.000392989 | gnorm 0.547 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62503
2023-02-11 12:56:09 | INFO | fairseq.trainer | begin training epoch 1302
2023-02-11 12:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:56:50 | INFO | fairseq_cli.train | end of epoch 1302 (average epoch stats below)
2023-02-11 12:56:50 | INFO | train | epoch 1302 | loss 4.858 | ppl 29 | wps 507423 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6480 | lr 0.000392837 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62544
2023-02-11 12:56:51 | INFO | fairseq.trainer | begin training epoch 1303
2023-02-11 12:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:57:31 | INFO | fairseq_cli.train | end of epoch 1303 (average epoch stats below)
2023-02-11 12:57:31 | INFO | train | epoch 1303 | loss 4.859 | ppl 29.02 | wps 510704 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6485 | lr 0.000392686 | gnorm 0.59 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62585
2023-02-11 12:57:32 | INFO | fairseq.trainer | begin training epoch 1304
2023-02-11 12:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:58:11 | INFO | fairseq_cli.train | end of epoch 1304 (average epoch stats below)
2023-02-11 12:58:11 | INFO | train | epoch 1304 | loss 4.858 | ppl 29.01 | wps 529101 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6490 | lr 0.000392534 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62625
2023-02-11 12:58:12 | INFO | fairseq.trainer | begin training epoch 1305
2023-02-11 12:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:58:53 | INFO | fairseq_cli.train | end of epoch 1305 (average epoch stats below)
2023-02-11 12:58:53 | INFO | train | epoch 1305 | loss 4.856 | ppl 28.96 | wps 503262 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6495 | lr 0.000392383 | gnorm 0.581 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62667
2023-02-11 12:58:53 | INFO | fairseq.trainer | begin training epoch 1306
2023-02-11 12:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 12:59:34 | INFO | train_inner | epoch 1306:      5 / 5 loss=4.865, ppl=29.14, wps=427021, ups=0.1, wpb=4.15596e+06, bsz=8117.2, num_updates=6500, lr=0.000392232, gnorm=0.644, loss_scale=0.5, train_wall=664, gb_free=5.6, wall=62708
2023-02-11 12:59:34 | INFO | fairseq_cli.train | end of epoch 1306 (average epoch stats below)
2023-02-11 12:59:34 | INFO | train | epoch 1306 | loss 4.868 | ppl 29.2 | wps 506744 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6500 | lr 0.000392232 | gnorm 0.883 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62708
2023-02-11 12:59:35 | INFO | fairseq.trainer | begin training epoch 1307
2023-02-11 12:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:00:14 | INFO | fairseq_cli.train | end of epoch 1307 (average epoch stats below)
2023-02-11 13:00:14 | INFO | train | epoch 1307 | loss 4.868 | ppl 29.2 | wps 531266 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6505 | lr 0.000392081 | gnorm 0.79 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62748
2023-02-11 13:00:14 | INFO | fairseq.trainer | begin training epoch 1308
2023-02-11 13:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:00:56 | INFO | fairseq_cli.train | end of epoch 1308 (average epoch stats below)
2023-02-11 13:00:56 | INFO | train | epoch 1308 | loss 4.86 | ppl 29.04 | wps 503071 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6510 | lr 0.000391931 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62790
2023-02-11 13:00:56 | INFO | fairseq.trainer | begin training epoch 1309
2023-02-11 13:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:01:37 | INFO | fairseq_cli.train | end of epoch 1309 (average epoch stats below)
2023-02-11 13:01:37 | INFO | train | epoch 1309 | loss 4.861 | ppl 29.06 | wps 508035 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6515 | lr 0.00039178 | gnorm 0.685 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62831
2023-02-11 13:01:38 | INFO | fairseq.trainer | begin training epoch 1310
2023-02-11 13:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:02:25 | INFO | valid | epoch 1310 | valid on 'valid' subset | loss 5.165 | ppl 35.87 | wps 0 | wpb 11230 | bsz 22 | num_updates 6520 | best_loss 5.113
2023-02-11 13:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1310 @ 6520 updates
2023-02-11 13:02:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1310.pt
2023-02-11 13:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1310.pt
2023-02-11 13:03:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1310.pt (epoch 1310 @ 6520 updates, score 5.165) (writing took 64.92224797199015 seconds)
2023-02-11 13:03:30 | INFO | fairseq_cli.train | end of epoch 1310 (average epoch stats below)
2023-02-11 13:03:30 | INFO | train | epoch 1310 | loss 4.857 | ppl 28.99 | wps 187245 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6520 | lr 0.00039163 | gnorm 0.628 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62944
2023-02-11 13:03:30 | INFO | fairseq.trainer | begin training epoch 1311
2023-02-11 13:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:04:11 | INFO | fairseq_cli.train | end of epoch 1311 (average epoch stats below)
2023-02-11 13:04:11 | INFO | train | epoch 1311 | loss 4.853 | ppl 28.9 | wps 512041 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6525 | lr 0.00039148 | gnorm 0.514 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 62985
2023-02-11 13:04:11 | INFO | fairseq.trainer | begin training epoch 1312
2023-02-11 13:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:04:52 | INFO | fairseq_cli.train | end of epoch 1312 (average epoch stats below)
2023-02-11 13:04:52 | INFO | train | epoch 1312 | loss 4.85 | ppl 28.85 | wps 514788 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6530 | lr 0.00039133 | gnorm 0.492 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63026
2023-02-11 13:04:52 | INFO | fairseq.trainer | begin training epoch 1313
2023-02-11 13:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:05:32 | INFO | fairseq_cli.train | end of epoch 1313 (average epoch stats below)
2023-02-11 13:05:32 | INFO | train | epoch 1313 | loss 4.848 | ppl 28.79 | wps 521664 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6535 | lr 0.000391181 | gnorm 0.508 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63066
2023-02-11 13:05:32 | INFO | fairseq.trainer | begin training epoch 1314
2023-02-11 13:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:06:13 | INFO | fairseq_cli.train | end of epoch 1314 (average epoch stats below)
2023-02-11 13:06:13 | INFO | train | epoch 1314 | loss 4.854 | ppl 28.92 | wps 509157 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6540 | lr 0.000391031 | gnorm 0.667 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63107
2023-02-11 13:06:14 | INFO | fairseq.trainer | begin training epoch 1315
2023-02-11 13:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:06:55 | INFO | fairseq_cli.train | end of epoch 1315 (average epoch stats below)
2023-02-11 13:06:55 | INFO | train | epoch 1315 | loss 4.852 | ppl 28.88 | wps 507129 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6545 | lr 0.000390882 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63149
2023-02-11 13:06:55 | INFO | fairseq.trainer | begin training epoch 1316
2023-02-11 13:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:07:35 | INFO | fairseq_cli.train | end of epoch 1316 (average epoch stats below)
2023-02-11 13:07:35 | INFO | train | epoch 1316 | loss 4.863 | ppl 29.1 | wps 526425 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6550 | lr 0.000390732 | gnorm 0.822 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63189
2023-02-11 13:07:35 | INFO | fairseq.trainer | begin training epoch 1317
2023-02-11 13:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:08:16 | INFO | fairseq_cli.train | end of epoch 1317 (average epoch stats below)
2023-02-11 13:08:16 | INFO | train | epoch 1317 | loss 4.855 | ppl 28.94 | wps 507738 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6555 | lr 0.000390583 | gnorm 0.613 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63230
2023-02-11 13:08:16 | INFO | fairseq.trainer | begin training epoch 1318
2023-02-11 13:08:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:08:58 | INFO | fairseq_cli.train | end of epoch 1318 (average epoch stats below)
2023-02-11 13:08:58 | INFO | train | epoch 1318 | loss 4.851 | ppl 28.86 | wps 504467 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6560 | lr 0.000390434 | gnorm 0.614 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63272
2023-02-11 13:08:58 | INFO | fairseq.trainer | begin training epoch 1319
2023-02-11 13:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:09:37 | INFO | fairseq_cli.train | end of epoch 1319 (average epoch stats below)
2023-02-11 13:09:37 | INFO | train | epoch 1319 | loss 4.851 | ppl 28.86 | wps 535856 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6565 | lr 0.000390286 | gnorm 0.627 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63311
2023-02-11 13:09:37 | INFO | fairseq.trainer | begin training epoch 1320
2023-02-11 13:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:10:27 | INFO | valid | epoch 1320 | valid on 'valid' subset | loss 5.223 | ppl 37.35 | wps 0 | wpb 11230 | bsz 22 | num_updates 6570 | best_loss 5.113
2023-02-11 13:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1320 @ 6570 updates
2023-02-11 13:10:27 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1320.pt
2023-02-11 13:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1320.pt
2023-02-11 13:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1320.pt (epoch 1320 @ 6570 updates, score 5.223) (writing took 66.97963855799753 seconds)
2023-02-11 13:11:34 | INFO | fairseq_cli.train | end of epoch 1320 (average epoch stats below)
2023-02-11 13:11:34 | INFO | train | epoch 1320 | loss 4.852 | ppl 28.88 | wps 179024 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6570 | lr 0.000390137 | gnorm 0.667 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63429
2023-02-11 13:11:35 | INFO | fairseq.trainer | begin training epoch 1321
2023-02-11 13:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:13:11 | INFO | fairseq_cli.train | end of epoch 1321 (average epoch stats below)
2023-02-11 13:13:11 | INFO | train | epoch 1321 | loss 4.856 | ppl 28.95 | wps 218862 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6575 | lr 0.000389989 | gnorm 0.778 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63525
2023-02-11 13:13:11 | INFO | fairseq.trainer | begin training epoch 1322
2023-02-11 13:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:13:54 | INFO | fairseq_cli.train | end of epoch 1322 (average epoch stats below)
2023-02-11 13:13:54 | INFO | train | epoch 1322 | loss 4.854 | ppl 28.92 | wps 487486 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6580 | lr 0.000389841 | gnorm 0.727 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63568
2023-02-11 13:13:54 | INFO | fairseq.trainer | begin training epoch 1323
2023-02-11 13:13:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:14:34 | INFO | fairseq_cli.train | end of epoch 1323 (average epoch stats below)
2023-02-11 13:14:34 | INFO | train | epoch 1323 | loss 4.852 | ppl 28.88 | wps 520085 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6585 | lr 0.000389693 | gnorm 0.68 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63608
2023-02-11 13:14:34 | INFO | fairseq.trainer | begin training epoch 1324
2023-02-11 13:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:15:16 | INFO | fairseq_cli.train | end of epoch 1324 (average epoch stats below)
2023-02-11 13:15:16 | INFO | train | epoch 1324 | loss 4.846 | ppl 28.75 | wps 503596 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6590 | lr 0.000389545 | gnorm 0.516 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63650
2023-02-11 13:15:16 | INFO | fairseq.trainer | begin training epoch 1325
2023-02-11 13:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:15:57 | INFO | fairseq_cli.train | end of epoch 1325 (average epoch stats below)
2023-02-11 13:15:57 | INFO | train | epoch 1325 | loss 4.845 | ppl 28.73 | wps 510760 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6595 | lr 0.000389397 | gnorm 0.561 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63691
2023-02-11 13:15:57 | INFO | fairseq.trainer | begin training epoch 1326
2023-02-11 13:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:16:37 | INFO | train_inner | epoch 1326:      5 / 5 loss=4.853, ppl=28.91, wps=411268, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=6600, lr=0.000389249, gnorm=0.633, loss_scale=0.5, train_wall=662, gb_free=5.6, wall=63731
2023-02-11 13:16:37 | INFO | fairseq_cli.train | end of epoch 1326 (average epoch stats below)
2023-02-11 13:16:37 | INFO | train | epoch 1326 | loss 4.842 | ppl 28.69 | wps 523257 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6600 | lr 0.000389249 | gnorm 0.547 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63731
2023-02-11 13:16:38 | INFO | fairseq.trainer | begin training epoch 1327
2023-02-11 13:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:17:19 | INFO | fairseq_cli.train | end of epoch 1327 (average epoch stats below)
2023-02-11 13:17:19 | INFO | train | epoch 1327 | loss 4.846 | ppl 28.76 | wps 503148 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6605 | lr 0.000389102 | gnorm 0.67 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63773
2023-02-11 13:17:19 | INFO | fairseq.trainer | begin training epoch 1328
2023-02-11 13:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:18:00 | INFO | fairseq_cli.train | end of epoch 1328 (average epoch stats below)
2023-02-11 13:18:00 | INFO | train | epoch 1328 | loss 4.843 | ppl 28.7 | wps 514164 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6610 | lr 0.000388955 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63814
2023-02-11 13:18:00 | INFO | fairseq.trainer | begin training epoch 1329
2023-02-11 13:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:18:40 | INFO | fairseq_cli.train | end of epoch 1329 (average epoch stats below)
2023-02-11 13:18:40 | INFO | train | epoch 1329 | loss 4.844 | ppl 28.73 | wps 527127 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6615 | lr 0.000388808 | gnorm 0.685 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63854
2023-02-11 13:18:40 | INFO | fairseq.trainer | begin training epoch 1330
2023-02-11 13:18:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:19:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:19:29 | INFO | valid | epoch 1330 | valid on 'valid' subset | loss 5.148 | ppl 35.45 | wps 0 | wpb 11230 | bsz 22 | num_updates 6620 | best_loss 5.113
2023-02-11 13:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1330 @ 6620 updates
2023-02-11 13:19:29 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1330.pt
2023-02-11 13:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1330.pt
2023-02-11 13:20:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1330.pt (epoch 1330 @ 6620 updates, score 5.148) (writing took 65.86978170499788 seconds)
2023-02-11 13:20:35 | INFO | fairseq_cli.train | end of epoch 1330 (average epoch stats below)
2023-02-11 13:20:35 | INFO | train | epoch 1330 | loss 4.846 | ppl 28.77 | wps 183051 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6620 | lr 0.000388661 | gnorm 0.725 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 63969
2023-02-11 13:20:35 | INFO | fairseq.trainer | begin training epoch 1331
2023-02-11 13:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:21:33 | INFO | fairseq_cli.train | end of epoch 1331 (average epoch stats below)
2023-02-11 13:21:33 | INFO | train | epoch 1331 | loss 4.842 | ppl 28.69 | wps 362749 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6625 | lr 0.000388514 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64027
2023-02-11 13:21:33 | INFO | fairseq.trainer | begin training epoch 1332
2023-02-11 13:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:22:17 | INFO | fairseq_cli.train | end of epoch 1332 (average epoch stats below)
2023-02-11 13:22:17 | INFO | train | epoch 1332 | loss 4.843 | ppl 28.71 | wps 481448 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6630 | lr 0.000388368 | gnorm 0.652 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64071
2023-02-11 13:22:17 | INFO | fairseq.trainer | begin training epoch 1333
2023-02-11 13:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:22:57 | INFO | fairseq_cli.train | end of epoch 1333 (average epoch stats below)
2023-02-11 13:22:57 | INFO | train | epoch 1333 | loss 4.844 | ppl 28.72 | wps 525086 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6635 | lr 0.000388221 | gnorm 0.682 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64111
2023-02-11 13:22:57 | INFO | fairseq.trainer | begin training epoch 1334
2023-02-11 13:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:23:37 | INFO | fairseq_cli.train | end of epoch 1334 (average epoch stats below)
2023-02-11 13:23:37 | INFO | train | epoch 1334 | loss 4.84 | ppl 28.63 | wps 515172 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6640 | lr 0.000388075 | gnorm 0.605 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64151
2023-02-11 13:23:38 | INFO | fairseq.trainer | begin training epoch 1335
2023-02-11 13:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:24:20 | INFO | fairseq_cli.train | end of epoch 1335 (average epoch stats below)
2023-02-11 13:24:20 | INFO | train | epoch 1335 | loss 4.853 | ppl 28.89 | wps 498776 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6645 | lr 0.000387929 | gnorm 0.844 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64194
2023-02-11 13:24:20 | INFO | fairseq.trainer | begin training epoch 1336
2023-02-11 13:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:24:59 | INFO | fairseq_cli.train | end of epoch 1336 (average epoch stats below)
2023-02-11 13:24:59 | INFO | train | epoch 1336 | loss 4.844 | ppl 28.72 | wps 529746 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6650 | lr 0.000387783 | gnorm 0.632 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64233
2023-02-11 13:25:00 | INFO | fairseq.trainer | begin training epoch 1337
2023-02-11 13:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:25:40 | INFO | fairseq_cli.train | end of epoch 1337 (average epoch stats below)
2023-02-11 13:25:40 | INFO | train | epoch 1337 | loss 4.84 | ppl 28.65 | wps 511637 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6655 | lr 0.000387638 | gnorm 0.619 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64274
2023-02-11 13:25:41 | INFO | fairseq.trainer | begin training epoch 1338
2023-02-11 13:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:26:22 | INFO | fairseq_cli.train | end of epoch 1338 (average epoch stats below)
2023-02-11 13:26:22 | INFO | train | epoch 1338 | loss 4.837 | ppl 28.59 | wps 502241 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6660 | lr 0.000387492 | gnorm 0.615 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64316
2023-02-11 13:26:23 | INFO | fairseq.trainer | begin training epoch 1339
2023-02-11 13:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:27:02 | INFO | fairseq_cli.train | end of epoch 1339 (average epoch stats below)
2023-02-11 13:27:02 | INFO | train | epoch 1339 | loss 4.835 | ppl 28.54 | wps 527502 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6665 | lr 0.000387347 | gnorm 0.558 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64356
2023-02-11 13:27:03 | INFO | fairseq.trainer | begin training epoch 1340
2023-02-11 13:27:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:27:52 | INFO | valid | epoch 1340 | valid on 'valid' subset | loss 5.168 | ppl 35.94 | wps 0 | wpb 11230 | bsz 22 | num_updates 6670 | best_loss 5.113
2023-02-11 13:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1340 @ 6670 updates
2023-02-11 13:27:52 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1340.pt
2023-02-11 13:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1340.pt
2023-02-11 13:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1340.pt (epoch 1340 @ 6670 updates, score 5.168) (writing took 74.24527095799567 seconds)
2023-02-11 13:29:06 | INFO | fairseq_cli.train | end of epoch 1340 (average epoch stats below)
2023-02-11 13:29:06 | INFO | train | epoch 1340 | loss 4.834 | ppl 28.53 | wps 170079 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6670 | lr 0.000387202 | gnorm 0.542 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64480
2023-02-11 13:29:06 | INFO | fairseq.trainer | begin training epoch 1341
2023-02-11 13:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:30:36 | INFO | fairseq_cli.train | end of epoch 1341 (average epoch stats below)
2023-02-11 13:30:36 | INFO | train | epoch 1341 | loss 4.836 | ppl 28.55 | wps 232856 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6675 | lr 0.000387056 | gnorm 0.629 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64570
2023-02-11 13:30:37 | INFO | fairseq.trainer | begin training epoch 1342
2023-02-11 13:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:31:18 | INFO | fairseq_cli.train | end of epoch 1342 (average epoch stats below)
2023-02-11 13:31:18 | INFO | train | epoch 1342 | loss 4.841 | ppl 28.67 | wps 497644 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6680 | lr 0.000386912 | gnorm 0.792 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64612
2023-02-11 13:31:19 | INFO | fairseq.trainer | begin training epoch 1343
2023-02-11 13:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:31:59 | INFO | fairseq_cli.train | end of epoch 1343 (average epoch stats below)
2023-02-11 13:31:59 | INFO | train | epoch 1343 | loss 4.836 | ppl 28.56 | wps 523442 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6685 | lr 0.000386767 | gnorm 0.635 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64653
2023-02-11 13:31:59 | INFO | fairseq.trainer | begin training epoch 1344
2023-02-11 13:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:32:41 | INFO | fairseq_cli.train | end of epoch 1344 (average epoch stats below)
2023-02-11 13:32:41 | INFO | train | epoch 1344 | loss 4.833 | ppl 28.51 | wps 500369 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6690 | lr 0.000386622 | gnorm 0.595 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64695
2023-02-11 13:32:41 | INFO | fairseq.trainer | begin training epoch 1345
2023-02-11 13:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:33:21 | INFO | fairseq_cli.train | end of epoch 1345 (average epoch stats below)
2023-02-11 13:33:21 | INFO | train | epoch 1345 | loss 4.835 | ppl 28.55 | wps 521141 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6695 | lr 0.000386478 | gnorm 0.66 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64735
2023-02-11 13:33:21 | INFO | fairseq.trainer | begin training epoch 1346
2023-02-11 13:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:34:02 | INFO | train_inner | epoch 1346:      5 / 5 loss=4.84, ppl=28.65, wps=402812, ups=0.1, wpb=4.20675e+06, bsz=8216.4, num_updates=6700, lr=0.000386334, gnorm=0.644, loss_scale=1, train_wall=663, gb_free=5.6, wall=64776
2023-02-11 13:34:02 | INFO | fairseq_cli.train | end of epoch 1346 (average epoch stats below)
2023-02-11 13:34:02 | INFO | train | epoch 1346 | loss 4.831 | ppl 28.46 | wps 517460 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6700 | lr 0.000386334 | gnorm 0.556 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64776
2023-02-11 13:34:02 | INFO | fairseq.trainer | begin training epoch 1347
2023-02-11 13:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:34:44 | INFO | fairseq_cli.train | end of epoch 1347 (average epoch stats below)
2023-02-11 13:34:44 | INFO | train | epoch 1347 | loss 4.836 | ppl 28.57 | wps 501415 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6705 | lr 0.00038619 | gnorm 0.711 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 64818
2023-02-11 13:34:44 | INFO | fairseq.trainer | begin training epoch 1348
2023-02-11 13:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:35:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 13:35:24 | INFO | fairseq_cli.train | end of epoch 1348 (average epoch stats below)
2023-02-11 13:35:24 | INFO | train | epoch 1348 | loss 4.832 | ppl 28.47 | wps 388955 | ups 0.1 | wpb 3.96794e+06 | bsz 7750 | num_updates 6709 | lr 0.000386074 | gnorm 0.808 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64858
2023-02-11 13:35:25 | INFO | fairseq.trainer | begin training epoch 1349
2023-02-11 13:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:36:04 | INFO | fairseq_cli.train | end of epoch 1349 (average epoch stats below)
2023-02-11 13:36:04 | INFO | train | epoch 1349 | loss 4.841 | ppl 28.67 | wps 526343 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6714 | lr 0.000385931 | gnorm 0.783 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 64898
2023-02-11 13:36:05 | INFO | fairseq.trainer | begin training epoch 1350
2023-02-11 13:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:36:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:36:53 | INFO | valid | epoch 1350 | valid on 'valid' subset | loss 5.168 | ppl 35.95 | wps 0 | wpb 11230 | bsz 22 | num_updates 6719 | best_loss 5.113
2023-02-11 13:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1350 @ 6719 updates
2023-02-11 13:36:53 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1350.pt
2023-02-11 13:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1350.pt
2023-02-11 13:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1350.pt (epoch 1350 @ 6719 updates, score 5.168) (writing took 76.1895590859931 seconds)
2023-02-11 13:38:09 | INFO | fairseq_cli.train | end of epoch 1350 (average epoch stats below)
2023-02-11 13:38:09 | INFO | train | epoch 1350 | loss 4.835 | ppl 28.53 | wps 168172 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6719 | lr 0.000385787 | gnorm 0.587 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65024
2023-02-11 13:38:10 | INFO | fairseq.trainer | begin training epoch 1351
2023-02-11 13:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:39:39 | INFO | fairseq_cli.train | end of epoch 1351 (average epoch stats below)
2023-02-11 13:39:39 | INFO | train | epoch 1351 | loss 4.831 | ppl 28.46 | wps 234113 | ups 0.06 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6724 | lr 0.000385644 | gnorm 0.507 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65113
2023-02-11 13:39:40 | INFO | fairseq.trainer | begin training epoch 1352
2023-02-11 13:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:40:22 | INFO | fairseq_cli.train | end of epoch 1352 (average epoch stats below)
2023-02-11 13:40:22 | INFO | train | epoch 1352 | loss 4.829 | ppl 28.43 | wps 496010 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6729 | lr 0.0003855 | gnorm 0.568 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65156
2023-02-11 13:40:22 | INFO | fairseq.trainer | begin training epoch 1353
2023-02-11 13:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:41:02 | INFO | fairseq_cli.train | end of epoch 1353 (average epoch stats below)
2023-02-11 13:41:02 | INFO | train | epoch 1353 | loss 4.829 | ppl 28.42 | wps 516805 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6734 | lr 0.000385357 | gnorm 0.594 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65196
2023-02-11 13:41:03 | INFO | fairseq.trainer | begin training epoch 1354
2023-02-11 13:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:41:43 | INFO | fairseq_cli.train | end of epoch 1354 (average epoch stats below)
2023-02-11 13:41:43 | INFO | train | epoch 1354 | loss 4.829 | ppl 28.42 | wps 514007 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6739 | lr 0.000385214 | gnorm 0.635 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65237
2023-02-11 13:41:44 | INFO | fairseq.trainer | begin training epoch 1355
2023-02-11 13:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:42:23 | INFO | fairseq_cli.train | end of epoch 1355 (average epoch stats below)
2023-02-11 13:42:23 | INFO | train | epoch 1355 | loss 4.828 | ppl 28.4 | wps 528746 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6744 | lr 0.000385071 | gnorm 0.584 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65277
2023-02-11 13:42:23 | INFO | fairseq.trainer | begin training epoch 1356
2023-02-11 13:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:43:05 | INFO | fairseq_cli.train | end of epoch 1356 (average epoch stats below)
2023-02-11 13:43:05 | INFO | train | epoch 1356 | loss 4.828 | ppl 28.39 | wps 506156 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6749 | lr 0.000384929 | gnorm 0.678 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65319
2023-02-11 13:43:05 | INFO | fairseq.trainer | begin training epoch 1357
2023-02-11 13:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:43:47 | INFO | fairseq_cli.train | end of epoch 1357 (average epoch stats below)
2023-02-11 13:43:47 | INFO | train | epoch 1357 | loss 4.828 | ppl 28.41 | wps 500468 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6754 | lr 0.000384786 | gnorm 0.671 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65361
2023-02-11 13:43:47 | INFO | fairseq.trainer | begin training epoch 1358
2023-02-11 13:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:44:26 | INFO | fairseq_cli.train | end of epoch 1358 (average epoch stats below)
2023-02-11 13:44:26 | INFO | train | epoch 1358 | loss 4.831 | ppl 28.47 | wps 531999 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6759 | lr 0.000384644 | gnorm 0.765 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65400
2023-02-11 13:44:27 | INFO | fairseq.trainer | begin training epoch 1359
2023-02-11 13:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:45:08 | INFO | fairseq_cli.train | end of epoch 1359 (average epoch stats below)
2023-02-11 13:45:08 | INFO | train | epoch 1359 | loss 4.826 | ppl 28.37 | wps 508135 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6764 | lr 0.000384502 | gnorm 0.619 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65442
2023-02-11 13:45:08 | INFO | fairseq.trainer | begin training epoch 1360
2023-02-11 13:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:45:56 | INFO | valid | epoch 1360 | valid on 'valid' subset | loss 5.177 | ppl 36.18 | wps 0 | wpb 11230 | bsz 22 | num_updates 6769 | best_loss 5.113
2023-02-11 13:45:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1360 @ 6769 updates
2023-02-11 13:45:56 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1360.pt
2023-02-11 13:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1360.pt
2023-02-11 13:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1360.pt (epoch 1360 @ 6769 updates, score 5.177) (writing took 68.30091762900702 seconds)
2023-02-11 13:47:04 | INFO | fairseq_cli.train | end of epoch 1360 (average epoch stats below)
2023-02-11 13:47:04 | INFO | train | epoch 1360 | loss 4.829 | ppl 28.42 | wps 180613 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6769 | lr 0.00038436 | gnorm 0.731 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65558
2023-02-11 13:47:04 | INFO | fairseq.trainer | begin training epoch 1361
2023-02-11 13:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:48:04 | INFO | fairseq_cli.train | end of epoch 1361 (average epoch stats below)
2023-02-11 13:48:04 | INFO | train | epoch 1361 | loss 4.824 | ppl 28.32 | wps 349164 | ups 0.08 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6774 | lr 0.000384218 | gnorm 0.554 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65618
2023-02-11 13:48:08 | INFO | fairseq.trainer | begin training epoch 1362
2023-02-11 13:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:48:49 | INFO | fairseq_cli.train | end of epoch 1362 (average epoch stats below)
2023-02-11 13:48:49 | INFO | train | epoch 1362 | loss 4.822 | ppl 28.29 | wps 470270 | ups 0.11 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6779 | lr 0.000384076 | gnorm 0.574 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65663
2023-02-11 13:48:49 | INFO | fairseq.trainer | begin training epoch 1363
2023-02-11 13:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:49:29 | INFO | fairseq_cli.train | end of epoch 1363 (average epoch stats below)
2023-02-11 13:49:29 | INFO | train | epoch 1363 | loss 4.826 | ppl 28.37 | wps 527272 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6784 | lr 0.000383934 | gnorm 0.771 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65703
2023-02-11 13:49:29 | INFO | fairseq.trainer | begin training epoch 1364
2023-02-11 13:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:50:10 | INFO | fairseq_cli.train | end of epoch 1364 (average epoch stats below)
2023-02-11 13:50:10 | INFO | train | epoch 1364 | loss 4.83 | ppl 28.44 | wps 509799 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6789 | lr 0.000383793 | gnorm 0.775 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65744
2023-02-11 13:50:11 | INFO | fairseq.trainer | begin training epoch 1365
2023-02-11 13:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:50:51 | INFO | fairseq_cli.train | end of epoch 1365 (average epoch stats below)
2023-02-11 13:50:51 | INFO | train | epoch 1365 | loss 4.821 | ppl 28.26 | wps 512797 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6794 | lr 0.000383652 | gnorm 0.536 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65785
2023-02-11 13:50:52 | INFO | fairseq.trainer | begin training epoch 1366
2023-02-11 13:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:51:31 | INFO | fairseq_cli.train | end of epoch 1366 (average epoch stats below)
2023-02-11 13:51:31 | INFO | train | epoch 1366 | loss 4.82 | ppl 28.25 | wps 523621 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6799 | lr 0.000383511 | gnorm 0.59 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65825
2023-02-11 13:51:32 | INFO | fairseq.trainer | begin training epoch 1367
2023-02-11 13:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:51:48 | INFO | train_inner | epoch 1367:      1 / 5 loss=4.828, ppl=28.41, wps=394682, ups=0.09, wpb=4.20675e+06, bsz=8216.4, num_updates=6800, lr=0.000383482, gnorm=0.649, loss_scale=0.5, train_wall=669, gb_free=5.4, wall=65842
2023-02-11 13:52:13 | INFO | fairseq_cli.train | end of epoch 1367 (average epoch stats below)
2023-02-11 13:52:13 | INFO | train | epoch 1367 | loss 4.821 | ppl 28.28 | wps 507821 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6804 | lr 0.00038337 | gnorm 0.682 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65867
2023-02-11 13:52:13 | INFO | fairseq.trainer | begin training epoch 1368
2023-02-11 13:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:52:54 | INFO | fairseq_cli.train | end of epoch 1368 (average epoch stats below)
2023-02-11 13:52:54 | INFO | train | epoch 1368 | loss 4.822 | ppl 28.29 | wps 507757 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6809 | lr 0.000383229 | gnorm 0.708 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65908
2023-02-11 13:52:55 | INFO | fairseq.trainer | begin training epoch 1369
2023-02-11 13:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:53:35 | INFO | fairseq_cli.train | end of epoch 1369 (average epoch stats below)
2023-02-11 13:53:35 | INFO | train | epoch 1369 | loss 4.821 | ppl 28.26 | wps 517575 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6814 | lr 0.000383088 | gnorm 0.673 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 65949
2023-02-11 13:53:35 | INFO | fairseq.trainer | begin training epoch 1370
2023-02-11 13:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 13:54:23 | INFO | valid | epoch 1370 | valid on 'valid' subset | loss 5.21 | ppl 37.01 | wps 0 | wpb 11230 | bsz 22 | num_updates 6819 | best_loss 5.113
2023-02-11 13:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1370 @ 6819 updates
2023-02-11 13:54:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1370.pt
2023-02-11 13:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1370.pt
2023-02-11 13:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1370.pt (epoch 1370 @ 6819 updates, score 5.21) (writing took 74.17851068201708 seconds)
2023-02-11 13:55:37 | INFO | fairseq_cli.train | end of epoch 1370 (average epoch stats below)
2023-02-11 13:55:37 | INFO | train | epoch 1370 | loss 4.823 | ppl 28.3 | wps 171686 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6819 | lr 0.000382948 | gnorm 0.721 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66071
2023-02-11 13:55:38 | INFO | fairseq.trainer | begin training epoch 1371
2023-02-11 13:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:57:09 | INFO | fairseq_cli.train | end of epoch 1371 (average epoch stats below)
2023-02-11 13:57:09 | INFO | train | epoch 1371 | loss 4.818 | ppl 28.21 | wps 229582 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6824 | lr 0.000382808 | gnorm 0.575 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66163
2023-02-11 13:57:09 | INFO | fairseq.trainer | begin training epoch 1372
2023-02-11 13:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:57:51 | INFO | fairseq_cli.train | end of epoch 1372 (average epoch stats below)
2023-02-11 13:57:51 | INFO | train | epoch 1372 | loss 4.817 | ppl 28.18 | wps 505181 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6829 | lr 0.000382667 | gnorm 0.594 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66205
2023-02-11 13:57:51 | INFO | fairseq.trainer | begin training epoch 1373
2023-02-11 13:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:58:32 | INFO | fairseq_cli.train | end of epoch 1373 (average epoch stats below)
2023-02-11 13:58:32 | INFO | train | epoch 1373 | loss 4.816 | ppl 28.18 | wps 514118 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6834 | lr 0.000382527 | gnorm 0.626 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66246
2023-02-11 13:58:32 | INFO | fairseq.trainer | begin training epoch 1374
2023-02-11 13:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:59:14 | INFO | fairseq_cli.train | end of epoch 1374 (average epoch stats below)
2023-02-11 13:59:14 | INFO | train | epoch 1374 | loss 4.813 | ppl 28.12 | wps 498663 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6839 | lr 0.000382388 | gnorm 0.55 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66288
2023-02-11 13:59:14 | INFO | fairseq.trainer | begin training epoch 1375
2023-02-11 13:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 13:59:54 | INFO | fairseq_cli.train | end of epoch 1375 (average epoch stats below)
2023-02-11 13:59:54 | INFO | train | epoch 1375 | loss 4.811 | ppl 28.08 | wps 524465 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6844 | lr 0.000382248 | gnorm 0.53 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66328
2023-02-11 13:59:54 | INFO | fairseq.trainer | begin training epoch 1376
2023-02-11 13:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:00:34 | INFO | fairseq_cli.train | end of epoch 1376 (average epoch stats below)
2023-02-11 14:00:34 | INFO | train | epoch 1376 | loss 4.813 | ppl 28.12 | wps 523851 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6849 | lr 0.000382108 | gnorm 0.674 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66368
2023-02-11 14:00:34 | INFO | fairseq.trainer | begin training epoch 1377
2023-02-11 14:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:01:16 | INFO | fairseq_cli.train | end of epoch 1377 (average epoch stats below)
2023-02-11 14:01:16 | INFO | train | epoch 1377 | loss 4.818 | ppl 28.21 | wps 500891 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6854 | lr 0.000381969 | gnorm 0.745 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66410
2023-02-11 14:01:16 | INFO | fairseq.trainer | begin training epoch 1378
2023-02-11 14:01:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:01:56 | INFO | fairseq_cli.train | end of epoch 1378 (average epoch stats below)
2023-02-11 14:01:56 | INFO | train | epoch 1378 | loss 4.817 | ppl 28.19 | wps 520518 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6859 | lr 0.00038183 | gnorm 0.751 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66450
2023-02-11 14:01:57 | INFO | fairseq.trainer | begin training epoch 1379
2023-02-11 14:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:02:37 | INFO | fairseq_cli.train | end of epoch 1379 (average epoch stats below)
2023-02-11 14:02:37 | INFO | train | epoch 1379 | loss 4.817 | ppl 28.19 | wps 522796 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6864 | lr 0.000381691 | gnorm 0.662 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66491
2023-02-11 14:02:37 | INFO | fairseq.trainer | begin training epoch 1380
2023-02-11 14:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:03:25 | INFO | valid | epoch 1380 | valid on 'valid' subset | loss 5.223 | ppl 37.34 | wps 0 | wpb 11230 | bsz 22 | num_updates 6869 | best_loss 5.113
2023-02-11 14:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1380 @ 6869 updates
2023-02-11 14:03:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1380.pt
2023-02-11 14:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1380.pt
2023-02-11 14:04:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1380.pt (epoch 1380 @ 6869 updates, score 5.223) (writing took 66.88485395899625 seconds)
2023-02-11 14:04:32 | INFO | fairseq_cli.train | end of epoch 1380 (average epoch stats below)
2023-02-11 14:04:32 | INFO | train | epoch 1380 | loss 4.814 | ppl 28.12 | wps 181856 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6869 | lr 0.000381552 | gnorm 0.626 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66606
2023-02-11 14:04:33 | INFO | fairseq.trainer | begin training epoch 1381
2023-02-11 14:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:06:05 | INFO | fairseq_cli.train | end of epoch 1381 (average epoch stats below)
2023-02-11 14:06:05 | INFO | train | epoch 1381 | loss 4.821 | ppl 28.26 | wps 227751 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6874 | lr 0.000381413 | gnorm 0.787 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66699
2023-02-11 14:06:06 | INFO | fairseq.trainer | begin training epoch 1382
2023-02-11 14:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:06:47 | INFO | fairseq_cli.train | end of epoch 1382 (average epoch stats below)
2023-02-11 14:06:47 | INFO | train | epoch 1382 | loss 4.814 | ppl 28.13 | wps 492295 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6879 | lr 0.000381274 | gnorm 0.612 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66741
2023-02-11 14:06:48 | INFO | fairseq.trainer | begin training epoch 1383
2023-02-11 14:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:07:30 | INFO | fairseq_cli.train | end of epoch 1383 (average epoch stats below)
2023-02-11 14:07:30 | INFO | train | epoch 1383 | loss 4.809 | ppl 28.02 | wps 495299 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6884 | lr 0.000381136 | gnorm 0.519 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66784
2023-02-11 14:07:30 | INFO | fairseq.trainer | begin training epoch 1384
2023-02-11 14:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:08:10 | INFO | fairseq_cli.train | end of epoch 1384 (average epoch stats below)
2023-02-11 14:08:10 | INFO | train | epoch 1384 | loss 4.808 | ppl 28.01 | wps 523646 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6889 | lr 0.000380997 | gnorm 0.537 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66824
2023-02-11 14:08:10 | INFO | fairseq.trainer | begin training epoch 1385
2023-02-11 14:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:08:51 | INFO | fairseq_cli.train | end of epoch 1385 (average epoch stats below)
2023-02-11 14:08:51 | INFO | train | epoch 1385 | loss 4.808 | ppl 28.01 | wps 515808 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6894 | lr 0.000380859 | gnorm 0.63 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66865
2023-02-11 14:08:51 | INFO | fairseq.trainer | begin training epoch 1386
2023-02-11 14:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:09:33 | INFO | fairseq_cli.train | end of epoch 1386 (average epoch stats below)
2023-02-11 14:09:33 | INFO | train | epoch 1386 | loss 4.814 | ppl 28.14 | wps 502249 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6899 | lr 0.000380721 | gnorm 0.769 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66907
2023-02-11 14:09:33 | INFO | fairseq.trainer | begin training epoch 1387
2023-02-11 14:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:09:48 | INFO | train_inner | epoch 1387:      1 / 5 loss=4.816, ppl=28.17, wps=389362, ups=0.09, wpb=4.20736e+06, bsz=8217.6, num_updates=6900, lr=0.000380693, gnorm=0.651, loss_scale=0.5, train_wall=662, gb_free=5.4, wall=66922
2023-02-11 14:10:13 | INFO | fairseq_cli.train | end of epoch 1387 (average epoch stats below)
2023-02-11 14:10:13 | INFO | train | epoch 1387 | loss 4.813 | ppl 28.11 | wps 515819 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6904 | lr 0.000380583 | gnorm 0.73 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66948
2023-02-11 14:10:14 | INFO | fairseq.trainer | begin training epoch 1388
2023-02-11 14:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:10:54 | INFO | fairseq_cli.train | end of epoch 1388 (average epoch stats below)
2023-02-11 14:10:54 | INFO | train | epoch 1388 | loss 4.813 | ppl 28.12 | wps 521646 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6909 | lr 0.000380445 | gnorm 0.721 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 66988
2023-02-11 14:10:54 | INFO | fairseq.trainer | begin training epoch 1389
2023-02-11 14:10:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:11:35 | INFO | fairseq_cli.train | end of epoch 1389 (average epoch stats below)
2023-02-11 14:11:35 | INFO | train | epoch 1389 | loss 4.809 | ppl 28.03 | wps 508402 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6914 | lr 0.000380308 | gnorm 0.657 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67029
2023-02-11 14:11:35 | INFO | fairseq.trainer | begin training epoch 1390
2023-02-11 14:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:12:23 | INFO | valid | epoch 1390 | valid on 'valid' subset | loss 5.203 | ppl 36.84 | wps 0 | wpb 11230 | bsz 22 | num_updates 6919 | best_loss 5.113
2023-02-11 14:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1390 @ 6919 updates
2023-02-11 14:12:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1390.pt
2023-02-11 14:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1390.pt
2023-02-11 14:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1390.pt (epoch 1390 @ 6919 updates, score 5.203) (writing took 66.2640902629937 seconds)
2023-02-11 14:13:29 | INFO | fairseq_cli.train | end of epoch 1390 (average epoch stats below)
2023-02-11 14:13:29 | INFO | train | epoch 1390 | loss 4.808 | ppl 28.01 | wps 184346 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6919 | lr 0.00038017 | gnorm 0.629 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67143
2023-02-11 14:13:30 | INFO | fairseq.trainer | begin training epoch 1391
2023-02-11 14:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:14:26 | INFO | fairseq_cli.train | end of epoch 1391 (average epoch stats below)
2023-02-11 14:14:26 | INFO | train | epoch 1391 | loss 4.807 | ppl 27.99 | wps 371601 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6924 | lr 0.000380033 | gnorm 0.588 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67200
2023-02-11 14:14:26 | INFO | fairseq.trainer | begin training epoch 1392
2023-02-11 14:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:15:05 | INFO | fairseq_cli.train | end of epoch 1392 (average epoch stats below)
2023-02-11 14:15:05 | INFO | train | epoch 1392 | loss 4.806 | ppl 27.98 | wps 539991 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6929 | lr 0.000379896 | gnorm 0.664 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67239
2023-02-11 14:15:05 | INFO | fairseq.trainer | begin training epoch 1393
2023-02-11 14:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:15:46 | INFO | fairseq_cli.train | end of epoch 1393 (average epoch stats below)
2023-02-11 14:15:46 | INFO | train | epoch 1393 | loss 4.811 | ppl 28.07 | wps 510234 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6934 | lr 0.000379759 | gnorm 0.785 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67280
2023-02-11 14:15:46 | INFO | fairseq.trainer | begin training epoch 1394
2023-02-11 14:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:16:28 | INFO | fairseq_cli.train | end of epoch 1394 (average epoch stats below)
2023-02-11 14:16:28 | INFO | train | epoch 1394 | loss 4.808 | ppl 28.01 | wps 504570 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6939 | lr 0.000379622 | gnorm 0.642 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67322
2023-02-11 14:16:28 | INFO | fairseq.trainer | begin training epoch 1395
2023-02-11 14:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:17:08 | INFO | fairseq_cli.train | end of epoch 1395 (average epoch stats below)
2023-02-11 14:17:08 | INFO | train | epoch 1395 | loss 4.805 | ppl 27.95 | wps 526696 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6944 | lr 0.000379485 | gnorm 0.634 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67362
2023-02-11 14:17:08 | INFO | fairseq.trainer | begin training epoch 1396
2023-02-11 14:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:17:49 | INFO | fairseq_cli.train | end of epoch 1396 (average epoch stats below)
2023-02-11 14:17:49 | INFO | train | epoch 1396 | loss 4.803 | ppl 27.92 | wps 508690 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6949 | lr 0.000379349 | gnorm 0.578 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67403
2023-02-11 14:17:49 | INFO | fairseq.trainer | begin training epoch 1397
2023-02-11 14:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:18:30 | INFO | fairseq_cli.train | end of epoch 1397 (average epoch stats below)
2023-02-11 14:18:30 | INFO | train | epoch 1397 | loss 4.801 | ppl 27.87 | wps 510839 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6954 | lr 0.000379213 | gnorm 0.512 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67444
2023-02-11 14:18:31 | INFO | fairseq.trainer | begin training epoch 1398
2023-02-11 14:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:19:11 | INFO | fairseq_cli.train | end of epoch 1398 (average epoch stats below)
2023-02-11 14:19:11 | INFO | train | epoch 1398 | loss 4.8 | ppl 27.86 | wps 520220 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6959 | lr 0.000379076 | gnorm 0.594 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67485
2023-02-11 14:19:11 | INFO | fairseq.trainer | begin training epoch 1399
2023-02-11 14:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:19:52 | INFO | fairseq_cli.train | end of epoch 1399 (average epoch stats below)
2023-02-11 14:19:52 | INFO | train | epoch 1399 | loss 4.809 | ppl 28.03 | wps 510035 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6964 | lr 0.00037894 | gnorm 0.8 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67526
2023-02-11 14:19:52 | INFO | fairseq.trainer | begin training epoch 1400
2023-02-11 14:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:20:39 | INFO | valid | epoch 1400 | valid on 'valid' subset | loss 5.183 | ppl 36.33 | wps 0 | wpb 11230 | bsz 22 | num_updates 6969 | best_loss 5.113
2023-02-11 14:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1400 @ 6969 updates
2023-02-11 14:20:39 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1400.pt
2023-02-11 14:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1400.pt
2023-02-11 14:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1400.pt (epoch 1400 @ 6969 updates, score 5.183) (writing took 64.85290708998218 seconds)
2023-02-11 14:21:44 | INFO | fairseq_cli.train | end of epoch 1400 (average epoch stats below)
2023-02-11 14:21:44 | INFO | train | epoch 1400 | loss 4.805 | ppl 27.96 | wps 187557 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6969 | lr 0.000378804 | gnorm 0.676 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67638
2023-02-11 14:21:44 | INFO | fairseq.trainer | begin training epoch 1401
2023-02-11 14:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:22:36 | INFO | fairseq_cli.train | end of epoch 1401 (average epoch stats below)
2023-02-11 14:22:36 | INFO | train | epoch 1401 | loss 4.809 | ppl 28.03 | wps 406524 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6974 | lr 0.000378668 | gnorm 0.824 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67690
2023-02-11 14:22:36 | INFO | fairseq.trainer | begin training epoch 1402
2023-02-11 14:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:23:16 | INFO | fairseq_cli.train | end of epoch 1402 (average epoch stats below)
2023-02-11 14:23:16 | INFO | train | epoch 1402 | loss 4.804 | ppl 27.93 | wps 522293 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6979 | lr 0.000378533 | gnorm 0.631 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67730
2023-02-11 14:23:16 | INFO | fairseq.trainer | begin training epoch 1403
2023-02-11 14:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:23:58 | INFO | fairseq_cli.train | end of epoch 1403 (average epoch stats below)
2023-02-11 14:23:58 | INFO | train | epoch 1403 | loss 4.8 | ppl 27.85 | wps 503380 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6984 | lr 0.000378397 | gnorm 0.575 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67772
2023-02-11 14:23:58 | INFO | fairseq.trainer | begin training epoch 1404
2023-02-11 14:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:24:39 | INFO | fairseq_cli.train | end of epoch 1404 (average epoch stats below)
2023-02-11 14:24:39 | INFO | train | epoch 1404 | loss 4.797 | ppl 27.8 | wps 507925 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6989 | lr 0.000378262 | gnorm 0.523 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67813
2023-02-11 14:24:40 | INFO | fairseq.trainer | begin training epoch 1405
2023-02-11 14:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:25:19 | INFO | fairseq_cli.train | end of epoch 1405 (average epoch stats below)
2023-02-11 14:25:19 | INFO | train | epoch 1405 | loss 4.798 | ppl 27.82 | wps 527899 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6994 | lr 0.000378127 | gnorm 0.65 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67853
2023-02-11 14:25:20 | INFO | fairseq.trainer | begin training epoch 1406
2023-02-11 14:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:26:01 | INFO | fairseq_cli.train | end of epoch 1406 (average epoch stats below)
2023-02-11 14:26:01 | INFO | train | epoch 1406 | loss 4.802 | ppl 27.9 | wps 508007 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 6999 | lr 0.000377991 | gnorm 0.77 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 67895
2023-02-11 14:26:01 | INFO | fairseq.trainer | begin training epoch 1407
2023-02-11 14:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:26:17 | INFO | train_inner | epoch 1407:      1 / 5 loss=4.805, ppl=27.96, wps=425562, ups=0.1, wpb=4.20696e+06, bsz=8216.8, num_updates=7000, lr=0.000377964, gnorm=0.659, loss_scale=1, train_wall=662, gb_free=5.4, wall=67911
2023-02-11 14:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 14:26:42 | INFO | fairseq_cli.train | end of epoch 1407 (average epoch stats below)
2023-02-11 14:26:42 | INFO | train | epoch 1407 | loss 4.805 | ppl 27.96 | wps 381168 | ups 0.1 | wpb 3.95284e+06 | bsz 7720.5 | num_updates 7003 | lr 0.000377884 | gnorm 0.804 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67936
2023-02-11 14:26:42 | INFO | fairseq.trainer | begin training epoch 1408
2023-02-11 14:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:27:22 | INFO | fairseq_cli.train | end of epoch 1408 (average epoch stats below)
2023-02-11 14:27:22 | INFO | train | epoch 1408 | loss 4.806 | ppl 27.97 | wps 527775 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7008 | lr 0.000377749 | gnorm 0.766 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 67976
2023-02-11 14:27:22 | INFO | fairseq.trainer | begin training epoch 1409
2023-02-11 14:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:28:03 | INFO | fairseq_cli.train | end of epoch 1409 (average epoch stats below)
2023-02-11 14:28:03 | INFO | train | epoch 1409 | loss 4.802 | ppl 27.9 | wps 506359 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7013 | lr 0.000377614 | gnorm 0.691 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68017
2023-02-11 14:28:04 | INFO | fairseq.trainer | begin training epoch 1410
2023-02-11 14:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:28:51 | INFO | valid | epoch 1410 | valid on 'valid' subset | loss 5.227 | ppl 37.46 | wps 0 | wpb 11230 | bsz 22 | num_updates 7018 | best_loss 5.113
2023-02-11 14:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1410 @ 7018 updates
2023-02-11 14:28:51 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1410.pt
2023-02-11 14:28:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1410.pt
2023-02-11 14:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1410.pt (epoch 1410 @ 7018 updates, score 5.227) (writing took 70.44597804601653 seconds)
2023-02-11 14:30:02 | INFO | fairseq_cli.train | end of epoch 1410 (average epoch stats below)
2023-02-11 14:30:02 | INFO | train | epoch 1410 | loss 4.798 | ppl 27.82 | wps 178038 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7018 | lr 0.000377479 | gnorm 0.608 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68136
2023-02-11 14:30:02 | INFO | fairseq.trainer | begin training epoch 1411
2023-02-11 14:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:31:35 | INFO | fairseq_cli.train | end of epoch 1411 (average epoch stats below)
2023-02-11 14:31:35 | INFO | train | epoch 1411 | loss 4.797 | ppl 27.8 | wps 223876 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7023 | lr 0.000377345 | gnorm 0.604 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68230
2023-02-11 14:31:37 | INFO | fairseq.trainer | begin training epoch 1412
2023-02-11 14:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:32:18 | INFO | fairseq_cli.train | end of epoch 1412 (average epoch stats below)
2023-02-11 14:32:18 | INFO | train | epoch 1412 | loss 4.794 | ppl 27.75 | wps 489183 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7028 | lr 0.000377211 | gnorm 0.579 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68273
2023-02-11 14:32:19 | INFO | fairseq.trainer | begin training epoch 1413
2023-02-11 14:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:33:01 | INFO | fairseq_cli.train | end of epoch 1413 (average epoch stats below)
2023-02-11 14:33:01 | INFO | train | epoch 1413 | loss 4.797 | ppl 27.81 | wps 491367 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7033 | lr 0.000377077 | gnorm 0.716 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68315
2023-02-11 14:33:02 | INFO | fairseq.trainer | begin training epoch 1414
2023-02-11 14:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:33:42 | INFO | fairseq_cli.train | end of epoch 1414 (average epoch stats below)
2023-02-11 14:33:42 | INFO | train | epoch 1414 | loss 4.797 | ppl 27.81 | wps 519442 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7038 | lr 0.000376943 | gnorm 0.739 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68356
2023-02-11 14:33:42 | INFO | fairseq.trainer | begin training epoch 1415
2023-02-11 14:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:34:21 | INFO | fairseq_cli.train | end of epoch 1415 (average epoch stats below)
2023-02-11 14:34:21 | INFO | train | epoch 1415 | loss 4.796 | ppl 27.79 | wps 531578 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7043 | lr 0.000376809 | gnorm 0.624 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68395
2023-02-11 14:34:22 | INFO | fairseq.trainer | begin training epoch 1416
2023-02-11 14:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:35:04 | INFO | fairseq_cli.train | end of epoch 1416 (average epoch stats below)
2023-02-11 14:35:04 | INFO | train | epoch 1416 | loss 4.791 | ppl 27.69 | wps 491938 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7048 | lr 0.000376675 | gnorm 0.53 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68438
2023-02-11 14:35:04 | INFO | fairseq.trainer | begin training epoch 1417
2023-02-11 14:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:35:44 | INFO | fairseq_cli.train | end of epoch 1417 (average epoch stats below)
2023-02-11 14:35:44 | INFO | train | epoch 1417 | loss 4.793 | ppl 27.73 | wps 523266 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7053 | lr 0.000376542 | gnorm 0.681 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68478
2023-02-11 14:35:45 | INFO | fairseq.trainer | begin training epoch 1418
2023-02-11 14:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:36:25 | INFO | fairseq_cli.train | end of epoch 1418 (average epoch stats below)
2023-02-11 14:36:25 | INFO | train | epoch 1418 | loss 4.791 | ppl 27.69 | wps 515119 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7058 | lr 0.000376408 | gnorm 0.574 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68519
2023-02-11 14:36:26 | INFO | fairseq.trainer | begin training epoch 1419
2023-02-11 14:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:37:07 | INFO | fairseq_cli.train | end of epoch 1419 (average epoch stats below)
2023-02-11 14:37:07 | INFO | train | epoch 1419 | loss 4.79 | ppl 27.66 | wps 504898 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7063 | lr 0.000376275 | gnorm 0.557 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68561
2023-02-11 14:37:07 | INFO | fairseq.trainer | begin training epoch 1420
2023-02-11 14:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:37:57 | INFO | valid | epoch 1420 | valid on 'valid' subset | loss 5.221 | ppl 37.29 | wps 0 | wpb 11230 | bsz 22 | num_updates 7068 | best_loss 5.113
2023-02-11 14:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1420 @ 7068 updates
2023-02-11 14:37:57 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1420.pt
2023-02-11 14:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1420.pt
2023-02-11 14:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1420.pt (epoch 1420 @ 7068 updates, score 5.221) (writing took 111.36372129700612 seconds)
2023-02-11 14:39:48 | INFO | fairseq_cli.train | end of epoch 1420 (average epoch stats below)
2023-02-11 14:39:48 | INFO | train | epoch 1420 | loss 4.801 | ppl 27.87 | wps 130588 | ups 0.03 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7068 | lr 0.000376142 | gnorm 0.924 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68722
2023-02-11 14:39:48 | INFO | fairseq.trainer | begin training epoch 1421
2023-02-11 14:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:41:53 | INFO | fairseq_cli.train | end of epoch 1421 (average epoch stats below)
2023-02-11 14:41:53 | INFO | train | epoch 1421 | loss 4.801 | ppl 27.87 | wps 167953 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7073 | lr 0.000376009 | gnorm 0.806 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68847
2023-02-11 14:41:54 | INFO | fairseq.trainer | begin training epoch 1422
2023-02-11 14:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:42:36 | INFO | fairseq_cli.train | end of epoch 1422 (average epoch stats below)
2023-02-11 14:42:36 | INFO | train | epoch 1422 | loss 4.795 | ppl 27.77 | wps 493100 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7078 | lr 0.000375876 | gnorm 0.688 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68890
2023-02-11 14:42:36 | INFO | fairseq.trainer | begin training epoch 1423
2023-02-11 14:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:43:16 | INFO | fairseq_cli.train | end of epoch 1423 (average epoch stats below)
2023-02-11 14:43:16 | INFO | train | epoch 1423 | loss 4.791 | ppl 27.69 | wps 522992 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7083 | lr 0.000375743 | gnorm 0.604 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68930
2023-02-11 14:43:16 | INFO | fairseq.trainer | begin training epoch 1424
2023-02-11 14:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:43:56 | INFO | fairseq_cli.train | end of epoch 1424 (average epoch stats below)
2023-02-11 14:43:56 | INFO | train | epoch 1424 | loss 4.788 | ppl 27.63 | wps 524112 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7088 | lr 0.000375611 | gnorm 0.58 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 68970
2023-02-11 14:43:56 | INFO | fairseq.trainer | begin training epoch 1425
2023-02-11 14:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:44:37 | INFO | fairseq_cli.train | end of epoch 1425 (average epoch stats below)
2023-02-11 14:44:37 | INFO | train | epoch 1425 | loss 4.784 | ppl 27.56 | wps 517985 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7093 | lr 0.000375478 | gnorm 0.516 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69011
2023-02-11 14:44:37 | INFO | fairseq.trainer | begin training epoch 1426
2023-02-11 14:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:45:18 | INFO | fairseq_cli.train | end of epoch 1426 (average epoch stats below)
2023-02-11 14:45:18 | INFO | train | epoch 1426 | loss 4.786 | ppl 27.58 | wps 509832 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7098 | lr 0.000375346 | gnorm 0.618 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69052
2023-02-11 14:45:18 | INFO | fairseq.trainer | begin training epoch 1427
2023-02-11 14:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:45:41 | INFO | train_inner | epoch 1427:      2 / 5 loss=4.794, ppl=27.75, wps=361167, ups=0.09, wpb=4.20615e+06, bsz=8215.2, num_updates=7100, lr=0.000375293, gnorm=0.658, loss_scale=0.5, train_wall=671, gb_free=5.4, wall=69075
2023-02-11 14:45:58 | INFO | fairseq_cli.train | end of epoch 1427 (average epoch stats below)
2023-02-11 14:45:58 | INFO | train | epoch 1427 | loss 4.787 | ppl 27.61 | wps 521151 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7103 | lr 0.000375214 | gnorm 0.687 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69092
2023-02-11 14:45:59 | INFO | fairseq.trainer | begin training epoch 1428
2023-02-11 14:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:46:39 | INFO | fairseq_cli.train | end of epoch 1428 (average epoch stats below)
2023-02-11 14:46:39 | INFO | train | epoch 1428 | loss 4.785 | ppl 27.57 | wps 523943 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7108 | lr 0.000375082 | gnorm 0.655 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69133
2023-02-11 14:46:39 | INFO | fairseq.trainer | begin training epoch 1429
2023-02-11 14:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:47:22 | INFO | fairseq_cli.train | end of epoch 1429 (average epoch stats below)
2023-02-11 14:47:22 | INFO | train | epoch 1429 | loss 4.787 | ppl 27.6 | wps 489324 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7113 | lr 0.00037495 | gnorm 0.683 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69176
2023-02-11 14:47:22 | INFO | fairseq.trainer | begin training epoch 1430
2023-02-11 14:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:48:08 | INFO | valid | epoch 1430 | valid on 'valid' subset | loss 5.195 | ppl 36.64 | wps 0 | wpb 11230 | bsz 22 | num_updates 7118 | best_loss 5.113
2023-02-11 14:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1430 @ 7118 updates
2023-02-11 14:48:08 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1430.pt
2023-02-11 14:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1430.pt
2023-02-11 14:49:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1430.pt (epoch 1430 @ 7118 updates, score 5.195) (writing took 67.45732188900001 seconds)
2023-02-11 14:49:15 | INFO | fairseq_cli.train | end of epoch 1430 (average epoch stats below)
2023-02-11 14:49:15 | INFO | train | epoch 1430 | loss 4.784 | ppl 27.54 | wps 184674 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7118 | lr 0.000374818 | gnorm 0.619 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69289
2023-02-11 14:49:16 | INFO | fairseq.trainer | begin training epoch 1431
2023-02-11 14:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:50:07 | INFO | fairseq_cli.train | end of epoch 1431 (average epoch stats below)
2023-02-11 14:50:07 | INFO | train | epoch 1431 | loss 4.787 | ppl 27.6 | wps 411397 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7123 | lr 0.000374687 | gnorm 0.733 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69341
2023-02-11 14:50:11 | INFO | fairseq.trainer | begin training epoch 1432
2023-02-11 14:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:50:50 | INFO | fairseq_cli.train | end of epoch 1432 (average epoch stats below)
2023-02-11 14:50:50 | INFO | train | epoch 1432 | loss 4.79 | ppl 27.66 | wps 485064 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7128 | lr 0.000374555 | gnorm 0.775 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69384
2023-02-11 14:50:50 | INFO | fairseq.trainer | begin training epoch 1433
2023-02-11 14:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:51:32 | INFO | fairseq_cli.train | end of epoch 1433 (average epoch stats below)
2023-02-11 14:51:32 | INFO | train | epoch 1433 | loss 4.785 | ppl 27.57 | wps 500433 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7133 | lr 0.000374424 | gnorm 0.624 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69426
2023-02-11 14:51:32 | INFO | fairseq.trainer | begin training epoch 1434
2023-02-11 14:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:52:13 | INFO | fairseq_cli.train | end of epoch 1434 (average epoch stats below)
2023-02-11 14:52:13 | INFO | train | epoch 1434 | loss 4.786 | ppl 27.58 | wps 513770 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7138 | lr 0.000374293 | gnorm 0.65 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69467
2023-02-11 14:52:13 | INFO | fairseq.trainer | begin training epoch 1435
2023-02-11 14:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:52:53 | INFO | fairseq_cli.train | end of epoch 1435 (average epoch stats below)
2023-02-11 14:52:53 | INFO | train | epoch 1435 | loss 4.784 | ppl 27.56 | wps 523026 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7143 | lr 0.000374162 | gnorm 0.663 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69507
2023-02-11 14:52:53 | INFO | fairseq.trainer | begin training epoch 1436
2023-02-11 14:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:53:35 | INFO | fairseq_cli.train | end of epoch 1436 (average epoch stats below)
2023-02-11 14:53:35 | INFO | train | epoch 1436 | loss 4.781 | ppl 27.49 | wps 507020 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7148 | lr 0.000374031 | gnorm 0.576 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69549
2023-02-11 14:53:35 | INFO | fairseq.trainer | begin training epoch 1437
2023-02-11 14:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:54:15 | INFO | fairseq_cli.train | end of epoch 1437 (average epoch stats below)
2023-02-11 14:54:15 | INFO | train | epoch 1437 | loss 4.785 | ppl 27.57 | wps 517500 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7153 | lr 0.0003739 | gnorm 0.708 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69589
2023-02-11 14:54:16 | INFO | fairseq.trainer | begin training epoch 1438
2023-02-11 14:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:54:56 | INFO | fairseq_cli.train | end of epoch 1438 (average epoch stats below)
2023-02-11 14:54:56 | INFO | train | epoch 1438 | loss 4.782 | ppl 27.51 | wps 517274 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7158 | lr 0.00037377 | gnorm 0.657 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69630
2023-02-11 14:54:56 | INFO | fairseq.trainer | begin training epoch 1439
2023-02-11 14:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:55:37 | INFO | fairseq_cli.train | end of epoch 1439 (average epoch stats below)
2023-02-11 14:55:37 | INFO | train | epoch 1439 | loss 4.784 | ppl 27.55 | wps 506862 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7163 | lr 0.000373639 | gnorm 0.705 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69671
2023-02-11 14:55:38 | INFO | fairseq.trainer | begin training epoch 1440
2023-02-11 14:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 14:56:25 | INFO | valid | epoch 1440 | valid on 'valid' subset | loss 5.179 | ppl 36.22 | wps 0 | wpb 11230 | bsz 22 | num_updates 7168 | best_loss 5.113
2023-02-11 14:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1440 @ 7168 updates
2023-02-11 14:56:25 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1440.pt
2023-02-11 14:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1440.pt
2023-02-11 14:57:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1440.pt (epoch 1440 @ 7168 updates, score 5.179) (writing took 64.00716735600145 seconds)
2023-02-11 14:57:29 | INFO | fairseq_cli.train | end of epoch 1440 (average epoch stats below)
2023-02-11 14:57:29 | INFO | train | epoch 1440 | loss 4.785 | ppl 27.56 | wps 189097 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7168 | lr 0.000373509 | gnorm 0.749 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69783
2023-02-11 14:57:29 | INFO | fairseq.trainer | begin training epoch 1441
2023-02-11 14:57:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:59:08 | INFO | fairseq_cli.train | end of epoch 1441 (average epoch stats below)
2023-02-11 14:59:08 | INFO | train | epoch 1441 | loss 4.782 | ppl 27.5 | wps 211335 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7173 | lr 0.000373379 | gnorm 0.65 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69882
2023-02-11 14:59:09 | INFO | fairseq.trainer | begin training epoch 1442
2023-02-11 14:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 14:59:49 | INFO | fairseq_cli.train | end of epoch 1442 (average epoch stats below)
2023-02-11 14:59:49 | INFO | train | epoch 1442 | loss 4.787 | ppl 27.61 | wps 517668 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7178 | lr 0.000373249 | gnorm 0.826 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69923
2023-02-11 14:59:49 | INFO | fairseq.trainer | begin training epoch 1443
2023-02-11 14:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:00:31 | INFO | fairseq_cli.train | end of epoch 1443 (average epoch stats below)
2023-02-11 15:00:31 | INFO | train | epoch 1443 | loss 4.791 | ppl 27.69 | wps 502375 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7183 | lr 0.000373119 | gnorm 0.817 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 69965
2023-02-11 15:00:31 | INFO | fairseq.trainer | begin training epoch 1444
2023-02-11 15:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:01:10 | INFO | fairseq_cli.train | end of epoch 1444 (average epoch stats below)
2023-02-11 15:01:10 | INFO | train | epoch 1444 | loss 4.783 | ppl 27.53 | wps 534616 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7188 | lr 0.000372989 | gnorm 0.647 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70004
2023-02-11 15:01:10 | INFO | fairseq.trainer | begin training epoch 1445
2023-02-11 15:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:01:51 | INFO | fairseq_cli.train | end of epoch 1445 (average epoch stats below)
2023-02-11 15:01:51 | INFO | train | epoch 1445 | loss 4.778 | ppl 27.45 | wps 508914 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7193 | lr 0.000372859 | gnorm 0.539 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70045
2023-02-11 15:01:52 | INFO | fairseq.trainer | begin training epoch 1446
2023-02-11 15:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:02:33 | INFO | fairseq_cli.train | end of epoch 1446 (average epoch stats below)
2023-02-11 15:02:33 | INFO | train | epoch 1446 | loss 4.776 | ppl 27.4 | wps 503292 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7198 | lr 0.00037273 | gnorm 0.523 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70087
2023-02-11 15:02:33 | INFO | fairseq.trainer | begin training epoch 1447
2023-02-11 15:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:02:56 | INFO | train_inner | epoch 1447:      2 / 5 loss=4.784, ppl=27.56, wps=406633, ups=0.1, wpb=4.20655e+06, bsz=8216, num_updates=7200, lr=0.000372678, gnorm=0.674, loss_scale=0.5, train_wall=663, gb_free=5.4, wall=70110
2023-02-11 15:03:13 | INFO | fairseq_cli.train | end of epoch 1447 (average epoch stats below)
2023-02-11 15:03:13 | INFO | train | epoch 1447 | loss 4.777 | ppl 27.41 | wps 528703 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7203 | lr 0.0003726 | gnorm 0.624 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70127
2023-02-11 15:03:13 | INFO | fairseq.trainer | begin training epoch 1448
2023-02-11 15:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:03:55 | INFO | fairseq_cli.train | end of epoch 1448 (average epoch stats below)
2023-02-11 15:03:55 | INFO | train | epoch 1448 | loss 4.782 | ppl 27.52 | wps 505386 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7208 | lr 0.000372471 | gnorm 0.765 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70169
2023-02-11 15:03:55 | INFO | fairseq.trainer | begin training epoch 1449
2023-02-11 15:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:04:36 | INFO | fairseq_cli.train | end of epoch 1449 (average epoch stats below)
2023-02-11 15:04:36 | INFO | train | epoch 1449 | loss 4.782 | ppl 27.52 | wps 501564 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7213 | lr 0.000372342 | gnorm 0.743 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70211
2023-02-11 15:04:37 | INFO | fairseq.trainer | begin training epoch 1450
2023-02-11 15:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 15:05:23 | INFO | valid | epoch 1450 | valid on 'valid' subset | loss 5.193 | ppl 36.59 | wps 0 | wpb 11230 | bsz 22 | num_updates 7218 | best_loss 5.113
2023-02-11 15:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1450 @ 7218 updates
2023-02-11 15:05:23 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1450.pt
2023-02-11 15:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1450.pt
2023-02-11 15:06:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1450.pt (epoch 1450 @ 7218 updates, score 5.193) (writing took 62.61579608099419 seconds)
2023-02-11 15:06:26 | INFO | fairseq_cli.train | end of epoch 1450 (average epoch stats below)
2023-02-11 15:06:26 | INFO | train | epoch 1450 | loss 4.78 | ppl 27.46 | wps 192848 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7218 | lr 0.000372213 | gnorm 0.71 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70320
2023-02-11 15:06:26 | INFO | fairseq.trainer | begin training epoch 1451
2023-02-11 15:06:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:07:18 | INFO | fairseq_cli.train | end of epoch 1451 (average epoch stats below)
2023-02-11 15:07:18 | INFO | train | epoch 1451 | loss 4.784 | ppl 27.56 | wps 403464 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7223 | lr 0.000372084 | gnorm 0.707 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70372
2023-02-11 15:07:18 | INFO | fairseq.trainer | begin training epoch 1452
2023-02-11 15:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:08:00 | INFO | fairseq_cli.train | end of epoch 1452 (average epoch stats below)
2023-02-11 15:08:00 | INFO | train | epoch 1452 | loss 4.784 | ppl 27.56 | wps 497910 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7228 | lr 0.000371955 | gnorm 0.604 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70414
2023-02-11 15:08:00 | INFO | fairseq.trainer | begin training epoch 1453
2023-02-11 15:08:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:08:42 | INFO | fairseq_cli.train | end of epoch 1453 (average epoch stats below)
2023-02-11 15:08:42 | INFO | train | epoch 1453 | loss 4.78 | ppl 27.48 | wps 498538 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7233 | lr 0.000371827 | gnorm 0.613 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70456
2023-02-11 15:08:43 | INFO | fairseq.trainer | begin training epoch 1454
2023-02-11 15:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:09:22 | INFO | fairseq_cli.train | end of epoch 1454 (average epoch stats below)
2023-02-11 15:09:22 | INFO | train | epoch 1454 | loss 4.778 | ppl 27.43 | wps 526571 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7238 | lr 0.000371698 | gnorm 0.604 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70496
2023-02-11 15:09:22 | INFO | fairseq.trainer | begin training epoch 1455
2023-02-11 15:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:10:03 | INFO | fairseq_cli.train | end of epoch 1455 (average epoch stats below)
2023-02-11 15:10:03 | INFO | train | epoch 1455 | loss 4.774 | ppl 27.36 | wps 516535 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7243 | lr 0.00037157 | gnorm 0.555 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70537
2023-02-11 15:10:03 | INFO | fairseq.trainer | begin training epoch 1456
2023-02-11 15:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:10:45 | INFO | fairseq_cli.train | end of epoch 1456 (average epoch stats below)
2023-02-11 15:10:45 | INFO | train | epoch 1456 | loss 4.772 | ppl 27.32 | wps 502487 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7248 | lr 0.000371442 | gnorm 0.524 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70579
2023-02-11 15:10:45 | INFO | fairseq.trainer | begin training epoch 1457
2023-02-11 15:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:11:24 | INFO | fairseq_cli.train | end of epoch 1457 (average epoch stats below)
2023-02-11 15:11:24 | INFO | train | epoch 1457 | loss 4.773 | ppl 27.34 | wps 529911 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7253 | lr 0.000371314 | gnorm 0.629 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 70618
2023-02-11 15:11:25 | INFO | fairseq.trainer | begin training epoch 1458
2023-02-11 15:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:12:06 | INFO | fairseq_cli.train | end of epoch 1458 (average epoch stats below)
2023-02-11 15:12:06 | INFO | train | epoch 1458 | loss 4.774 | ppl 27.36 | wps 509633 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7258 | lr 0.000371186 | gnorm 0.725 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70660
2023-02-11 15:12:06 | INFO | fairseq.trainer | begin training epoch 1459
2023-02-11 15:12:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:12:47 | INFO | fairseq_cli.train | end of epoch 1459 (average epoch stats below)
2023-02-11 15:12:47 | INFO | train | epoch 1459 | loss 4.778 | ppl 27.43 | wps 503474 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7263 | lr 0.000371058 | gnorm 0.831 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70701
2023-02-11 15:12:48 | INFO | fairseq.trainer | begin training epoch 1460
2023-02-11 15:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:13:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 15:13:35 | INFO | valid | epoch 1460 | valid on 'valid' subset | loss 5.209 | ppl 36.99 | wps 0 | wpb 11230 | bsz 22 | num_updates 7268 | best_loss 5.113
2023-02-11 15:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1460 @ 7268 updates
2023-02-11 15:13:35 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1460.pt
2023-02-11 15:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1460.pt
2023-02-11 15:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1460.pt (epoch 1460 @ 7268 updates, score 5.209) (writing took 60.99595419902471 seconds)
2023-02-11 15:14:36 | INFO | fairseq_cli.train | end of epoch 1460 (average epoch stats below)
2023-02-11 15:14:36 | INFO | train | epoch 1460 | loss 4.781 | ppl 27.5 | wps 193998 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7268 | lr 0.00037093 | gnorm 0.842 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70810
2023-02-11 15:14:36 | INFO | fairseq.trainer | begin training epoch 1461
2023-02-11 15:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:15:27 | INFO | fairseq_cli.train | end of epoch 1461 (average epoch stats below)
2023-02-11 15:15:27 | INFO | train | epoch 1461 | loss 4.778 | ppl 27.43 | wps 413295 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7273 | lr 0.000370803 | gnorm 0.746 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70861
2023-02-11 15:15:27 | INFO | fairseq.trainer | begin training epoch 1462
2023-02-11 15:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:16:07 | INFO | fairseq_cli.train | end of epoch 1462 (average epoch stats below)
2023-02-11 15:16:07 | INFO | train | epoch 1462 | loss 4.772 | ppl 27.33 | wps 518136 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7278 | lr 0.000370676 | gnorm 0.635 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70901
2023-02-11 15:16:08 | INFO | fairseq.trainer | begin training epoch 1463
2023-02-11 15:16:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:16:48 | INFO | fairseq_cli.train | end of epoch 1463 (average epoch stats below)
2023-02-11 15:16:48 | INFO | train | epoch 1463 | loss 4.769 | ppl 27.26 | wps 516235 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7283 | lr 0.000370548 | gnorm 0.552 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70942
2023-02-11 15:16:48 | INFO | fairseq.trainer | begin training epoch 1464
2023-02-11 15:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:17:28 | INFO | fairseq_cli.train | end of epoch 1464 (average epoch stats below)
2023-02-11 15:17:28 | INFO | train | epoch 1464 | loss 4.768 | ppl 27.25 | wps 528710 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7288 | lr 0.000370421 | gnorm 0.63 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 70982
2023-02-11 15:17:28 | INFO | fairseq.trainer | begin training epoch 1465
2023-02-11 15:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:18:09 | INFO | fairseq_cli.train | end of epoch 1465 (average epoch stats below)
2023-02-11 15:18:09 | INFO | train | epoch 1465 | loss 4.77 | ppl 27.28 | wps 507616 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7293 | lr 0.000370294 | gnorm 0.685 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71023
2023-02-11 15:18:10 | INFO | fairseq.trainer | begin training epoch 1466
2023-02-11 15:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:18:50 | INFO | fairseq_cli.train | end of epoch 1466 (average epoch stats below)
2023-02-11 15:18:50 | INFO | train | epoch 1466 | loss 4.771 | ppl 27.3 | wps 517847 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7298 | lr 0.000370167 | gnorm 0.769 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71064
2023-02-11 15:18:50 | INFO | fairseq.trainer | begin training epoch 1467
2023-02-11 15:18:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:19:14 | INFO | train_inner | epoch 1467:      2 / 5 loss=4.776, ppl=27.4, wps=430308, ups=0.1, wpb=4.20776e+06, bsz=8218.4, num_updates=7300, lr=0.000370117, gnorm=0.677, loss_scale=1, train_wall=663, gb_free=5.4, wall=71088
2023-02-11 15:19:31 | INFO | fairseq_cli.train | end of epoch 1467 (average epoch stats below)
2023-02-11 15:19:31 | INFO | train | epoch 1467 | loss 4.77 | ppl 27.28 | wps 515980 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7303 | lr 0.000370041 | gnorm 0.667 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71105
2023-02-11 15:19:31 | INFO | fairseq.trainer | begin training epoch 1468
2023-02-11 15:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:20:13 | INFO | fairseq_cli.train | end of epoch 1468 (average epoch stats below)
2023-02-11 15:20:13 | INFO | train | epoch 1468 | loss 4.769 | ppl 27.26 | wps 494615 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7308 | lr 0.000369914 | gnorm 0.651 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71147
2023-02-11 15:20:13 | INFO | fairseq.trainer | begin training epoch 1469
2023-02-11 15:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:20:53 | INFO | fairseq_cli.train | end of epoch 1469 (average epoch stats below)
2023-02-11 15:20:53 | INFO | train | epoch 1469 | loss 4.765 | ppl 27.19 | wps 529640 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7313 | lr 0.000369787 | gnorm 0.592 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71187
2023-02-11 15:20:53 | INFO | fairseq.trainer | begin training epoch 1470
2023-02-11 15:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 15:21:41 | INFO | valid | epoch 1470 | valid on 'valid' subset | loss 5.204 | ppl 36.86 | wps 0 | wpb 11230 | bsz 22 | num_updates 7318 | best_loss 5.113
2023-02-11 15:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1470 @ 7318 updates
2023-02-11 15:21:41 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1470.pt
2023-02-11 15:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1470.pt
2023-02-11 15:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1470.pt (epoch 1470 @ 7318 updates, score 5.204) (writing took 77.79553205901175 seconds)
2023-02-11 15:22:59 | INFO | fairseq_cli.train | end of epoch 1470 (average epoch stats below)
2023-02-11 15:22:59 | INFO | train | epoch 1470 | loss 4.765 | ppl 27.19 | wps 166974 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7318 | lr 0.000369661 | gnorm 0.623 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71313
2023-02-11 15:22:59 | INFO | fairseq.trainer | begin training epoch 1471
2023-02-11 15:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:23:49 | INFO | fairseq_cli.train | end of epoch 1471 (average epoch stats below)
2023-02-11 15:23:49 | INFO | train | epoch 1471 | loss 4.765 | ppl 27.19 | wps 420900 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7323 | lr 0.000369535 | gnorm 0.67 | loss_scale 1 | train_wall 33 | gb_free 5.6 | wall 71363
2023-02-11 15:23:49 | INFO | fairseq.trainer | begin training epoch 1472
2023-02-11 15:23:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:24:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-02-11 15:24:27 | INFO | fairseq_cli.train | end of epoch 1472 (average epoch stats below)
2023-02-11 15:24:27 | INFO | train | epoch 1472 | loss 4.774 | ppl 27.36 | wps 413865 | ups 0.1 | wpb 3.968e+06 | bsz 7750 | num_updates 7327 | lr 0.000369434 | gnorm 0.857 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71401
2023-02-11 15:24:28 | INFO | fairseq.trainer | begin training epoch 1473
2023-02-11 15:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:25:10 | INFO | fairseq_cli.train | end of epoch 1473 (average epoch stats below)
2023-02-11 15:25:10 | INFO | train | epoch 1473 | loss 4.776 | ppl 27.4 | wps 492440 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7332 | lr 0.000369308 | gnorm 0.853 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71444
2023-02-11 15:25:10 | INFO | fairseq.trainer | begin training epoch 1474
2023-02-11 15:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:25:50 | INFO | fairseq_cli.train | end of epoch 1474 (average epoch stats below)
2023-02-11 15:25:50 | INFO | train | epoch 1474 | loss 4.771 | ppl 27.3 | wps 526635 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7337 | lr 0.000369182 | gnorm 0.636 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71484
2023-02-11 15:25:50 | INFO | fairseq.trainer | begin training epoch 1475
2023-02-11 15:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:26:30 | INFO | fairseq_cli.train | end of epoch 1475 (average epoch stats below)
2023-02-11 15:26:31 | INFO | train | epoch 1475 | loss 4.768 | ppl 27.24 | wps 517568 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7342 | lr 0.000369056 | gnorm 0.616 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71525
2023-02-11 15:26:31 | INFO | fairseq.trainer | begin training epoch 1476
2023-02-11 15:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:27:13 | INFO | fairseq_cli.train | end of epoch 1476 (average epoch stats below)
2023-02-11 15:27:13 | INFO | train | epoch 1476 | loss 4.763 | ppl 27.16 | wps 498228 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7347 | lr 0.000368931 | gnorm 0.63 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71567
2023-02-11 15:27:13 | INFO | fairseq.trainer | begin training epoch 1477
2023-02-11 15:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:27:53 | INFO | fairseq_cli.train | end of epoch 1477 (average epoch stats below)
2023-02-11 15:27:53 | INFO | train | epoch 1477 | loss 4.766 | ppl 27.21 | wps 524298 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7352 | lr 0.000368805 | gnorm 0.693 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71607
2023-02-11 15:27:53 | INFO | fairseq.trainer | begin training epoch 1478
2023-02-11 15:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:28:34 | INFO | fairseq_cli.train | end of epoch 1478 (average epoch stats below)
2023-02-11 15:28:34 | INFO | train | epoch 1478 | loss 4.77 | ppl 27.29 | wps 513973 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7357 | lr 0.00036868 | gnorm 0.787 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71648
2023-02-11 15:28:34 | INFO | fairseq.trainer | begin training epoch 1479
2023-02-11 15:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:29:16 | INFO | fairseq_cli.train | end of epoch 1479 (average epoch stats below)
2023-02-11 15:29:16 | INFO | train | epoch 1479 | loss 4.765 | ppl 27.19 | wps 502112 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7362 | lr 0.000368555 | gnorm 0.638 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71690
2023-02-11 15:29:16 | INFO | fairseq.trainer | begin training epoch 1480
2023-02-11 15:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 15:30:03 | INFO | valid | epoch 1480 | valid on 'valid' subset | loss 5.191 | ppl 36.54 | wps 0 | wpb 11230 | bsz 22 | num_updates 7367 | best_loss 5.113
2023-02-11 15:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1480 @ 7367 updates
2023-02-11 15:30:03 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1480.pt
2023-02-11 15:30:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1480.pt
2023-02-11 15:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1480.pt (epoch 1480 @ 7367 updates, score 5.191) (writing took 69.47442189700087 seconds)
2023-02-11 15:31:12 | INFO | fairseq_cli.train | end of epoch 1480 (average epoch stats below)
2023-02-11 15:31:12 | INFO | train | epoch 1480 | loss 4.76 | ppl 27.1 | wps 180590 | ups 0.04 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7367 | lr 0.00036843 | gnorm 0.525 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71806
2023-02-11 15:31:13 | INFO | fairseq.trainer | begin training epoch 1481
2023-02-11 15:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:32:05 | INFO | fairseq_cli.train | end of epoch 1481 (average epoch stats below)
2023-02-11 15:32:05 | INFO | train | epoch 1481 | loss 4.761 | ppl 27.11 | wps 400186 | ups 0.1 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7372 | lr 0.000368305 | gnorm 0.64 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71859
2023-02-11 15:32:05 | INFO | fairseq.trainer | begin training epoch 1482
2023-02-11 15:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:32:44 | INFO | fairseq_cli.train | end of epoch 1482 (average epoch stats below)
2023-02-11 15:32:44 | INFO | train | epoch 1482 | loss 4.761 | ppl 27.11 | wps 533442 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7377 | lr 0.00036818 | gnorm 0.654 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71898
2023-02-11 15:32:45 | INFO | fairseq.trainer | begin training epoch 1483
2023-02-11 15:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:33:27 | INFO | fairseq_cli.train | end of epoch 1483 (average epoch stats below)
2023-02-11 15:33:27 | INFO | train | epoch 1483 | loss 4.762 | ppl 27.14 | wps 492239 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7382 | lr 0.000368055 | gnorm 0.772 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71941
2023-02-11 15:33:27 | INFO | fairseq.trainer | begin training epoch 1484
2023-02-11 15:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:34:07 | INFO | fairseq_cli.train | end of epoch 1484 (average epoch stats below)
2023-02-11 15:34:07 | INFO | train | epoch 1484 | loss 4.766 | ppl 27.21 | wps 523644 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7387 | lr 0.000367931 | gnorm 0.775 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 71981
2023-02-11 15:34:07 | INFO | fairseq.trainer | begin training epoch 1485
2023-02-11 15:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:34:48 | INFO | fairseq_cli.train | end of epoch 1485 (average epoch stats below)
2023-02-11 15:34:48 | INFO | train | epoch 1485 | loss 4.759 | ppl 27.07 | wps 514891 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7392 | lr 0.000367806 | gnorm 0.618 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72022
2023-02-11 15:34:48 | INFO | fairseq.trainer | begin training epoch 1486
2023-02-11 15:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:35:29 | INFO | fairseq_cli.train | end of epoch 1486 (average epoch stats below)
2023-02-11 15:35:29 | INFO | train | epoch 1486 | loss 4.757 | ppl 27.05 | wps 511784 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7397 | lr 0.000367682 | gnorm 0.608 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72063
2023-02-11 15:35:29 | INFO | fairseq.trainer | begin training epoch 1487
2023-02-11 15:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:36:01 | INFO | train_inner | epoch 1487:      3 / 5 loss=4.765, ppl=27.19, wps=417692, ups=0.1, wpb=4.20655e+06, bsz=8216, num_updates=7400, lr=0.000367607, gnorm=0.671, loss_scale=0.5, train_wall=671, gb_free=5.4, wall=72095
2023-02-11 15:36:10 | INFO | fairseq_cli.train | end of epoch 1487 (average epoch stats below)
2023-02-11 15:36:10 | INFO | train | epoch 1487 | loss 4.757 | ppl 27.04 | wps 518039 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7402 | lr 0.000367558 | gnorm 0.649 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72104
2023-02-11 15:36:10 | INFO | fairseq.trainer | begin training epoch 1488
2023-02-11 15:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:36:50 | INFO | fairseq_cli.train | end of epoch 1488 (average epoch stats below)
2023-02-11 15:36:50 | INFO | train | epoch 1488 | loss 4.757 | ppl 27.03 | wps 522109 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7407 | lr 0.000367434 | gnorm 0.641 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72144
2023-02-11 15:36:50 | INFO | fairseq.trainer | begin training epoch 1489
2023-02-11 15:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:37:33 | INFO | fairseq_cli.train | end of epoch 1489 (average epoch stats below)
2023-02-11 15:37:33 | INFO | train | epoch 1489 | loss 4.755 | ppl 27.01 | wps 492097 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7412 | lr 0.00036731 | gnorm 0.621 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72187
2023-02-11 15:37:33 | INFO | fairseq.trainer | begin training epoch 1490
2023-02-11 15:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-11 15:38:19 | INFO | valid | epoch 1490 | valid on 'valid' subset | loss 5.21 | ppl 37.02 | wps 0 | wpb 11230 | bsz 22 | num_updates 7417 | best_loss 5.113
2023-02-11 15:38:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1490 @ 7417 updates
2023-02-11 15:38:19 | INFO | fairseq.trainer | Saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1490.pt
2023-02-11 15:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1490.pt
2023-02-11 15:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/gryang/fairseq/LRS23vocab_LibriLRS23_wordpiece/drop0.5wd0.01/checkpoint1490.pt (epoch 1490 @ 7417 updates, score 5.21) (writing took 59.399090416991385 seconds)
2023-02-11 15:39:18 | INFO | fairseq_cli.train | end of epoch 1490 (average epoch stats below)
2023-02-11 15:39:18 | INFO | train | epoch 1490 | loss 4.755 | ppl 27.01 | wps 199635 | ups 0.05 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7417 | lr 0.000367186 | gnorm 0.673 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72292
2023-02-11 15:39:18 | INFO | fairseq.trainer | begin training epoch 1491
2023-02-11 15:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:40:11 | INFO | fairseq_cli.train | end of epoch 1491 (average epoch stats below)
2023-02-11 15:40:11 | INFO | train | epoch 1491 | loss 4.762 | ppl 27.13 | wps 394953 | ups 0.09 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7422 | lr 0.000367062 | gnorm 0.846 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72345
2023-02-11 15:40:12 | INFO | fairseq.trainer | begin training epoch 1492
2023-02-11 15:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:40:52 | INFO | fairseq_cli.train | end of epoch 1492 (average epoch stats below)
2023-02-11 15:40:52 | INFO | train | epoch 1492 | loss 4.766 | ppl 27.2 | wps 514970 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7427 | lr 0.000366939 | gnorm 0.838 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72386
2023-02-11 15:40:52 | INFO | fairseq.trainer | begin training epoch 1493
2023-02-11 15:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:41:34 | INFO | fairseq_cli.train | end of epoch 1493 (average epoch stats below)
2023-02-11 15:41:34 | INFO | train | epoch 1493 | loss 4.76 | ppl 27.09 | wps 506731 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7432 | lr 0.000366815 | gnorm 0.682 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72428
2023-02-11 15:41:34 | INFO | fairseq.trainer | begin training epoch 1494
2023-02-11 15:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:42:13 | INFO | fairseq_cli.train | end of epoch 1494 (average epoch stats below)
2023-02-11 15:42:13 | INFO | train | epoch 1494 | loss 4.757 | ppl 27.05 | wps 531802 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7437 | lr 0.000366692 | gnorm 0.688 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72467
2023-02-11 15:42:13 | INFO | fairseq.trainer | begin training epoch 1495
2023-02-11 15:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:42:54 | INFO | fairseq_cli.train | end of epoch 1495 (average epoch stats below)
2023-02-11 15:42:54 | INFO | train | epoch 1495 | loss 4.754 | ppl 26.99 | wps 513287 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7442 | lr 0.000366569 | gnorm 0.622 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72508
2023-02-11 15:42:54 | INFO | fairseq.trainer | begin training epoch 1496
2023-02-11 15:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:43:36 | INFO | fairseq_cli.train | end of epoch 1496 (average epoch stats below)
2023-02-11 15:43:36 | INFO | train | epoch 1496 | loss 4.753 | ppl 26.96 | wps 501564 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7447 | lr 0.000366445 | gnorm 0.533 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72550
2023-02-11 15:43:36 | INFO | fairseq.trainer | begin training epoch 1497
2023-02-11 15:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:44:16 | INFO | fairseq_cli.train | end of epoch 1497 (average epoch stats below)
2023-02-11 15:44:16 | INFO | train | epoch 1497 | loss 4.753 | ppl 26.97 | wps 527224 | ups 0.13 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7452 | lr 0.000366322 | gnorm 0.635 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72590
2023-02-11 15:44:16 | INFO | fairseq.trainer | begin training epoch 1498
2023-02-11 15:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:44:57 | INFO | fairseq_cli.train | end of epoch 1498 (average epoch stats below)
2023-02-11 15:44:57 | INFO | train | epoch 1498 | loss 4.753 | ppl 26.97 | wps 518232 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7457 | lr 0.0003662 | gnorm 0.631 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72631
2023-02-11 15:44:57 | INFO | fairseq.trainer | begin training epoch 1499
2023-02-11 15:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-02-11 15:45:39 | INFO | fairseq_cli.train | end of epoch 1499 (average epoch stats below)
2023-02-11 15:45:39 | INFO | train | epoch 1499 | loss 4.755 | ppl 27.01 | wps 498369 | ups 0.12 | wpb 4.20675e+06 | bsz 8216.4 | num_updates 7462 | lr 0.000366077 | gnorm 0.743 | loss_scale 0.5 | train_wall 33 | gb_free 5.6 | wall 72673
2023-02-11 15:45:39 | INFO | fairseq.trainer | begin training epoch 1500
2023-02-11 15:45:39 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/home/gryang/anaconda3/envs/fairseqnew/bin/fairseq-train", line 8, in <module>
    sys.exit(cli_main())
  File "/home/gryang/fairseq/fairseq_cli/train.py", line 507, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/gryang/fairseq/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/gryang/anaconda3/envs/fairseqnew/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/gryang/anaconda3/envs/fairseqnew/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/gryang/anaconda3/envs/fairseqnew/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 2 terminated with signal SIGKILL
/home/gryang/anaconda3/envs/fairseqnew/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6640 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
