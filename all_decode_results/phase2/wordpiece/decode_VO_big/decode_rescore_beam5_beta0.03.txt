2023-02-10 11:25:53,735 - __main__ - INFO - Namespace(batch_size=48, beam=500, beamWidth=5, beamsizetoken=None, beamthreshold=100.0, beta=0.03, decode_type='HYBRID_RESCORE', eval_lrs3_model_file='/data2/alumni/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/check/train-step_1191-wer_0.674.ckpt', lexicon='/data2/alumni/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/lst/LRS23.lst', lmpath='/data2/alumni/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/LRS23_4gram.bin', lmweight=1, logname='/data2/alumni/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main_noneed/decode_VO_big/decode_rescore_beam5_beta0.03.txt', modal='VO', nbest=30, silweight=0, type='kenlm', unitlm=False, unkweight=-inf, wordscore=2)
2023-02-10 11:25:53,737 - __main__ - INFO - 
Trained Model File: /data2/alumni/gryang/Leveraging-Self-Supervised-Learning-for-AVSR-main/check/train-step_1191-wer_0.674.ckpt
2023-02-10 11:25:53,748 - __main__ - INFO - no noise
2023-02-10 11:25:59,393 - __main__ - INFO - _IncompatibleKeys(missing_keys=['transformer_lm._float_tensor', 'transformer_lm.models.0.decoder.version', 'transformer_lm.models.0.decoder.embed_tokens.weight', 'transformer_lm.models.0.decoder.project_in_dim.weight', 'transformer_lm.models.0.decoder.embed_positions._float_tensor', 'transformer_lm.models.0.decoder.layers.0.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.0.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.0.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.0.fc1.weight', 'transformer_lm.models.0.decoder.layers.0.fc1.bias', 'transformer_lm.models.0.decoder.layers.0.fc2.weight', 'transformer_lm.models.0.decoder.layers.0.fc2.bias', 'transformer_lm.models.0.decoder.layers.0.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.0.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.1.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.1.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.1.fc1.weight', 'transformer_lm.models.0.decoder.layers.1.fc1.bias', 'transformer_lm.models.0.decoder.layers.1.fc2.weight', 'transformer_lm.models.0.decoder.layers.1.fc2.bias', 'transformer_lm.models.0.decoder.layers.1.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.1.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.2.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.2.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.2.fc1.weight', 'transformer_lm.models.0.decoder.layers.2.fc1.bias', 'transformer_lm.models.0.decoder.layers.2.fc2.weight', 'transformer_lm.models.0.decoder.layers.2.fc2.bias', 'transformer_lm.models.0.decoder.layers.2.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.2.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.3.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.3.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.3.fc1.weight', 'transformer_lm.models.0.decoder.layers.3.fc1.bias', 'transformer_lm.models.0.decoder.layers.3.fc2.weight', 'transformer_lm.models.0.decoder.layers.3.fc2.bias', 'transformer_lm.models.0.decoder.layers.3.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.3.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.4.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.4.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.4.fc1.weight', 'transformer_lm.models.0.decoder.layers.4.fc1.bias', 'transformer_lm.models.0.decoder.layers.4.fc2.weight', 'transformer_lm.models.0.decoder.layers.4.fc2.bias', 'transformer_lm.models.0.decoder.layers.4.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.4.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.5.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.5.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.5.fc1.weight', 'transformer_lm.models.0.decoder.layers.5.fc1.bias', 'transformer_lm.models.0.decoder.layers.5.fc2.weight', 'transformer_lm.models.0.decoder.layers.5.fc2.bias', 'transformer_lm.models.0.decoder.layers.5.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.5.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.6.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.6.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.6.fc1.weight', 'transformer_lm.models.0.decoder.layers.6.fc1.bias', 'transformer_lm.models.0.decoder.layers.6.fc2.weight', 'transformer_lm.models.0.decoder.layers.6.fc2.bias', 'transformer_lm.models.0.decoder.layers.6.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.6.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.7.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.7.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.7.fc1.weight', 'transformer_lm.models.0.decoder.layers.7.fc1.bias', 'transformer_lm.models.0.decoder.layers.7.fc2.weight', 'transformer_lm.models.0.decoder.layers.7.fc2.bias', 'transformer_lm.models.0.decoder.layers.7.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.7.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.8.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.8.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.8.fc1.weight', 'transformer_lm.models.0.decoder.layers.8.fc1.bias', 'transformer_lm.models.0.decoder.layers.8.fc2.weight', 'transformer_lm.models.0.decoder.layers.8.fc2.bias', 'transformer_lm.models.0.decoder.layers.8.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.8.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.9.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.9.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.9.fc1.weight', 'transformer_lm.models.0.decoder.layers.9.fc1.bias', 'transformer_lm.models.0.decoder.layers.9.fc2.weight', 'transformer_lm.models.0.decoder.layers.9.fc2.bias', 'transformer_lm.models.0.decoder.layers.9.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.9.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.10.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.10.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.10.fc1.weight', 'transformer_lm.models.0.decoder.layers.10.fc1.bias', 'transformer_lm.models.0.decoder.layers.10.fc2.weight', 'transformer_lm.models.0.decoder.layers.10.fc2.bias', 'transformer_lm.models.0.decoder.layers.10.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.10.final_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.k_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.k_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.v_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.v_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.q_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.q_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn.out_proj.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn.out_proj.bias', 'transformer_lm.models.0.decoder.layers.11.self_attn_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.11.self_attn_layer_norm.bias', 'transformer_lm.models.0.decoder.layers.11.fc1.weight', 'transformer_lm.models.0.decoder.layers.11.fc1.bias', 'transformer_lm.models.0.decoder.layers.11.fc2.weight', 'transformer_lm.models.0.decoder.layers.11.fc2.bias', 'transformer_lm.models.0.decoder.layers.11.final_layer_norm.weight', 'transformer_lm.models.0.decoder.layers.11.final_layer_norm.bias', 'transformer_lm.models.0.decoder.project_out_dim.weight', 'transformer_lm.models.0.decoder.output_projection.weight', 'lstm_lm._float_tensor', 'lstm_lm.models.0.decoder.version', 'lstm_lm.models.0.decoder.embed_tokens.weight', 'lstm_lm.models.0.decoder.project_in_dim.weight', 'lstm_lm.models.0.decoder.embed_positions._float_tensor', 'lstm_lm.models.0.decoder.layers.0.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.0.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.0.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.0.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.0.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.0.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.0.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.0.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.0.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.0.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.0.fc1.weight', 'lstm_lm.models.0.decoder.layers.0.fc1.bias', 'lstm_lm.models.0.decoder.layers.0.fc2.weight', 'lstm_lm.models.0.decoder.layers.0.fc2.bias', 'lstm_lm.models.0.decoder.layers.0.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.0.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.1.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.1.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.1.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.1.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.1.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.1.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.1.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.1.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.1.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.1.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.1.fc1.weight', 'lstm_lm.models.0.decoder.layers.1.fc1.bias', 'lstm_lm.models.0.decoder.layers.1.fc2.weight', 'lstm_lm.models.0.decoder.layers.1.fc2.bias', 'lstm_lm.models.0.decoder.layers.1.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.1.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.2.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.2.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.2.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.2.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.2.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.2.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.2.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.2.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.2.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.2.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.2.fc1.weight', 'lstm_lm.models.0.decoder.layers.2.fc1.bias', 'lstm_lm.models.0.decoder.layers.2.fc2.weight', 'lstm_lm.models.0.decoder.layers.2.fc2.bias', 'lstm_lm.models.0.decoder.layers.2.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.2.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.3.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.3.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.3.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.3.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.3.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.3.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.3.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.3.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.3.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.3.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.3.fc1.weight', 'lstm_lm.models.0.decoder.layers.3.fc1.bias', 'lstm_lm.models.0.decoder.layers.3.fc2.weight', 'lstm_lm.models.0.decoder.layers.3.fc2.bias', 'lstm_lm.models.0.decoder.layers.3.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.3.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.4.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.4.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.4.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.4.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.4.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.4.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.4.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.4.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.4.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.4.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.4.fc1.weight', 'lstm_lm.models.0.decoder.layers.4.fc1.bias', 'lstm_lm.models.0.decoder.layers.4.fc2.weight', 'lstm_lm.models.0.decoder.layers.4.fc2.bias', 'lstm_lm.models.0.decoder.layers.4.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.4.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.5.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.5.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.5.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.5.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.5.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.5.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.5.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.5.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.5.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.5.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.5.fc1.weight', 'lstm_lm.models.0.decoder.layers.5.fc1.bias', 'lstm_lm.models.0.decoder.layers.5.fc2.weight', 'lstm_lm.models.0.decoder.layers.5.fc2.bias', 'lstm_lm.models.0.decoder.layers.5.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.5.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.6.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.6.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.6.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.6.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.6.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.6.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.6.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.6.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.6.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.6.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.6.fc1.weight', 'lstm_lm.models.0.decoder.layers.6.fc1.bias', 'lstm_lm.models.0.decoder.layers.6.fc2.weight', 'lstm_lm.models.0.decoder.layers.6.fc2.bias', 'lstm_lm.models.0.decoder.layers.6.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.6.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.7.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.7.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.7.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.7.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.7.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.7.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.7.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.7.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.7.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.7.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.7.fc1.weight', 'lstm_lm.models.0.decoder.layers.7.fc1.bias', 'lstm_lm.models.0.decoder.layers.7.fc2.weight', 'lstm_lm.models.0.decoder.layers.7.fc2.bias', 'lstm_lm.models.0.decoder.layers.7.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.7.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.8.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.8.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.8.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.8.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.8.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.8.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.8.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.8.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.8.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.8.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.8.fc1.weight', 'lstm_lm.models.0.decoder.layers.8.fc1.bias', 'lstm_lm.models.0.decoder.layers.8.fc2.weight', 'lstm_lm.models.0.decoder.layers.8.fc2.bias', 'lstm_lm.models.0.decoder.layers.8.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.8.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.9.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.9.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.9.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.9.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.9.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.9.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.9.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.9.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.9.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.9.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.9.fc1.weight', 'lstm_lm.models.0.decoder.layers.9.fc1.bias', 'lstm_lm.models.0.decoder.layers.9.fc2.weight', 'lstm_lm.models.0.decoder.layers.9.fc2.bias', 'lstm_lm.models.0.decoder.layers.9.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.9.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.10.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.10.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.10.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.10.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.10.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.10.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.10.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.10.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.10.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.10.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.10.fc1.weight', 'lstm_lm.models.0.decoder.layers.10.fc1.bias', 'lstm_lm.models.0.decoder.layers.10.fc2.weight', 'lstm_lm.models.0.decoder.layers.10.fc2.bias', 'lstm_lm.models.0.decoder.layers.10.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.10.final_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.11.self_attn.k_proj.weight', 'lstm_lm.models.0.decoder.layers.11.self_attn.k_proj.bias', 'lstm_lm.models.0.decoder.layers.11.self_attn.v_proj.weight', 'lstm_lm.models.0.decoder.layers.11.self_attn.v_proj.bias', 'lstm_lm.models.0.decoder.layers.11.self_attn.q_proj.weight', 'lstm_lm.models.0.decoder.layers.11.self_attn.q_proj.bias', 'lstm_lm.models.0.decoder.layers.11.self_attn.out_proj.weight', 'lstm_lm.models.0.decoder.layers.11.self_attn.out_proj.bias', 'lstm_lm.models.0.decoder.layers.11.self_attn_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.11.self_attn_layer_norm.bias', 'lstm_lm.models.0.decoder.layers.11.fc1.weight', 'lstm_lm.models.0.decoder.layers.11.fc1.bias', 'lstm_lm.models.0.decoder.layers.11.fc2.weight', 'lstm_lm.models.0.decoder.layers.11.fc2.bias', 'lstm_lm.models.0.decoder.layers.11.final_layer_norm.weight', 'lstm_lm.models.0.decoder.layers.11.final_layer_norm.bias', 'lstm_lm.models.0.decoder.project_out_dim.weight', 'lstm_lm.models.0.decoder.output_projection.weight'], unexpected_keys=[])
2023-02-10 11:25:59,487 - __main__ - INFO - 
Testing the trained model .... 

2023-02-10 11:27:29,341 - __main__ - INFO - rescore index:3
2023-02-10 11:27:40,402 - __main__ - INFO - rescore index:1
2023-02-10 11:27:56,909 - __main__ - INFO - 

2023-02-10 11:27:56,909 - __main__ - INFO - evalWER:163,evalCCount:484
2023-02-10 11:27:56,918 - __main__ - INFO - batch1 || Test CER: 0.23370 || Test WER: 0.33678
2023-02-10 11:29:20,305 - __main__ - INFO - rescore index:1
2023-02-10 11:29:26,762 - __main__ - INFO - rescore index:1
2023-02-10 11:29:39,512 - __main__ - INFO - rescore index:1
2023-02-10 11:29:43,526 - __main__ - INFO - rescore index:1
2023-02-10 11:29:48,119 - __main__ - INFO - 

2023-02-10 11:29:48,119 - __main__ - INFO - evalWER:316,evalCCount:834
2023-02-10 11:29:48,120 - __main__ - INFO - batch2 || Test CER: 0.24857 || Test WER: 0.37890
2023-02-10 11:31:03,736 - __main__ - INFO - rescore index:1
2023-02-10 11:31:07,581 - __main__ - INFO - rescore index:2
2023-02-10 11:31:15,540 - __main__ - INFO - rescore index:1
2023-02-10 11:31:30,010 - __main__ - INFO - rescore index:1
2023-02-10 11:31:33,340 - __main__ - INFO - 

2023-02-10 11:31:33,340 - __main__ - INFO - evalWER:511,evalCCount:1188
2023-02-10 11:31:33,340 - __main__ - INFO - batch3 || Test CER: 0.28493 || Test WER: 0.43013
2023-02-10 11:33:15,060 - __main__ - INFO - rescore index:1
2023-02-10 11:33:22,228 - __main__ - INFO - 

2023-02-10 11:33:22,228 - __main__ - INFO - evalWER:696,evalCCount:1518
2023-02-10 11:33:22,228 - __main__ - INFO - batch4 || Test CER: 0.30627 || Test WER: 0.45850
2023-02-10 11:34:47,844 - __main__ - INFO - rescore index:1
2023-02-10 11:34:49,132 - __main__ - INFO - rescore index:2
2023-02-10 11:35:03,596 - __main__ - INFO - rescore index:1
2023-02-10 11:35:10,200 - __main__ - INFO - rescore index:1
2023-02-10 11:35:12,908 - __main__ - INFO - 

2023-02-10 11:35:12,908 - __main__ - INFO - evalWER:919,evalCCount:1908
2023-02-10 11:35:12,908 - __main__ - INFO - batch5 || Test CER: 0.32262 || Test WER: 0.48166
2023-02-10 11:36:39,810 - __main__ - INFO - rescore index:2
2023-02-10 11:36:44,291 - __main__ - INFO - rescore index:1
2023-02-10 11:36:48,950 - __main__ - INFO - rescore index:1
2023-02-10 11:36:57,543 - __main__ - INFO - rescore index:3
2023-02-10 11:36:58,195 - __main__ - INFO - rescore index:1
2023-02-10 11:37:05,525 - __main__ - INFO - 

2023-02-10 11:37:05,526 - __main__ - INFO - evalWER:1105,evalCCount:2310
2023-02-10 11:37:05,538 - __main__ - INFO - batch6 || Test CER: 0.32064 || Test WER: 0.47835
2023-02-10 11:38:32,877 - __main__ - INFO - rescore index:1
2023-02-10 11:38:38,624 - __main__ - INFO - rescore index:1
2023-02-10 11:38:40,647 - __main__ - INFO - rescore index:1
2023-02-10 11:38:54,129 - __main__ - INFO - rescore index:1
2023-02-10 11:38:57,458 - __main__ - INFO - 

2023-02-10 11:38:57,458 - __main__ - INFO - evalWER:1251,evalCCount:2719
2023-02-10 11:38:57,458 - __main__ - INFO - batch7 || Test CER: 0.30816 || Test WER: 0.46010
2023-02-10 11:40:15,075 - __main__ - INFO - rescore index:1
2023-02-10 11:40:19,256 - __main__ - INFO - rescore index:1
2023-02-10 11:40:24,101 - __main__ - INFO - rescore index:1
2023-02-10 11:40:29,963 - __main__ - INFO - rescore index:1
2023-02-10 11:40:44,732 - __main__ - INFO - 

2023-02-10 11:40:44,732 - __main__ - INFO - evalWER:1408,evalCCount:3029
2023-02-10 11:40:44,732 - __main__ - INFO - batch8 || Test CER: 0.31180 || Test WER: 0.46484
2023-02-10 11:42:04,267 - __main__ - INFO - rescore index:1
2023-02-10 11:42:10,093 - __main__ - INFO - rescore index:4
2023-02-10 11:42:15,286 - __main__ - INFO - rescore index:3
2023-02-10 11:42:19,226 - __main__ - INFO - rescore index:1
2023-02-10 11:42:32,992 - __main__ - INFO - rescore index:1
2023-02-10 11:42:35,076 - __main__ - INFO - 

2023-02-10 11:42:35,076 - __main__ - INFO - evalWER:1591,evalCCount:3390
2023-02-10 11:42:35,076 - __main__ - INFO - batch9 || Test CER: 0.31589 || Test WER: 0.46932
2023-02-10 11:44:13,661 - __main__ - INFO - rescore index:1
2023-02-10 11:44:18,789 - __main__ - INFO - rescore index:2
2023-02-10 11:44:19,474 - __main__ - INFO - 

2023-02-10 11:44:19,475 - __main__ - INFO - evalWER:1748,evalCCount:3695
2023-02-10 11:44:19,475 - __main__ - INFO - batch10 || Test CER: 0.31804 || Test WER: 0.47307
2023-02-10 11:45:42,493 - __main__ - INFO - rescore index:1
2023-02-10 11:45:53,061 - __main__ - INFO - rescore index:1
2023-02-10 11:45:53,705 - __main__ - INFO - rescore index:1
2023-02-10 11:45:55,708 - __main__ - INFO - rescore index:1
2023-02-10 11:45:56,343 - __main__ - INFO - rescore index:1
2023-02-10 11:45:58,989 - __main__ - INFO - rescore index:1
2023-02-10 11:46:08,648 - __main__ - INFO - 

2023-02-10 11:46:08,649 - __main__ - INFO - evalWER:1894,evalCCount:3997
2023-02-10 11:46:08,656 - __main__ - INFO - batch11 || Test CER: 0.31989 || Test WER: 0.47386
2023-02-10 11:47:25,768 - __main__ - INFO - rescore index:1
2023-02-10 11:47:30,859 - __main__ - INFO - rescore index:1
2023-02-10 11:47:42,620 - __main__ - INFO - rescore index:1
2023-02-10 11:47:44,559 - __main__ - INFO - rescore index:1
2023-02-10 11:47:46,619 - __main__ - INFO - 

2023-02-10 11:47:46,620 - __main__ - INFO - evalWER:2005,evalCCount:4307
2023-02-10 11:47:46,620 - __main__ - INFO - batch12 || Test CER: 0.31341 || Test WER: 0.46552
2023-02-10 11:49:13,552 - __main__ - INFO - rescore index:1
2023-02-10 11:49:39,666 - __main__ - INFO - 

2023-02-10 11:49:39,670 - __main__ - INFO - evalWER:2152,evalCCount:4652
2023-02-10 11:49:39,688 - __main__ - INFO - batch13 || Test CER: 0.31045 || Test WER: 0.46260
2023-02-10 11:51:04,774 - __main__ - INFO - rescore index:5
2023-02-10 11:51:06,184 - __main__ - INFO - rescore index:8
2023-02-10 11:51:08,731 - __main__ - INFO - rescore index:1
2023-02-10 11:51:27,957 - __main__ - INFO - rescore index:1
2023-02-10 11:51:28,570 - __main__ - INFO - rescore index:1
2023-02-10 11:51:28,627 - __main__ - INFO - 

2023-02-10 11:51:28,627 - __main__ - INFO - evalWER:2371,evalCCount:5049
2023-02-10 11:51:28,628 - __main__ - INFO - batch14 || Test CER: 0.31535 || Test WER: 0.46960
2023-02-10 11:52:57,082 - __main__ - INFO - rescore index:1
2023-02-10 11:52:58,461 - __main__ - INFO - rescore index:1
2023-02-10 11:53:08,299 - __main__ - INFO - rescore index:1
2023-02-10 11:53:24,952 - __main__ - INFO - 

2023-02-10 11:53:24,953 - __main__ - INFO - evalWER:2567,evalCCount:5379
2023-02-10 11:53:24,953 - __main__ - INFO - batch15 || Test CER: 0.32057 || Test WER: 0.47723
2023-02-10 11:54:40,022 - __main__ - INFO - rescore index:1
2023-02-10 11:54:40,653 - __main__ - INFO - rescore index:1
2023-02-10 11:54:49,790 - __main__ - INFO - rescore index:1
2023-02-10 11:54:53,743 - __main__ - INFO - 

2023-02-10 11:54:53,747 - __main__ - INFO - evalWER:2758,evalCCount:5719
2023-02-10 11:54:53,772 - __main__ - INFO - batch16 || Test CER: 0.32329 || Test WER: 0.48225
2023-02-10 11:56:20,771 - __main__ - INFO - rescore index:1
2023-02-10 11:56:29,082 - __main__ - INFO - rescore index:1
2023-02-10 11:56:42,852 - __main__ - INFO - 

2023-02-10 11:56:42,853 - __main__ - INFO - evalWER:2926,evalCCount:6019
2023-02-10 11:56:42,862 - __main__ - INFO - batch17 || Test CER: 0.32515 || Test WER: 0.48613
2023-02-10 11:58:06,262 - __main__ - INFO - rescore index:2
2023-02-10 11:58:28,087 - __main__ - INFO - rescore index:1
2023-02-10 11:58:34,083 - __main__ - INFO - 

2023-02-10 11:58:34,083 - __main__ - INFO - evalWER:3101,evalCCount:6394
2023-02-10 11:58:34,083 - __main__ - INFO - batch18 || Test CER: 0.32299 || Test WER: 0.48499
2023-02-10 11:59:59,361 - __main__ - INFO - rescore index:1
2023-02-10 12:00:07,264 - __main__ - INFO - rescore index:1
2023-02-10 12:00:20,862 - __main__ - INFO - rescore index:1
2023-02-10 12:00:22,348 - __main__ - INFO - 

2023-02-10 12:00:22,348 - __main__ - INFO - evalWER:3257,evalCCount:6716
2023-02-10 12:00:22,348 - __main__ - INFO - batch19 || Test CER: 0.32203 || Test WER: 0.48496
2023-02-10 12:01:41,880 - __main__ - INFO - rescore index:2
2023-02-10 12:01:43,758 - __main__ - INFO - rescore index:1
2023-02-10 12:01:57,845 - __main__ - INFO - rescore index:1
2023-02-10 12:02:00,350 - __main__ - INFO - rescore index:2
2023-02-10 12:02:07,499 - __main__ - INFO - rescore index:2
2023-02-10 12:02:08,847 - __main__ - INFO - 

2023-02-10 12:02:08,847 - __main__ - INFO - evalWER:3493,evalCCount:7103
2023-02-10 12:02:08,847 - __main__ - INFO - batch20 || Test CER: 0.32625 || Test WER: 0.49176
2023-02-10 12:03:33,233 - __main__ - INFO - rescore index:1
2023-02-10 12:03:35,162 - __main__ - INFO - rescore index:4
2023-02-10 12:03:37,101 - __main__ - INFO - rescore index:7
2023-02-10 12:03:50,271 - __main__ - INFO - rescore index:1
2023-02-10 12:03:51,070 - __main__ - INFO - rescore index:1
2023-02-10 12:03:58,756 - __main__ - INFO - 

2023-02-10 12:03:58,799 - __main__ - INFO - evalWER:3680,evalCCount:7487
2023-02-10 12:03:58,799 - __main__ - INFO - batch21 || Test CER: 0.32629 || Test WER: 0.49152
2023-02-10 12:05:27,119 - __main__ - INFO - rescore index:2
2023-02-10 12:05:28,391 - __main__ - INFO - rescore index:2
2023-02-10 12:05:44,175 - __main__ - INFO - rescore index:1
2023-02-10 12:05:51,937 - __main__ - INFO - 

2023-02-10 12:05:51,937 - __main__ - INFO - evalWER:3883,evalCCount:7876
2023-02-10 12:05:51,937 - __main__ - INFO - batch22 || Test CER: 0.32767 || Test WER: 0.49302
2023-02-10 12:07:16,756 - __main__ - INFO - rescore index:1
2023-02-10 12:07:21,962 - __main__ - INFO - rescore index:2
2023-02-10 12:07:32,992 - __main__ - INFO - rescore index:1
2023-02-10 12:07:40,383 - __main__ - INFO - 

2023-02-10 12:07:40,383 - __main__ - INFO - evalWER:4056,evalCCount:8243
2023-02-10 12:07:40,383 - __main__ - INFO - batch23 || Test CER: 0.32690 || Test WER: 0.49205
2023-02-10 12:09:10,934 - __main__ - INFO - rescore index:2
2023-02-10 12:09:22,734 - __main__ - INFO - 

2023-02-10 12:09:22,734 - __main__ - INFO - evalWER:4236,evalCCount:8613
2023-02-10 12:09:22,734 - __main__ - INFO - batch24 || Test CER: 0.32604 || Test WER: 0.49181
2023-02-10 12:10:42,690 - __main__ - INFO - rescore index:1
2023-02-10 12:11:05,935 - __main__ - INFO - 

2023-02-10 12:11:05,935 - __main__ - INFO - evalWER:4365,evalCCount:8967
2023-02-10 12:11:05,946 - __main__ - INFO - batch25 || Test CER: 0.32164 || Test WER: 0.48678
2023-02-10 12:12:36,200 - __main__ - INFO - rescore index:1
2023-02-10 12:12:49,234 - __main__ - INFO - rescore index:1
2023-02-10 12:12:53,776 - __main__ - INFO - rescore index:1
2023-02-10 12:12:55,455 - __main__ - INFO - rescore index:1
2023-02-10 12:12:56,684 - __main__ - INFO - rescore index:1
2023-02-10 12:12:57,366 - __main__ - INFO - 

2023-02-10 12:12:57,366 - __main__ - INFO - evalWER:4523,evalCCount:9335
2023-02-10 12:12:57,366 - __main__ - INFO - batch26 || Test CER: 0.32083 || Test WER: 0.48452
2023-02-10 12:14:21,428 - __main__ - INFO - rescore index:1
2023-02-10 12:14:24,548 - __main__ - INFO - rescore index:1
2023-02-10 12:14:45,199 - __main__ - INFO - 

2023-02-10 12:14:45,199 - __main__ - INFO - evalWER:4687,evalCCount:9689
2023-02-10 12:14:45,199 - __main__ - INFO - batch27 || Test CER: 0.31930 || Test WER: 0.48374
2023-02-10 12:15:38,328 - __main__ - INFO - rescore index:2
2023-02-10 12:15:45,093 - __main__ - INFO - rescore index:1
2023-02-10 12:15:46,496 - __main__ - INFO - 

2023-02-10 12:15:46,496 - __main__ - INFO - evalWER:4788,evalCCount:9890
2023-02-10 12:15:46,496 - __main__ - INFO - batch28 || Test CER: 0.32018 || Test WER: 0.48413
2023-02-10 12:15:46,497 - __main__ - INFO - evalWER:4788,evalCCount:9890
2023-02-10 12:15:46,508 - __main__ - INFO - VOMODAL || Test CER: 0.32018 || Test WER: 0.48413
2023-02-10 12:15:46,508 - __main__ - INFO - 
Testing Done.

